{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计标签信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = '/data/hjl/data'\n",
    "label_file = 'wsi_label_info-20240905.xlsx'\n",
    "label_path = os.path.join(root_dir, label_file)\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_excel(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsi_label\n",
      "NILM            30561\n",
      "ASC-US           7928\n",
      "LSIL             5472\n",
      "BV               3980\n",
      "ASC-H            1905\n",
      "M                1903\n",
      "HSIL             1391\n",
      "T                 614\n",
      "AGC               538\n",
      "ASCH               28\n",
      "E                  18\n",
      "Actinomyces         8\n",
      "NILM-atrophy        4\n",
      "FXJ                 3\n",
      "炎症                  2\n",
      "LSIL+BV             2\n",
      "ASC-h               2\n",
      "ASC-US+BV           2\n",
      "H                   2\n",
      "？                   1\n",
      "ASC-H+BV            1\n",
      "HSV                 1\n",
      "SCC                 1\n",
      "Name: count, dtype: int64\n",
      "########################################\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "54367it [19:21, 46.80it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "904\n",
      "wsi_label\n",
      "NILM            30164\n",
      "ASC-US           7751\n",
      "LSIL             5371\n",
      "BV               3933\n",
      "M                1874\n",
      "ASC-H            1851\n",
      "HSIL             1342\n",
      "T                 602\n",
      "AGC               529\n",
      "E                  17\n",
      "Actinomyces         8\n",
      "NILM-atrophy        4\n",
      "炎症                  2\n",
      "LSIL+BV             2\n",
      "ASC-h               2\n",
      "ASC-US+BV           2\n",
      "ASCH                2\n",
      "H                   2\n",
      "？                   1\n",
      "HSV                 1\n",
      "ASC-H+BV            1\n",
      "FXJ                 1\n",
      "SCC                 1\n",
      "Name: count, dtype: int64\n",
      "########################################\n",
      "wsi_label\n",
      "NILM            29454\n",
      "ASC-US           5905\n",
      "LSIL             4433\n",
      "BV               3782\n",
      "M                1803\n",
      "ASC-H            1493\n",
      "HSIL             1195\n",
      "T                 587\n",
      "AGC               497\n",
      "E                  17\n",
      "Actinomyces         8\n",
      "NILM-atrophy        4\n",
      "ASC-US+BV           2\n",
      "炎症                  2\n",
      "LSIL+BV             1\n",
      "FXJ                 1\n",
      "ASC-H+BV            1\n",
      "ASC-h               1\n",
      "？                   1\n",
      "HSV                 1\n",
      "ASCH                1\n",
      "SCC                 1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# print(df['wsi_label'])\n",
    "print(df['wsi_label'].value_counts())\n",
    "print('########################################')\n",
    "\n",
    "feat_dir = '/data/hjl/data/ori_img_feats/embed6/'\n",
    "count = 0\n",
    "for index, wsi in tqdm(df.iterrows()): \n",
    "    if not os.path.exists(os.path.join(feat_dir, wsi['wsi_id'].replace('.pt', ''))):\n",
    "        count += 1\n",
    "        # print(wsi['wsi_id'])\n",
    "        df = df.drop(index)\n",
    "\n",
    "print(count)\n",
    "print(df['wsi_label'].value_counts())\n",
    "print('########################################')\n",
    "\n",
    "df = df.drop_duplicates(subset='wsi_id')\n",
    "print(df['wsi_label'].value_counts())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 构造子样本标签"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "root_dir = '/data/hjl/data'\n",
    "sample_num = 2000\n",
    "output_file = f'wsi_label_{sample_num}.csv'\n",
    "output_path = os.path.join(root_dir, output_file)\n",
    "# sample_df = df.sample(n=sample_num, replace=False)\n",
    "# sample_df.to_csv(output_path, index=False)\n",
    "discard_wsi_list = ['CX20193918-ASC-US.pt', 'T2303300641.pt']\n",
    "\n",
    "value_list = ['NILM', 'ASC-US', 'LSIL', 'ASC-H', 'HSIL', 'AGC', 'T', 'M', 'BV']\n",
    "specific_value = 'NILM-atrophy'  \n",
    "specific_samples = df[df['wsi_label'] == specific_value]\n",
    "\n",
    "# 计算特定值样本的数量\n",
    "specific_samples_count = specific_samples.shape[0]\n",
    "\n",
    "# 然后从剩余的数据中随机选择 2000 - specific_samples_count 个样本\n",
    "remaining_samples_count = 2000 - specific_samples_count\n",
    "\n",
    "df = df[~df['wsi_id'].isin(discard_wsi_list)]\n",
    "remaining_samples = df[df['wsi_label'].isin(value_list)].sample(n=remaining_samples_count, replace=False)\n",
    "\n",
    "# 将特定值样本和随机选择的样本合并\n",
    "combined_samples = pd.concat([specific_samples, remaining_samples])\n",
    "\n",
    "# 再次保存到CSV文件\n",
    "combined_samples.to_csv(output_path, index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wsi_label\n",
      "NILM            1203\n",
      "ASC-US           209\n",
      "BV               177\n",
      "LSIL             171\n",
      "M                 86\n",
      "ASC-H             59\n",
      "HSIL              38\n",
      "T                 32\n",
      "AGC               21\n",
      "NILM-atrophy       4\n",
      "Name: count, dtype: int64\n",
      "########\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "wsi_label\n",
       "NILM            1203\n",
       "ASC-US           209\n",
       "BV               177\n",
       "LSIL             171\n",
       "M                 86\n",
       "ASC-H             59\n",
       "HSIL              38\n",
       "T                 32\n",
       "AGC               21\n",
       "NILM-atrophy       4\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(combined_samples['wsi_label'].value_counts())\n",
    "unique_samples = combined_samples.drop_duplicates()\n",
    "print('########')\n",
    "unique_samples['wsi_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     2000\n",
      "unique      10\n",
      "top       NILM\n",
      "freq      1203\n",
      "Name: wsi_label, dtype: object\n",
      "wsi_label\n",
      "NILM            1203\n",
      "ASC-US           209\n",
      "BV               177\n",
      "LSIL             171\n",
      "M                 86\n",
      "ASC-H             59\n",
      "HSIL              38\n",
      "T                 32\n",
      "AGC               21\n",
      "NILM-atrophy       4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "root_dir = '/data/hjl/data'\n",
    "label_file = 'wsi_label_2000.csv'\n",
    "label_path = os.path.join(root_dir, label_file)\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_csv(label_path)\n",
    "\n",
    "print(df['wsi_label'].describe())\n",
    "print(df['wsi_label'].value_counts())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 匹配WSI位置"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:08, 239.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = '/data/hjl/data'\n",
    "label_file = 'wsi_label_2000.csv'\n",
    "label_path = os.path.join(root_dir, label_file)\n",
    "sample_num = 2000\n",
    "output_file = f'wsi_label_{sample_num}_path.csv'\n",
    "output_path = os.path.join(root_dir, output_file)\n",
    "wsi_root_dir = '/data2/px_data_lake/TCT_POS_NEG_DATA3'\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_csv(label_path)\n",
    "wsi_paths = []\n",
    "for index, wsi in tqdm(df.iterrows()): \n",
    "    wsi_name = wsi['wsi_id'].replace('.pt', '')\n",
    "    wsi_path = glob.glob(os.path.join(wsi_root_dir, '*', '*', wsi_name), recursive=True)\n",
    "    if len(wsi_path) == 0:\n",
    "        print(f'No matching WSI found for {wsi_name}')\n",
    "        wsi_paths.append('flag')\n",
    "    else:\n",
    "        wsi_paths.append(wsi_path[0]) \n",
    "df['wsi_path'] = wsi_paths\n",
    "df.to_csv(output_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:00, 20395.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "feat_dir = '/data/hjl/data/ori_img_feats/embed6/'\n",
    "root_dir = '/data/hjl/data'\n",
    "label_file = 'wsi_label_2000.csv'\n",
    "label_path = os.path.join(root_dir, label_file)\n",
    "df = pd.read_csv(label_path)\n",
    "count = 0\n",
    "for index, wsi in tqdm(df.iterrows()): \n",
    "    wsi_id = wsi['wsi_id'].replace('.pt', '')\n",
    "    feat_path = glob.glob(os.path.join(feat_dir, wsi_id))\n",
    "    if len(feat_path) == 0:\n",
    "        print(f'No matching WSI found for {wsi_id}')\n",
    "        count += 1\n",
    "print(count)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 统计图片信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2000/2000 [00:05<00:00, 358.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_dir = '/data/hjl/data'\n",
    "label_file = 'wsi_label_2000_path.csv'\n",
    "label_path = os.path.join(root_dir, label_file)\n",
    "# sample_num = 2000\n",
    "output_file = f'wsi_label_2000_imgpath.csv'\n",
    "output_path = os.path.join(root_dir, output_file)\n",
    "# wsi_root_dir = '/data2/px_data_lake/TCT_POS_NEG_DATA3'\n",
    "\n",
    "# 读取xlsx文件\n",
    "df = pd.read_csv(label_path)\n",
    "wsi_paths = df['wsi_path']\n",
    "wsi_img_paths = []\n",
    "count = 0\n",
    "print(len(wsi_paths))\n",
    "for wsi_path in tqdm(wsi_paths):\n",
    "    tmp_path1 = os.path.join(wsi_path, 'TCT', 'OriginalImage')\n",
    "    tmp_path2 = os.path.join(wsi_path, 'DigitalSlice', 'OriginalImage')\n",
    "    tmp_path3 = os.path.join(wsi_path, 'OriginalImage')\n",
    "    tmp_path4 = 'flag'\n",
    "    flag = False\n",
    "    if os.path.exists(tmp_path1):\n",
    "        wsi_img_paths.append(tmp_path1)\n",
    "    elif os.path.exists(tmp_path2):\n",
    "        wsi_img_paths.append(tmp_path2)\n",
    "    elif os.path.exists(tmp_path3):\n",
    "        wsi_img_paths.append(tmp_path3)\n",
    "    else:\n",
    "        for filename in os.listdir(wsi_path):\n",
    "            if filename.endswith('.jpg'):\n",
    "                flag = True\n",
    "        if flag:\n",
    "            wsi_img_paths.append(wsi_path)\n",
    "        else:\n",
    "            wsi_img_paths.append(tmp_path4)\n",
    "            print(wsi_path)\n",
    "            count += 1\n",
    "print(count)\n",
    "df['wsi_img_path'] = wsi_img_paths\n",
    "df.to_csv(output_path, index=False)\n",
    "\n",
    "# df['wsi_path'] = wsi_paths\n",
    "# df.to_csv(output_path, index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 创建数据集软连接"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "output_dir = '/data/hjl/data/TCTGC-2000'\n",
    "csv_file = '/data/hjl/data/wsi_label_2000_imgpath.csv'\n",
    "df = pd.read_csv(csv_file)\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    wsi_name = row['wsi_id'].replace('.pt', '')\n",
    "    wsi_img_path = row['wsi_img_path']\n",
    "    os.symlink(wsi_img_path, os.path.join(output_dir, wsi_name))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
