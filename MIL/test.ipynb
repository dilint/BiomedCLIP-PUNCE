{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class BinaryFocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=0.25, gamma=2.0, reduction='mean', eps=1e-8):\n",
    "        \"\"\"\n",
    "        alpha: 类别权重（平衡正负样本，建议 0.25 用于正样本少的场景）\n",
    "        gamma: 难易样本调节因子（越大，对难样本的关注越高）\n",
    "        reduction: 'mean'/'sum'/'none'\n",
    "        eps: 数值稳定性\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, inputs, targets):\n",
    "        # 计算概率\n",
    "        probs = torch.sigmoid(inputs)\n",
    "        bce_loss = F.binary_cross_entropy_with_logits(\n",
    "            inputs, targets, reduction='none'\n",
    "        )\n",
    "        \n",
    "        # Focal Weight: (1 - p_t)^gamma\n",
    "        p_t = probs * targets + (1 - probs) * (1 - targets)  # p if t=1 else 1-p\n",
    "        focal_weight = (1 - p_t).pow(self.gamma)\n",
    "        \n",
    "        # Alpha 权重\n",
    "        alpha_weight = self.alpha * targets + (1 - self.alpha) * (1 - targets)\n",
    "        \n",
    "        # 组合损失\n",
    "        loss = focal_weight * alpha_weight * bce_loss\n",
    "        \n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class AsymmetricLossOptimized(nn.Module):\n",
    "    ''' Notice - optimized version, minimizes memory allocation and gpu uploading,\n",
    "    favors inplace operations'''\n",
    "\n",
    "    def __init__(self, gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8, disable_torch_grad_focal_loss=False, ft_cls=None, num_classes=9):\n",
    "        super(AsymmetricLossOptimized, self).__init__()\n",
    "\n",
    "        self.gamma_neg = gamma_neg\n",
    "        self.gamma_pos = gamma_pos\n",
    "        self.clip = clip\n",
    "        self.disable_torch_grad_focal_loss = disable_torch_grad_focal_loss\n",
    "        self.eps = eps\n",
    "\n",
    "        self.flag = True\n",
    "\n",
    "        self.ft_cls = ft_cls\n",
    "        self.num_classes = num_classes\n",
    "        # prevent memory allocation and gpu uploading every iteration, and encourages inplace operations\n",
    "        self.targets = self.anti_targets = self.xs_pos = self.xs_neg = self.asymmetric_w = self.loss = None\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        \"\"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: input logits\n",
    "        y: targets (multi-label binarized vector)\n",
    "        \"\"\"\n",
    "        \n",
    "        self.targets = y\n",
    "        self.anti_targets = 1 - y\n",
    "\n",
    "        # Calculating Probabilities\n",
    "        self.xs_pos = torch.sigmoid(x)\n",
    "        self.xs_neg = 1.0 - self.xs_pos\n",
    "\n",
    "        # Asymmetric Clipping\n",
    "        if self.clip is not None and self.clip > 0:\n",
    "            self.xs_neg.add_(self.clip).clamp_(max=1)\n",
    "\n",
    "        self.loss = self.targets * torch.log(self.xs_pos.clamp(min=self.eps))\n",
    "        self.loss.add_(self.anti_targets * torch.log(self.xs_neg.clamp(min=self.eps)))\n",
    "        \n",
    "        # Asymmetric Focusing\n",
    "        if self.gamma_neg > 0 or self.gamma_pos > 0:\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(False)\n",
    "            self.xs_pos = self.xs_pos * self.targets\n",
    "            self.xs_neg = self.xs_neg * self.anti_targets\n",
    "\n",
    "            if self.ft_cls is not None:\n",
    "                # 需要按照微调需求手动更改\n",
    "                # 根据目前的测试结果看，漏的情况的原因：1）阳性类的得分不够；2）0类的得分高了\n",
    "                \n",
    "                # 由于1和0经常比较相近，因此我们还可以考虑不对1类动手的方案\n",
    "                gamma_neg = [1.0] + [1.0] + [10.] + [10.] + [10.] + [10.] + [1.]*3\n",
    "                gamma_pos = [self.gamma_pos] * 9\n",
    "                #weights = [0.] + [1.]*5 + [0.]*4\n",
    "                weights = [0.] + [1.] + [2.]*4 + [0.]*3\n",
    "            else:\n",
    "                gamma_neg = self.gamma_neg\n",
    "                gamma_pos = self.gamma_pos\n",
    "                weights = torch.tensor([1.]*9, device=x.device)\n",
    "\n",
    "            self.asymmetric_w = torch.pow(1 - self.xs_pos - self.xs_neg,\n",
    "                                          gamma_pos * self.targets + gamma_neg * self.anti_targets)\n",
    "\n",
    "            if self.disable_torch_grad_focal_loss:\n",
    "                torch.set_grad_enabled(True)\n",
    "            self.loss = self.loss * self.asymmetric_w\n",
    "        \n",
    "\n",
    "        if self.ft_cls is not None and 1==1:\n",
    "            assert self.loss.shape[-1] == 10\n",
    "            if self.ft_cls == 1:\n",
    "                print(\"移除阳性类的loss\")\n",
    "                self.loss *= torch.tensor([1.] + [0.]*5 + [0.]*4).to(x.device) # 移除阳性类的loss\n",
    "            elif self.ft_cls == 2: # 移除阴性类的loss:\n",
    "                print(\"移除阴性类的loss\")\n",
    "                self.loss = self.loss*weights\n",
    "\n",
    "        return -self.loss.sum(dim=1).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 10]) torch.Size([5, 10])\n",
      "tensor(0.2845) tensor(0.8440) tensor(1.6843)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "num_classes = 10\n",
    "batch_size = 5\n",
    "logits = torch.randn(batch_size, num_classes)\n",
    "labels = torch.randint(0, num_classes, (batch_size,))\n",
    "labels_onehot = F.one_hot(labels, num_classes).type(torch.float32)\n",
    "print(logits.shape, labels_onehot.shape)\n",
    "criterion_focal = BinaryFocalLoss(alpha=0.25, gamma=2, reduction='mean', eps=1e-8)\n",
    "criterion_bce = nn.BCEWithLogitsLoss(reduction='mean')\n",
    "criterion_asl = AsymmetricLossOptimized(gamma_neg=4, gamma_pos=1, clip=0.05, eps=1e-8)\n",
    "loss_focal = criterion_focal(logits, labels_onehot)\n",
    "loss_bce = criterion_bce(logits, labels_onehot)\n",
    "loss_asl = criterion_asl(logits, labels_onehot)\n",
    "print(loss_focal, loss_bce, loss_asl)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
