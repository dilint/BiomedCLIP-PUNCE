{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msklearn\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmetrics\u001b[39;00m \u001b[39mimport\u001b[39;00m confusion_matrix\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/sklearn/__init__.py:82\u001b[0m\n\u001b[1;32m     80\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _distributor_init  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[1;32m     81\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __check_build  \u001b[39m# noqa: F401\u001b[39;00m\n\u001b[0;32m---> 82\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbase\u001b[39;00m \u001b[39mimport\u001b[39;00m clone\n\u001b[1;32m     83\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39m_show_versions\u001b[39;00m \u001b[39mimport\u001b[39;00m show_versions\n\u001b[1;32m     85\u001b[0m __all__ \u001b[39m=\u001b[39m [\u001b[39m'\u001b[39m\u001b[39mcalibration\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcovariance\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mcross_decomposition\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     86\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mdatasets\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdecomposition\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdummy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mensemble\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexceptions\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     87\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mexperimental\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mexternals\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mfeature_extraction\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     96\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mclone\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mget_config\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mset_config\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mconfig_context\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m     97\u001b[0m            \u001b[39m'\u001b[39m\u001b[39mshow_versions\u001b[39m\u001b[39m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/sklearn/base.py:20\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m __version__\n\u001b[0;32m---> 20\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m \u001b[39mimport\u001b[39;00m _IS_32BIT\n\u001b[1;32m     22\u001b[0m _DEFAULT_TAGS \u001b[39m=\u001b[39m {\n\u001b[1;32m     23\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mnon_deterministic\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     24\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrequires_positive_X\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mbinary_only\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     36\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mrequires_fit\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mTrue\u001b[39;00m}\n\u001b[1;32m     39\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mclone\u001b[39m(estimator, safe\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/sklearn/utils/__init__.py:27\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mexceptions\u001b[39;00m \u001b[39mimport\u001b[39;00m DataConversionWarning\n\u001b[1;32m     26\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdeprecation\u001b[39;00m \u001b[39mimport\u001b[39;00m deprecated\n\u001b[0;32m---> 27\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mfixes\u001b[39;00m \u001b[39mimport\u001b[39;00m np_version\n\u001b[1;32m     28\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mvalidation\u001b[39;00m \u001b[39mimport\u001b[39;00m (as_float_array,\n\u001b[1;32m     29\u001b[0m                          assert_all_finite,\n\u001b[1;32m     30\u001b[0m                          check_random_state, column_or_1d, check_array,\n\u001b[1;32m     31\u001b[0m                          check_consistent_length, check_X_y, indexable,\n\u001b[1;32m     32\u001b[0m                          check_symmetric, check_scalar)\n\u001b[1;32m     33\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m get_config\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/sklearn/utils/fixes.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msp\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstats\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msparse\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlinalg\u001b[39;00m \u001b[39mimport\u001b[39;00m lsqr \u001b[39mas\u001b[39;00m sparse_lsqr  \u001b[39m# noqa\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_parse_version\u001b[39m(version_string):\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/stats/__init__.py:485\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m.. _statsrefmanual:\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    480\u001b[0m \n\u001b[1;32m    481\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    483\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_warnings_errors\u001b[39;00m \u001b[39mimport\u001b[39;00m (ConstantInputWarning, NearConstantInputWarning,\n\u001b[1;32m    484\u001b[0m                                DegenerateDataWarning, FitError)\n\u001b[0;32m--> 485\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_py\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n\u001b[1;32m    486\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_variation\u001b[39;00m \u001b[39mimport\u001b[39;00m variation\n\u001b[1;32m    487\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mdistributions\u001b[39;00m \u001b[39mimport\u001b[39;00m \u001b[39m*\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/stats/_stats_py.py:46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mspecial\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m linalg\n\u001b[0;32m---> 46\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m distributions\n\u001b[1;32m     47\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _mstats_basic \u001b[39mas\u001b[39;00m mstats_basic\n\u001b[1;32m     48\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_stats_mstats_common\u001b[39;00m \u001b[39mimport\u001b[39;00m (_find_repeats, linregress, theilslopes,\n\u001b[1;32m     49\u001b[0m                                    siegelslopes)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/stats/distributions.py:8\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39m# Author:  Travis Oliphant  2002-2011 with contributions from\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39m#          SciPy Developers 2004-2011\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39m#       instead of `git blame -Lxxx,+x`.\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[39m#\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_distn_infrastructure\u001b[39;00m \u001b[39mimport\u001b[39;00m (rv_discrete, rv_continuous, rv_frozen)\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _continuous_distns\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m _discrete_distns\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/stats/_distn_infrastructure.py:22\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mspecial\u001b[39;00m \u001b[39mimport\u001b[39;00m comb, entr\n\u001b[1;32m     20\u001b[0m \u001b[39m# for root finding for continuous distribution ppf, and max likelihood\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[39m# estimation\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m optimize\n\u001b[1;32m     24\u001b[0m \u001b[39m# for functions of continuous distributions (e.g. moments, entropy, cdf)\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mscipy\u001b[39;00m \u001b[39mimport\u001b[39;00m integrate\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[0;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/__init__.py:200\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(name)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(name):\n\u001b[1;32m    199\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m submodules:\n\u001b[0;32m--> 200\u001b[0m         \u001b[39mreturn\u001b[39;00m _importlib\u001b[39m.\u001b[39;49mimport_module(\u001b[39mf\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mscipy.\u001b[39;49m\u001b[39m{\u001b[39;49;00mname\u001b[39m}\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    201\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m         \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/importlib/__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m             \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m    126\u001b[0m         level \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 127\u001b[0m \u001b[39mreturn\u001b[39;00m _bootstrap\u001b[39m.\u001b[39;49m_gcd_import(name[level:], package, level)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/scipy/optimize/__init__.py:419\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_linprog\u001b[39;00m \u001b[39mimport\u001b[39;00m linprog, linprog_verbose_callback\n\u001b[1;32m    418\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_lsap\u001b[39;00m \u001b[39mimport\u001b[39;00m linear_sum_assignment\n\u001b[0;32m--> 419\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_differentialevolution\u001b[39;00m \u001b[39mimport\u001b[39;00m differential_evolution\n\u001b[1;32m    420\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_lsq\u001b[39;00m \u001b[39mimport\u001b[39;00m least_squares, lsq_linear\n\u001b[1;32m    421\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m_constraints\u001b[39;00m \u001b[39mimport\u001b[39;00m (NonlinearConstraint,\n\u001b[1;32m    422\u001b[0m                            LinearConstraint,\n\u001b[1;32m    423\u001b[0m                            Bounds)\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:975\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:671\u001b[0m, in \u001b[0;36m_load_unlocked\u001b[0;34m(spec)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:839\u001b[0m, in \u001b[0;36mexec_module\u001b[0;34m(self, module)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:971\u001b[0m, in \u001b[0;36mget_code\u001b[0;34m(self, fullname)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap_external>:640\u001b[0m, in \u001b[0;36m_compile_bytecode\u001b[0;34m(data, name, bytecode_path, source_path)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, average_precision_score,precision_score,f1_score,recall_score\n",
    "\n",
    "# create confusion matrix\n",
    "y_true = np.array([-1]*70 + [0]*160 + [1]*30)\n",
    "y_pred = np.array([-1]*40 + [0]*20 + [1]*20 + \n",
    "                  [-1]*30 + [0]*80 + [1]*30 + \n",
    "                  [-1]*5 + [0]*15 + [1]*20)\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "conf_matrix = pd.DataFrame(cm, index=['Cat','Dog','Pig'], columns=['Cat','Dog','Pig'])\n",
    "\n",
    "print(y_true.shape)\n",
    "print(y_pred.shape)\n",
    "print('------Weighted------')\n",
    "print('Weighted precision', precision_score(y_true, y_pred, average='weighted'))\n",
    "print('Weighted recall', recall_score(y_true, y_pred, average='weighted'))\n",
    "print('Weighted f1-score', f1_score(y_true, y_pred, average='weighted'))\n",
    "print('------Macro------')\n",
    "print('Macro precision', precision_score(y_true, y_pred, average='macro'))\n",
    "print('Macro recall', recall_score(y_true, y_pred, average='macro'))\n",
    "print('Macro f1-score', f1_score(y_true, y_pred, average='macro'))\n",
    "print('------Micro------')\n",
    "print('Micro precision', precision_score(y_true, y_pred, average='micro'))\n",
    "print('Micro recall', recall_score(y_true, y_pred, average='micro'))\n",
    "print('Micro f1-score', f1_score(y_true, y_pred, average='micro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 3, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = a + [4]\n",
    "b = tuple(b)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "ckp_path = '/home/huangjialong/projects/BiomedCLIP-PUNCE/mil-methods/output-model/output-test/resnet1-meanmil-ngc-customsplit/fold_0_model_best_auc.pt'\n",
    "torch.load(ckp_path)\n",
    "ckp_dict = torch.load(ckp_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['BJXFK-LA-591455', 'c00567195', 'BJXFK-XXBA-579873', 'BJXFK-XA-575822', 'c00564281', 'BJXK-XIMEA-FFK-P-599781', 'BJXFK-YX577236', 'F22', 'BJXFK-XA576163', 'BJFFK-SCLC574253', 'C00564517', 'BJFFK-XA574864', 'BJFFK-XA573779', 'BJFFK-XA574570', 'BJXK-XIMEA-FFK-P-592670', 'BJXFK-YX575769', 'BJFFK-XA575058', 'F2', 'C00570399', 'BJXK-XIMEA-FFK-P-601186', 'BJXK-XIMEA-FFK-P-599581', 'BJXFK-XA577091', 'BJXFK-XA575834', 'BJXFK-XA583281', 'c00568834', 'F25', 'BJXFK-YX-576622', 'BJXFK-XA576692', 'BJFFK-XA571457', 'BJXFK-XA577014', 'c00569478', 'BJXFK-YX583088', 'BJXFK-XA577016', 'BJFFK-XA571327', 'C00569905', 'c00568308', 'BJFFK-SCLC572374', 'BJFFK-XA571332', 'c00567186', 'c00568523', 'BJFFK-XA572378', 'BJFFK-XA575640', 'BJXFK-YX584459', 'BJFFK-XA575740', 'BJXK-XIMEA-FFK-P-601001', 'BJXFK-XA-581051', 'BJXK-XIMEA-FFK-P-593609', 'c00568309', 'BJFFK-XA571956', 'BJFFK-XA570908', 'BJXK-XIMEA-FFK-P-602284', 'C00562488', 'BJXFK-XA579315', 'BJXK-XIMEA-FFK-P-598709', 'BJFFK-XA573780', 'BJFFK-XA571951', 'F8', 'BJXFK-EXZLWFX-586914', 'BJXK-XIMEA-FFK-P-592163', 'BJFFK-XA574012', 'BJFFK-XA573815', 'BJFFK-XA574061', 'BJXFK-YX577852', 'F7', 'BJXFK-XA583062', 'BJXFK-XA576184', 'BJXK-XIMEA-FFK-P-592757', 'BJXFK-YX590065', 'BJXFK-EXZLWFX-588182', 'BJXK-XIMEA-FFK-P-593826', 'BJXFK-YX-575866', 'BJFFK-XA574126', 'BJXK-XIMEA-FFK-P-599123', 'BJXFK-XA-590263', 'BJXFK-XXBA-575861', 'BJXFK-XA581050', 'BJXFK-XA576102', 'BJXFK-XA586392', 'BJFFK-XA572478', 'BJXK-XIMEA-FFK-P-593722', 'BJXFK-XA576734', 'BJXK-XIMEA-FFK-P-599508', 'BJFFK-XA573481', 'F27', 'BJXFK-XA588179', 'BJXFK-XXBA-591060', 'BJFFK-XA575619', 'BJXFK-EXZLWFX-581977', 'BJXK-XIMEA-FFK-P-601996', 'BJXFK-XA586645', 'C00569479', 'BJXFK-XA576250', 'BJXFK-XA-591134', 'BJFFK-XA571885', 'c00570276', 'BJXFK-XA-XXBA-576162', 'BJXFK-YX-575750', 'BJFFK-XA570999', 'BJFFK-XA571608', 'BJFFK-XA572293', 'BJXK-XIMEA-FFK-P-593127', 'BJXFK-JPL-585186', 'C0056281f', 'c00570667', 'BJXFK-JPL-576255', 'BJXK-XIMEA-FFK-P-591855', 'BJXFK-XA576932', 'F24', 'BJXFK-YX585201', 'BJFFK-XA571134', 'c00566112', 'C00569807', 'BJFFK-XA572862', 'BJXFK-XXBA-576604', 'BJFFK-XA572375', 'BJXFK-XA576924', 'BJXFK-XA587998', 'BJFFK-JPL571326', 'c00567896', 'BJXK-XIMEA-FFK-P-593715', 'BJXFK-JPL-577915', 'c00570171', 'BJXFK-LA-587831', 'BJXFK-XA589465', 'BJFFK-XA572708', 'C00562664', 'BJXK-XIMEA-FFK-P-598831', 'BJFFK-SCLC572373', 'BJXK-XIMEA-FFK-P-600723', 'c00563357', 'c00570398', 'BJFFK-XA573501', 'BJFFK-XA575215', 'BJXFK-YX576249', 'BJXK-XIMEA-FFK-P-599505', 'C00569706', 'BJXFK-XA575786', 'BJFFK-JPL570703', 'BJFFK-XA574333', 'BJXK-XIMEA-FFK-P-599731', 'BJXFK-XA-XXBA-578232', 'BJXK-XIMEA-FFK-P-601297', 'BJXFK-JPL-582473', 'BJFFK-XA571953', 'F23', 'BJFFK-XA573781', 'BJXFK-XA587308', 'BJXFK-EXZLWFX-580084', 'c00570277', 'C00568307', 'BJXK-XIMEA-FFK-P-598610', 'BJXFK-XA591299', 'BJXFK-YX590265', 'BJFFK-XA574584', 'BJFFK-JPL571450', 'C00569142', 'BJFFK-XA575743', 'BJFFK-XA570907', 'C00562663', 'BJXK-XIMEA-FFK-P-598555', 'C00567317', 'BJXK-XIMEA-FFK-P-599220', 'BJXK-XIMEA-FFK-P-600407', 'BJFFK-XA575445', 'BJXFK-EXZLWFX-585294', 'c00567894', 'BJXFK-XA589233', 'BJXFK-JPL-584243', 'BJXFK-XA585881', 'BJXFK-XA576164', 'BJFFK-XA575703', 'BJXFK-JPL-586018', 'BJFFK-XA573000', 'F1', 'BJFFK-XA573710', 'BJXFK-XXBA-590356', 'BJFFK-XA573708', 'BJXFK-XA583282', 'BJXFK-XA-590514', 'BJXFK-YX581895', 'BJFFK-XA573638', 'BJFFK-XA574865', 'BJXFK-XA-XXBA-576103', 'BJXFK-XA586728', 'BJXFK-YX576670', 'BJXFK-YX577400', 'BJFFK-XA573776', 'BJFFK-JPL570906', 'C00565462', 'BJXK-XIMEA-FFK-P-593212', 'BJFFK-XA571508', 'BJXFK-XA580423', 'BJFFK-XA571452', 'BJFFK-XA573974', 'BJXFK-EXZLWFX-580664', 'BJXFK-XA591086', 'BJFFK-XA571510', 'BJFFK-XA574583', 'BJFFK-XA574842', 'BJXK-XIMEA-P-C601031', 'BJFFK-XA573871', 'BJXK-XIMEA-FFK-P-593309', 'BJFFK-XA571994', 'BJXFK-EXZLWFX-580048', 'BJXFK-XXBA-575862', 'BJFFK-XA572332', 'BJXFK-JPL-585628', 'BJXK-XIMEA-FFK-P-592511', 'BJXK-XIMEA-FFK-P-594531', 'BJXFK-XA577093', 'BJXFK-XA591363', 'BJFFK-XA575354', 'BJXFK-XA578049', 'BJXFK-XA578780', 'BJFFK-XA571606', 'BJXFK-XA586013', 'BJXFK-XA-589881', 'BJXFK-EXZLWFX-582096', 'BJXFK-XA577621', 'BJXK-XIMEA-FFK-P-599699', 'c00567767', 'BJXFK-XA-576006', 'C00562668', 'BJXFK-LA-587550', 'c00570619', 'BJXFK-LA-589256', 'BJXFK-XA-579871', 'BJXFK-XA-580054', 'BJXFK-XA-579925', 'BJXFK-YX577427', 'BJFFK-JPL571605', 'BJFFK-XA572376', 'BJXFK-JPL-584457', 'BJXK-XIMEA-FFK-P-593304', 'BJFFK-JPL570998', 'BJFFK-XA573909', 'c00570400', 'BJFFK-XA570823', 'F14', 'BJXFK-NILM-589516', 'F65', 'BJXFK-NILM-591007', 'BJXFK-NILM-590323', 'BJXFK-NILM-591132', 'BJXFK-NILM-590606', 'F12', 'F69', 'F78', 'F72', 'BJXFK-NILM-591545', 'F67', 'F77', 'F61', 'F82', 'F93', 'F66', 'BJXFK-NILM-590508', 'F92', 'BJXK-XIMEA-FFK-N-598911', 'F68', 'F85', 'BJXFK-NILM-591201', 'F79', 'BJXFK-NILM-590322', 'c00569477', 'F80', 'F98', 'F83', 'BJXFK-NILM-589662', 'BJXFK-NILM-591230', 'BJXFK-NILM-591304', 'c00569144', 'BJXFK-NILM-589580', 'BJXFK-NILM-589508', 'BJXFK-NILM-591089', 'BJXFK-NILM-591253', 'F15', 'BJXFK-NILM-591607', 'BJXFK-NILM-590688', 'BJXFK-NILM-591624', 'F13', 'F97', 'BJXFK-NILM-591294', 'BJXFK-NILM-590757', 'BJXK-XIMEA-FFK-N-598823', 'F88', 'BJTCT563861', 'c00563160', 'F81', 'BJXFK-NILM-590672', 'F90', 'F94', 'F95', 'F75', 'F84', 'F74', 'BJXFK-NILM-589730', 'BJTCT563940', 'BJXFK-NILM-590687', 'F99', 'BJXFK-NILM-591084', 'F11', 'BJXFK-NILM-591444', 'BJXFK-NILM-591276', 'F86', 'F73', 'BJXFK-NILM-590673', 'F71', 'BJXFK-NILM-591313', 'BJXFK-NILM-591311', 'C00567187', 'BJFFK-SQ571250', 'BJXK-XIMEA-FFK-P-594801', 'BJXK-XIMEA-FFK-P-599858', 'BJFFK-XA571456', 'BJXK-XIMEA-FFK-P-602787', 'C00568218', 'BJXK-XIMEA-FFK-P-602501', 'BJXK-XIMEA-FFK-P-594934', 'F40', 'BJXK-XIMEA-FFK-P-595754', 'BJXK-XIMEA-FFK-P-596250', 'BJXK-XIMEA-FFK-P-595753', 'F4', 'BJXK-XIMEA-FFK-P-595253', 'BJXK-XIMEA-FFK-P-597796', 'BJXK-XIMEA-FFK-P-593818', 'BJXK-XIMEA-FFK-P-595303', 'BJXK-XIMEA-FFK-P-599895', 'BJXK-XIMEA-FFK-P-598413', 'BJXK-XIMEA-FFK-P-599867', 'BJXK-XIMEA-FFK-P-602793', 'C00564166', 'BJXK-XIMEA-FFK-P-594333', 'BJXK-XIMEA-FFK-P-593136', 'F43', 'BJXK-XIMEA-FFK-P-602157', 'BJXK-XIMEA-FFK-P-591724', 'BJFFK-JPL572707', 'BJXK-XIMEA-FFK-P-598817', 'BJXK-XIMEA-FFK-P-595158', 'F28', 'BJXK-XIMEA-FFK-P-593142', 'F45', 'BJFFK-SCLC574043', 'BJXK-XIMEA-P-599587', 'F35', 'BJXK-XIMEA-FFK-P-601790', 'C00562410', 'BJXK-XIMEA-FFK-P-601882', 'BJFFK-SQ570830', 'BJXK-XIMEA-FFK-P-599292', 'BJXK-XIMEA-FFK-P-597495', 'BJXK-XIMEA-FFK-P-599223', 'BJXK-XIMEA-FFK-P-599495', 'BJXK-XIMEA-FFK-P-598439', 'BJXK-XIMEA-FFK-P-592517', 'BJXK-XIMEA-FFK-P-600069', 'BJXK-XIMEA-FFK-P-595006', 'BJXK-XIMEA-FFK-P-601787', 'C00569138', 'F58', 'BJXK-XIMEA-FFK-P-597670', 'BJXK-XIMEA-FFK-P-601791', 'C00568110', 'BJXK-XIMEA-FFK-P-602399', 'BJXK-XIMEA-FFK-P-598304', 'BJXK-XIMEA-FFK-P-596341', 'BJXK-XIMEA-P-595010', 'BJXK-XIMEA-FFK-P-596783', 'BJXK-XIMEA-FFK-P-596785', 'BJXK-XIMEA-FFK-P-602900', 'C00567184', 'c00568222', 'BJXK-XIMEA-FFK-P-597001', 'BJXK-XIMEA-FFK-P-599857', 'F39', 'BJXK-XIMEA-FFK-P-602661', 'c00563158', 'C00569903', 'F36', 'c00566002', 'F29', 'F60', 'BJXK-XIMEA-FFK-P-593015', 'BJXK-XIMEA-FFK-P-593128', 'BJXK-XIMEA-FFK-P-601393', 'BJXK-XIMEA-FFK-P-592779', 'BJXK-XIMEA-FFK-P-596249', 'BJXK-XIMEA-FFK-P-601185', 'BJXK-XIMEA-FFK-P-601411', 'C00569715', 'BJXK-XIMEA-FFK-P-598926', 'BJXK-XIMEA-FFK-P-597134', 'F46', 'c00566207', 'BJXK-XIMEA-P-595259', 'F33', 'F41', 'BJXK-XIMEA-FFK-P-595871', 'F59', 'BJXK-XIMEA-FFK-P-595752', 'BJXK-XIMEA-FFK-P-592778', 'c00565704', 'BJFFK-SQ573819', 'F3', 'BJXK-XIMEA-FFK-P-594552', 'C00567183', 'BJXK-XIMEA-FFK-P-599694', 'BJXK-XIMEA-FFK-P-597669', 'BJXK-XIMEA-FFK-P-597069', 'BJFFK-SQ574677', 'BJXK-XIMEA-FFK-P-595757', 'F10', 'F32', 'BJXK-XIMEA-FFK-P-595041', 'BJFFK-SQ571266', 'BJFFK-JPL572747', 'F57', 'C00568109', 'F38', 'BJXK-XIMEA-FFK-P-596254', 'BJFFK-SCLC574011', 'BJXK-XIMEA-FFK-P-601989', 'BJFFK-SCLC571451', 'BJXK-XIMEA-FFK-P-598504', 'c00565709', 'C00564974', 'BJXK-XIMEA-FFK-P-602889', 'BJXK-XIMEA-FFK-P-602386', 'c00566203', 'F42', 'BJXK-XIMEA-FFK-P-598833', 'F34', 'BJFFK-JPL573004', 'BJXK-XIMEA-FFK-P-599695', 'BJXK-XIMEA-FFK-P-595224', 'F44', 'BJXK-XIMEA-FFK-N-602653', 'BJXFK-NILM-607487', 'BJXK-XIMEA-FFK-N-601554', 'BJTCT564874', 'BJXFK-NILM-608646', 'BJTCT569901', 'BJXFK-NILM-607389', 'BJXK-XIMEA-FFK-N-602654', 'BJXFK-NILM-603193', 'BJTCT568024', 'BJTCT563942', 'BJTCT570623', 'BJXFK-NILM-603605', 'BJTCT569371', 'BJFFK-ZS573972', 'BJXK-XIMEA-N-599025', 'BJXK-XIMEA-FFK-N-601555', 'BJXFK-NILM-608428', 'BJXK-XIMEA-FFK-N-600497', 'BJXFK-NILM-608247', 'BJXFK-NILM-590675', 'BJXFK-NILM-590582', 'BJXFK-NILM-590755', 'BJXFK-NILM-590900', 'BJTCT568022', 'BJTCT570617', 'BJXK-XIMEA-N-601392', 'BJXK-XIMEA-FFK-N-601988', 'F52', 'BJXK-XIMEA-FFK-N-599859', 'BJXFK-NILM-591329', 'BJXK-XIMEA-FFK-N-602293', 'BJXK-XIMEA-FFK-N-601283', 'BJXFK-NILM-609152', 'BJTCT570620', 'BJXFK-NILM-606591', 'BJXFK-NILM-590677', 'BJXFK-NILM-608703', 'BJXK-XIMEA-FFK-N-600716', 'BJTCT569806', 'BJFFK-ZS572911', 'BJXK-XIMEA-FFK-N-599776', 'BJXK-XIMEA-N-601314', 'BJXFK-NILM-606611', 'BJXFK-NILM-590793', 'BJXFK-NILM-606968', 'BJXFK-NILM-608939', 'BJXFK-NILM-607496', 'BJXFK-NILM-603434', 'BJXFK-NILM-607483', 'BJXFK-NILM-608168', 'BJXK-XIMEA-N-601412', 'BJXFK-NILM-591353', 'BJXFK-NILM-603301', 'BJXFK-NILM-608169', 'BJXFK-NILM-609043', 'BJXFK-NILM-591356', 'BJFFK-ZS573463', 'BJXFK-NILM-607486', 'BJXFK-NILM-601200', 'BJXFK-NILM-608873', 'BJXFK-NILM-608417', 'BJXFK-NILM-607271', 'BJXK-XIMEA-N-602285', 'BJXK-XIMEA-FFK-N-602655', 'BJXK-XIMEA-FFK-N-600714', 'BJTCT569714', 'BJXK-XIMEA-N-600972', 'BJXFK-NILM-603511', 'BJXFK-NILM-590440', 'BJXK-XIMEA-FFK-N-599715', 'BJXFK-NILM-607920', 'BJXK-XIMEA-FFK-N-600720', 'BJTCT568026', 'BJXFK-NILM-591448', 'BJFFK-ZS572458', 'BJXFK-NILM-608795', 'BJXK-XIMEA-FFK-N-599866', 'BJXFK-NILM-591074', 'BJXFK-NILM-603304', 'BJXFK-NILM-589809', 'BJXFK-NILM-607599', 'BJTCT570828', 'BJXFK-NILM-591131', 'BJXK-XIMEA-FFK-N-602185', 'BJXFK-NILM-603446', 'BJXK-XIMEA-N-602504', 'BJXFK-NILM-608777', 'BJXK-XIMEA-FFK-N-602290', 'BJXFK-NILM-607812', 'BJXK-XIMEA-N-598910', 'BJXK-XIMEA-FFK-N-598927', 'BJXFK-NILM-590462', 'BJTCT571330', 'BJXFK-NILM-607258', 'F54', 'BJXK-XIMEA-N-601391', 'BJXFK-NILM-589796', 'BJFFK-ZS575685', 'BJXFK-NILM-607598', 'BJXK-XIMEA-N-599153', 'BJXFK-NILM-607192', 'BJXFK-NILM-606991', 'BJXFK-NILM-607270', 'BJTCT570273', 'BJXK-XIMEA-N-600292', 'BJXFK-NILM-607022', 'BJXK-XIMEA-FFK-N-599629', 'BJXK-XIMEA-N-599252', 'BJXK-XIMEA-N-599088', 'BJXFK-NILM-591091', 'BJXFK-NILM-607485', 'BJXFK-NILM-591371', 'BJXFK-NILM-591229', 'BJXFK-NILM-591204', 'BJXK-XIMEA-FFK-N-601816', 'BJXFK-NILM-607513', 'BJXK-XIMEA-FFK-N-600803', 'BJTCT570826', 'BJFFK-ZS573778', 'BJXK-XIMEA-FFK-N-600218', 'BJTCT570032', 'BJXFK-NILM-603142', 'F56', 'BJXFK-NILM-609235', 'BJXFK-NILM-606705', 'BJXK-XIMEA-N-599154', 'F50', 'BJXFK-NILM-591071', 'BJXK-XIMEA-N-599226', 'BJTCT571139', 'BJXFK-NILM-608773', 'BJXK-XIMEA-FFK-N-601280', 'BJXFK-NILM-607350', 'BJXK-XIMEA-FFK-N-599865', 'BJXFK-NILM-606895', 'BJTCT570030', 'BJFFK-ZS573634', 'BJXFK-NILM-589509', 'BJFFK-ZS575657', 'BJXFK-NILM-609234', 'BJTCT570004', 'BJXFK-NILM-603690', 'BJTCT571334', 'BJTCT568030', 'BJXFK-NILM-591254', 'BJXK-XIMEA-FFK-N-600068', 'BJXFK-NILM-606929', 'BJXFK-NILM-608796', 'BJXK-XIMEA-FFK-N-600789', 'BJXFK-NILM-590510', 'BJTCT570827', 'BJTCT563941', 'BJTCT570618', 'BJXFK-NILM-590922', 'BJTCT564059', 'BJXFK-NILM-608109', 'F49', 'BJXK-XIMEA-FFK-N-599777', 'BJTCT570170', 'BJXFK-NILM-603750', 'BJTCT567895', 'BJXFK-NILM-608108', 'BJXFK-NILM-589656', 'BJXFK-NILM-603770', 'BJXFK-NILM-590974', 'BJTCT564871', 'BJXFK-NILM-609262', 'BJXFK-NILM-606832', 'BJXFK-NILM-606707', 'BJXFK-NILM-606752', 'BJXFK-NILM-607057', 'BJXFK-NILM-603487', 'BJTCT570392', 'BJXK-XIMEA-FFK-N-603331', 'BJTCT570275', 'BJXFK-NILM-608416', 'BJXFK-NILM-591443', 'BJXK-XIMEA-FFK-N-599716', 'BJXFK-NILM-590894', 'BJXK-XIMEA-FFK-N-600729', 'BJXFK-NILM-590903', 'BJXK-XIMEA-FFK-N-598914', 'BJXK-XIMEA-FFK-N-600790', 'BJTCT570622', 'BJXK-XIMEA-N-599333', 'BJXK-XIMEA-N-599229', 'BJXK-XIMEA-FFK-N-601279', 'BJXFK-NILM-603032', 'BJTCT570913', 'BJXFK-NILM-590583', 'BJXFK-NILM-608321', 'BJFFK-ZS571537', 'BJTCT571269', 'BJXFK-NILM-590756', 'BJXFK-NILM-609258', 'BJTCT570167', 'BJXFK-NILM-607719', 'BJTCT570027', 'BJXFK-NILM-606709', 'BJXK-XIMEA-FFK-N-601808', 'BJTCT569904', 'BJTCT569711', 'BJXFK-NILM-603143', 'BJFFK-ZS571909', 'F53', 'BJXFK-NILM-591481', 'BJXK-XIMEA-FFK-N-602082', 'BJXFK-NILM-606756', 'BJTCT570914', 'BJXK-XIMEA-FFK-N-599881', 'BJTCT570029', 'BJTCT570391', 'BJTCT570911', 'BJTCT567688', 'BJXFK-NILM-590526', 'BJXK-XIMEA-FFK-N-601985', 'BJTCT570396', 'BJFFK-ZS573546', 'BJTCT564058', 'BJXFK-NILM-589729', 'BJXK-XIMEA-N-599122', 'BJXFK-NILM-606927', 'BJTCT569475', 'BJXFK-NILM-606971', 'BJTCT569584', 'BJXFK-NILM-603445', 'BJXFK-NILM-603588', 'BJFFK-ZS572711', 'BJTCT569805', 'BJXK-XIMEA-FFK-N-600715', 'BJTCT568025', 'BJXFK-NILM-590461', 'BJTCT570912', 'BJXFK-NILM-608724', 'BJXFK-NILM-590465', 'BJXK-XIMEA-FFK-N-599779', 'BJXFK-NILM-590904', 'BJTCT564164', 'BJXFK-NILM-608772', 'BJXFK-NILM-591065', 'BJXFK-NILM-590321', 'BJXFK-NILM-608415', 'BJXK-XIMEA-FFK-N-598824', 'BJTCT571333', 'BJFFK-ZS572891', 'BJTCT569369', 'BJTCT569582', 'BJXFK-NILM-590460', 'BJXFK-NILM-591225', 'BJXFK-NILM-608704', 'BJTCT570829', 'BJTCT567687', 'BJXFK-NILM-591355', 'BJXFK-NILM-603507', 'BJTCT564168', 'BJXFK-NILM-603191', 'BJXFK-NILM-607495', 'BJTCT570397', 'BJXFK-NILM-608702', 'BJXFK-NILM-609039', 'BJTCT569710', 'BJXFK-NILM-591256', 'BJXFK-NILM-601203', 'BJXK-XIMEA-FFK-N-599532', 'BJXFK-NILM-608774', 'BJXK-XIMEA-FFK-N-602196', 'BJFFK-ZS573914', 'BJXFK-NILM-603195', 'BJTCT571136', 'BJXK-XIMEA-FFK-N-600804', 'BJXK-XIMEA-FFK-N-600291', 'F51', 'BJXK-XIMEA-FFK-N-603314', 'BJXFK-NILM-609295', 'BJXK-XIMEA-FFK-N-600578', 'BJXFK-NILM-608701', 'BJXFK-NILM-601184', 'BJXFK-NILM-608775', 'BJXK-XIMEA-FFK-N-598948', 'BJXK-XIMEA-N-599228', 'BJXFK-NILM-591354', 'BJXK-XIMEA-FFK-N-601987', 'BJXFK-NILM-607349', 'BJXFK-NILM-589819', 'BJXFK-NILM-606803', 'BJTCT564873', 'BJXFK-NILM-607921', 'BJFFK-ZS572890', 'BJTCT569581', 'BJTCT564055', 'BJTCT569476', 'BJXFK-NILM-591606', 'BJXFK-NILM-607489', 'BJTCT571138', 'BJXK-XIMEA-N-599253', 'BJXK-XIMEA-FFK-N-601556', 'BJTCT564056', 'BJXFK-NILM-607351', 'BJXFK-NILM-591059', 'BJXK-XIMEA-N-603136', 'BJXFK-NILM-589612', 'BJXFK-NILM-607491', 'BJTCT564162', 'BJXFK-NILM-591255', 'BJTCT568031', 'BJTCT571135', 'BJXK-XIMEA-FFK-N-601990', 'BJTCT571137', 'BJTCT568023', 'BJXK-XIMEA-FFK-N-600053', 'F55', 'BJXFK-NILM-607096', 'BJXFK-NILM-603364', 'BJXFK-NILM-608934', 'BJXFK-NILM-608246', 'BJTCT568032', 'BJXFK-NILM-589657', 'BJTCT570915', 'BJXFK-NILM-591546', 'BJTCT564870', 'BJXFK-NILM-590459', 'BJXFK-NILM-591139', 'BJXFK-NILM-607257', 'BJXK-XIMEA-FFK-N-599024', 'BJFFK-ZS573868']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "wsis = []\n",
    "file_name = './simclr/train_label.csv'\n",
    "with open(file_name, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for row in lines:\n",
    "        row = row.strip().split(',')\n",
    "        wsis.append(row[0])\n",
    "print(wsis)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home1/wsi/tct/NILM/xCR20018818-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005897-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006000-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006569-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179985-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166624-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175637-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018330-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008034-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006621-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018882-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005843-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179988-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018485-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018268-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006943-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152317-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007765-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171594-NILM',\n",
       " '/home1/wsi/tct/NILM/202000822',\n",
       " '/home1/wsi/tct/NILM/CX20176960-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006719-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006691-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007597-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174926-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007709-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018261-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152310-NILM',\n",
       " '/home1/wsi/tct/NILM/202000779',\n",
       " '/home1/wsi/tct/NILM/xCR20018855-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152324-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167394-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006568-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166714-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018862-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007954-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152312-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179970-NILM',\n",
       " '/home1/wsi/tct/NILM/202000878',\n",
       " '/home1/wsi/tct/NILM/202000844',\n",
       " '/home1/wsi/tct/NILM/xCY20005811-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010722-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174991-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017708-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018342-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180074-NILM',\n",
       " '/home1/wsi/tct/NILM/202000908',\n",
       " '/home1/wsi/tct/NILM/CX20152372-NILM',\n",
       " '/home1/wsi/tct/NILM/202000842',\n",
       " '/home1/wsi/tct/NILM/xCY20006615-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174958-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176083-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176087-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177011-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010692-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018970-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006651-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018661-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018363-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166674-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166625-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018509-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177067-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174893-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006863-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20011063-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176096-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177908-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174917-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018382-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006908-NILM',\n",
       " '/home1/wsi/tct/NILM/202000774',\n",
       " '/home1/wsi/tct/NILM/xCR20018491-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180044-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007844-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018061-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006710-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018441-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174985-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152410-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166629-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176092-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175576-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018152-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018573-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152390-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006599-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018248-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176151-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152295-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018522-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176124-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177859-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007628-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006896-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167393-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167375-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006783-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010709-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005815-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177837-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180936-NILM',\n",
       " '/home1/wsi/tct/NILM/202000940',\n",
       " '/home1/wsi/tct/NILM/202000857',\n",
       " '/home1/wsi/tct/NILM/xCY20006792-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006782-NILM',\n",
       " '/home1/wsi/tct/NILM/202000795',\n",
       " '/home1/wsi/tct/NILM/xCY20007592-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180061-NILM',\n",
       " '/home1/wsi/tct/NILM/202000860',\n",
       " '/home1/wsi/tct/NILM/CX20172446-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006609-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005820-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018294-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006588-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005857-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177899-NILM',\n",
       " '/home1/wsi/tct/NILM/202000948',\n",
       " '/home1/wsi/tct/NILM/xCY20007964-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175566-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010727-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017996-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005792-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018314-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018902-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175640-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176112-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018675-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006595-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007835-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006551-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176115-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018319-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017869-NILM',\n",
       " '/home1/wsi/tct/NILM/202000828',\n",
       " '/home1/wsi/tct/NILM/CX20174896-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018906-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005916-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179979-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174961-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005995-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018512-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008015-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006618-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017730-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152384-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018529-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018460-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005826-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006772-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176127-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007961-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008014-NILM',\n",
       " '/home1/wsi/tct/NILM/202000816',\n",
       " '/home1/wsi/tct/NILM/CX20152395-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166724-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152397-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018937-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010696-NILM',\n",
       " '/home1/wsi/tct/NILM/202000893',\n",
       " '/home1/wsi/tct/NILM/xCY20010663-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177034-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174883-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20172449-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177888-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006857-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171626-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005917-NILM',\n",
       " '/home1/wsi/tct/NILM/202000768',\n",
       " '/home1/wsi/tct/NILM/xCR20018638-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175577-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167379-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008010-NILM',\n",
       " '/home1/wsi/tct/NILM/202000938',\n",
       " '/home1/wsi/tct/NILM/CX20176126-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174897-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166641-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018226-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175586-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018422-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008031-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005817-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006581-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005844-NILM',\n",
       " '/home1/wsi/tct/NILM/202000926',\n",
       " '/home1/wsi/tct/NILM/xCR20018513-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175649-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006580-NILM',\n",
       " '/home1/wsi/tct/NILM/202000933',\n",
       " '/home1/wsi/tct/NILM/202000787',\n",
       " '/home1/wsi/tct/NILM/CX20152399-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018517-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005922-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018088-NILM',\n",
       " '/home1/wsi/tct/NILM/202000868',\n",
       " '/home1/wsi/tct/NILM/xCR20018128-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006005-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005847-NILM',\n",
       " '/home1/wsi/tct/NILM/CX202012383-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176122-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175650-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175612-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008030-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018156-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005834-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152364-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018616-NILM',\n",
       " '/home1/wsi/tct/NILM/202000794',\n",
       " '/home1/wsi/tct/NILM/xCY20005754-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166677-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006600-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175583-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152347-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005906-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005937-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167406-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007617-NILM',\n",
       " '/home1/wsi/tct/NILM/202000845',\n",
       " '/home1/wsi/tct/NILM/xCR20017825-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008062-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166713-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006608-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180055-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177833-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174994-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017709-NILM',\n",
       " '/home1/wsi/tct/NILM/202000861',\n",
       " '/home1/wsi/tct/NILM/xCY20006667-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175636-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166711-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174978-NILM',\n",
       " '/home1/wsi/tct/NILM/202000796',\n",
       " '/home1/wsi/tct/NILM/CX20174916-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152344-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006634-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018537-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010717-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010669-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007817-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007603-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017844-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006867-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005980-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20019002-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006584-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180926-NILM',\n",
       " '/home1/wsi/tct/NILM/202000830',\n",
       " '/home1/wsi/tct/NILM/xCR20018929-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176973-NILM',\n",
       " '/home1/wsi/tct/NILM/202000864',\n",
       " '/home1/wsi/tct/NILM/202000866',\n",
       " '/home1/wsi/tct/NILM/CX20152362-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171623-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006830-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005863-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018146-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005876-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175638-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152337-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171612-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018078-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152366-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20019006-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018705-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166639-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174886-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167402-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174932-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018989-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167382-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018356-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175002-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018166-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166701-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167380-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007826-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175658-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006885-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010668-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018796-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179991-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177901-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007777-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007776-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176077-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177038-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171609-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174975-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174999-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007613-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152401-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177910-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174931-NILM',\n",
       " '/home1/wsi/tct/NILM/202000935',\n",
       " '/home1/wsi/tct/NILM/xCY20007767-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006795-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167377-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010732-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007834-NILM',\n",
       " '/home1/wsi/tct/NILM/202000953',\n",
       " '/home1/wsi/tct/NILM/xCY20008048-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018630-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152335-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171622-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180064-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017943-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018444-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152409-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010708-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010664-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175611-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166686-NILM',\n",
       " '/home1/wsi/tct/NILM/202000942',\n",
       " '/home1/wsi/tct/NILM/CX20177850-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010693-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010729-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010714-NILM',\n",
       " '/home1/wsi/tct/NILM/202000848',\n",
       " '/home1/wsi/tct/NILM/xCR20018810-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018979-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006591-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152287-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006763-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176132-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152325-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006638-NILM',\n",
       " '/home1/wsi/tct/NILM/202000865',\n",
       " '/home1/wsi/tct/NILM/CX20174927-NILM',\n",
       " '/home1/wsi/tct/NILM/202000783',\n",
       " '/home1/wsi/tct/NILM/xCY20005763-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007842-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176966-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175603-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018923-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005945-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176098-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166649-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006589-NILM',\n",
       " '/home1/wsi/tct/NILM/202000767',\n",
       " '/home1/wsi/tct/NILM/CX20180060-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166702-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006656-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018217-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166726-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167361-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176097-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177861-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007783-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176986-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180944-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166675-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006843-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166645-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175606-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008043-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006821-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006706-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005994-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018402-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018301-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177042-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166728-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174937-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005948-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005830-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018674-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176063-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017767-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018652-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171602-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176133-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176053-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177073-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152293-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152284-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175664-NILM',\n",
       " '/home1/wsi/tct/NILM/202000859',\n",
       " '/home1/wsi/tct/NILM/xCY20010716-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006842-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010700-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175622-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006882-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152302-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006672-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006676-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018602-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018800-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174948-NILM',\n",
       " '/home1/wsi/tct/NILM/202000927',\n",
       " '/home1/wsi/tct/NILM/CX20166690-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177848-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152353-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006001-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166717-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005765-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018044-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008024-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167363-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177827-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167395-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175659-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166623-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167409-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175633-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007782-NILM',\n",
       " '/home1/wsi/tct/NILM/202000786',\n",
       " '/home1/wsi/tct/NILM/CX20171645-NILM',\n",
       " '/home1/wsi/tct/NILM/202000903',\n",
       " '/home1/wsi/tct/NILM/xCR20018120-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152357-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018530-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006808-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010713-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171606-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005866-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166648-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006715-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174903-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152331-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180040-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177851-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010655-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005766-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007811-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018129-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018553-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005942-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017796-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174954-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006873-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018684-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017921-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152354-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010688-NILM',\n",
       " '/home1/wsi/tct/NILM/202000890',\n",
       " '/home1/wsi/tct/NILM/CX20177025-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180016-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166700-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177894-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006630-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017973-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018792-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177914-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018299-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152341-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010675-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167372-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018668-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005814-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017818-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152391-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152342-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007830-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006787-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006410-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152321-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008053-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018998-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010731-NILM',\n",
       " '/home1/wsi/tct/NILM/202000928',\n",
       " '/home1/wsi/tct/NILM/xCR20017905-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018071-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010721-NILM',\n",
       " '/home1/wsi/tct/NILM/202000835',\n",
       " '/home1/wsi/tct/NILM/CX20171642-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017792-NILM',\n",
       " '/home1/wsi/tct/NILM/202000955',\n",
       " '/home1/wsi/tct/NILM/xCR20018932-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006845-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176996-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007831-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152323-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010680-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010699-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010690-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010720-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018988-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006917-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005981-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171613-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007632-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152373-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152356-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006948-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166636-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176962-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008011-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010694-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152307-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167407-NILM',\n",
       " '/home1/wsi/tct/NILM/202000791',\n",
       " '/home1/wsi/tct/NILM/CX20167355-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174941-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152352-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152315-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167378-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180002-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007636-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006866-NILM',\n",
       " '/home1/wsi/tct/NILM/202000836',\n",
       " '/home1/wsi/tct/NILM/CX20174968-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006747-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018721-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006831-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018516-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007808-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010723-NILM',\n",
       " '/home1/wsi/tct/NILM/202000770',\n",
       " '/home1/wsi/tct/NILM/xCR20018634-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152333-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166729-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018396-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018610-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166721-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152377-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005880-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177845-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007819-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176992-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152380-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006594-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152378-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007627-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005783-NILM',\n",
       " '/home1/wsi/tct/NILM/202000884',\n",
       " '/home1/wsi/tct/NILM/xCR20018536-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018985-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180037-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005750-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005912-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007773-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018649-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007720-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152340-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017859-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177015-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174892-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007724-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008020-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007637-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017809-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018971-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006721-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175632-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179999-NILM',\n",
       " '/home1/wsi/tct/NILM/170657627-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017870-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006693-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152407-NILM',\n",
       " '/home1/wsi/tct/NILM/202000824',\n",
       " '/home1/wsi/tct/NILM/CX20176982-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007602-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018698-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174969-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018669-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006743-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006657-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007797-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008009-NILM',\n",
       " '/home1/wsi/tct/NILM/202000952',\n",
       " '/home1/wsi/tct/NILM/xCR20018007-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018847-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006819-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180027-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180071-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167354-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152406-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006628-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006624-NILM',\n",
       " '/home1/wsi/tct/NILM/202000781',\n",
       " '/home1/wsi/tct/NILM/CX20167357-NILM',\n",
       " '/home1/wsi/tct/NILM/202000843',\n",
       " '/home1/wsi/tct/NILM/xCY20006576-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175563-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174965-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018681-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177024-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20178936-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006620-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010711-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167367-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175594-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20172452-NILM',\n",
       " '/home1/wsi/tct/NILM/202000918',\n",
       " '/home1/wsi/tct/NILM/CX20174902-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010710-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152332-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180068-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018134-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176146-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010670-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152370-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180937-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008067-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005809-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179995-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175623-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017880-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167401-NILM',\n",
       " '/home1/wsi/tct/NILM/202000855',\n",
       " '/home1/wsi/tct/NILM/xCR20018528-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175587-NILM',\n",
       " '/home1/wsi/tct/NILM/202000924',\n",
       " '/home1/wsi/tct/NILM/CX20174907-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005804-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177072-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018857-NILM',\n",
       " '/home1/wsi/tct/NILM/202000833',\n",
       " '/home1/wsi/tct/NILM/xCY20005892-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018197-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166705-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018309-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166635-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174945-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167391-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006847-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018615-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006610-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152411-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006683-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007801-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180049-NILM',\n",
       " '/home1/wsi/tct/NILM/202000789',\n",
       " '/home1/wsi/tct/NILM/xCY20006932-NILM',\n",
       " '/home1/wsi/tct/NILM/202000931',\n",
       " '/home1/wsi/tct/NILM/xCR20018856-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152369-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152328-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006883-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010677-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005818-NILM',\n",
       " '/home1/wsi/tct/NILM/202000817',\n",
       " '/home1/wsi/tct/NILM/xCY20006804-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006738-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152313-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152289-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005998-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018664-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018657-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174984-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018958-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166613-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166698-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171592-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018677-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175648-NILM',\n",
       " '/home1/wsi/tct/NILM/202000945',\n",
       " '/home1/wsi/tct/NILM/xCY20010672-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176066-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166719-NILM',\n",
       " '/home1/wsi/tct/NILM/202000932',\n",
       " '/home1/wsi/tct/NILM/CX20180041-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006762-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005777-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152351-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152412-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166646-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176144-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018864-NILM',\n",
       " '/home1/wsi/tct/NILM/202000906',\n",
       " '/home1/wsi/tct/NILM/202000854',\n",
       " '/home1/wsi/tct/NILM/CX20166633-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018700-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018406-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166707-NILM',\n",
       " '/home1/wsi/tct/NILM/202000793',\n",
       " '/home1/wsi/tct/NILM/202000874',\n",
       " '/home1/wsi/tct/NILM/xCR20018032-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175645-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152355-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018907-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007824-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006601-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167398-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006877-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018090-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018075-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018904-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176071-NILM',\n",
       " '/home1/wsi/tct/NILM/202000902',\n",
       " '/home1/wsi/tct/NILM/CX20166689-NILM',\n",
       " '/home1/wsi/tct/NILM/202000939',\n",
       " '/home1/wsi/tct/NILM/202000880',\n",
       " '/home1/wsi/tct/NILM/CX20167369-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20011067-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006575-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005985-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176963-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008019-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006614-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007601-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152371-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018611-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018232-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152334-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010703-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006839-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018699-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018990-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018270-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010654-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166716-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152396-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174918-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005797-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180948-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179994-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017763-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018459-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018918-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167396-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017845-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152394-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166684-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006835-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018135-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018412-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167374-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006834-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018577-NILM',\n",
       " '/home1/wsi/tct/NILM/202000889',\n",
       " '/home1/wsi/tct/NILM/CX20174955-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167366-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006409-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006921-NILM',\n",
       " '/home1/wsi/tct/NILM/202000826',\n",
       " '/home1/wsi/tct/NILM/CX20166653-NILM',\n",
       " '/home1/wsi/tct/NILM/202000792',\n",
       " '/home1/wsi/tct/NILM/CX20166622-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018718-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171603-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171637-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018325-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176067-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005907-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152314-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20172447-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176082-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177881-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177868-NILM',\n",
       " '/home1/wsi/tct/NILM/202000773',\n",
       " '/home1/wsi/tct/NILM/CX20171649-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177879-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006411-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006003-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167359-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174995-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007711-NILM',\n",
       " '/home1/wsi/tct/NILM/202000775',\n",
       " '/home1/wsi/tct/NILM/xCY20005977-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152375-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006663-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005988-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007593-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018682-NILM',\n",
       " '/home1/wsi/tct/NILM/202000896-',\n",
       " '/home1/wsi/tct/NILM/CX20166615-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177063-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018298-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176057-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167400-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171641-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166699-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017909-NILM',\n",
       " '/home1/wsi/tct/NILM/202000772',\n",
       " '/home1/wsi/tct/NILM/xCY20007800-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018666-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018582-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175593-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176993-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166691-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018413-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018772-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018678-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152403-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166709-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174906-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20178937-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005969-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152301-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006702-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006820-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177890-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017783-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171655-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018346-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174981-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017805-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176069-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018656-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008035-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006897-NILM',\n",
       " '/home1/wsi/tct/NILM/202000916',\n",
       " '/home1/wsi/tct/NILM/xCY20006714-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175641-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180059-NILM',\n",
       " '/home1/wsi/tct/NILM/202000944',\n",
       " '/home1/wsi/tct/NILM/xCY20007715-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176977-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007728-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152350-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167389-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018124-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006944-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018130-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175627-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006579-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010686-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152368-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166619-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174944-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166667-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008039-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177865-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006949-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171596-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007762-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180026-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20017986-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177028-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166614-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006793-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20008066-NILM',\n",
       " '/home1/wsi/tct/NILM/202000797',\n",
       " '/home1/wsi/tct/NILM/CX20180949-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152318-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006578-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180013-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174949-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006876-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018373-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007612-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152382-NILM',\n",
       " '/home1/wsi/tct/NILM/202000907',\n",
       " '/home1/wsi/tct/NILM/xCY20006811-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005887-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176072-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177000-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174960-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177855-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166669-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010679-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018838-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175655-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176149-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20178926-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177021-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177891-NILM',\n",
       " '/home1/wsi/tct/NILM/202000832',\n",
       " '/home1/wsi/tct/NILM/xCR20018544-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018926-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006731-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174912-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166671-NILM',\n",
       " '/home1/wsi/tct/NILM/202000946',\n",
       " '/home1/wsi/tct/NILM/CX20177918-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010683-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018892-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005960-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175596-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010687-NILM',\n",
       " '/home1/wsi/tct/NILM/202000841',\n",
       " '/home1/wsi/tct/NILM/CX20174959-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176155-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005869-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007950-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176113-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006916-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005838-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166666-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005810-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007606-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006686-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167364-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006570-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166672-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010658-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176141-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005829-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179978-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177874-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166685-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005753-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018730-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177008-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179941-NILM',\n",
       " '/home1/wsi/tct/NILM/202000919',\n",
       " '/home1/wsi/tct/NILM/xCY20005821-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005971-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006664-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010735-NILM',\n",
       " '/home1/wsi/tct/NILM/202000943',\n",
       " '/home1/wsi/tct/NILM/CX20175642-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018510-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20179968-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005936-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177864-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176136-NILM',\n",
       " '/home1/wsi/tct/NILM/202000862',\n",
       " '/home1/wsi/tct/NILM/xCY20006810-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175609-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018629-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20169246-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010667-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018696-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005796-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175607-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20177841-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174988-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171593-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167385-NILM',\n",
       " '/home1/wsi/tct/NILM/202000929',\n",
       " '/home1/wsi/tct/NILM/CX20152404-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174980-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007839-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010673-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176076-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166632-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006678-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005842-NILM',\n",
       " '/home1/wsi/tct/NILM/202000788',\n",
       " '/home1/wsi/tct/NILM/202000785',\n",
       " '/home1/wsi/tct/NILM/xCY20010682-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018026-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018118-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171650-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175616-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171597-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010674-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005853-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005877-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005862-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018825-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20175617-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166697-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018824-NILM',\n",
       " '/home1/wsi/tct/NILM/202000847',\n",
       " '/home1/wsi/tct/NILM/CX20176967-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018643-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166655-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006720-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007960-NILM',\n",
       " '/home1/wsi/tct/NILM/202000950',\n",
       " '/home1/wsi/tct/NILM/CX20180941-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176052-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166706-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018703-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171636-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018511-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174979-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176106-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005875-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005989-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176145-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20167362-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018658-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166681-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166650-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20176102-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007725-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018290-NILM',\n",
       " '/home1/wsi/tct/NILM/202000819',\n",
       " '/home1/wsi/tct/NILM/202000790',\n",
       " '/home1/wsi/tct/NILM/CX20174887-NILM',\n",
       " '/home1/wsi/tct/NILM/202000887',\n",
       " '/home1/wsi/tct/NILM/CX20167397-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174998-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152319-NILM',\n",
       " '/home1/wsi/tct/NILM/202000914',\n",
       " '/home1/wsi/tct/NILM/xCY20006910-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180017-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171651-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180058-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166627-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006587-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018284-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018835-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20180033-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018618-NILM',\n",
       " '/home1/wsi/tct/NILM/202000954',\n",
       " '/home1/wsi/tct/NILM/202000891',\n",
       " '/home1/wsi/tct/NILM/xCY20006666-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20007818-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018637-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018991-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018254-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20152398-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20171627-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20174989-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166670-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20006907-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20010724-NILM',\n",
       " '/home1/wsi/tct/NILM/202000776',\n",
       " '/home1/wsi/tct/NILM/xCY20005913-NILM',\n",
       " '/home1/wsi/tct/NILM/CX20166688-NILM',\n",
       " '/home1/wsi/tct/NILM/xCY20005902-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018279-NILM',\n",
       " '/home1/wsi/tct/NILM/202000831',\n",
       " '/home1/wsi/tct/NILM/CX20171654-NILM',\n",
       " '/home1/wsi/tct/NILM/xCR20018566-NILM',\n",
       " ...]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "wsi_root = '/home1/wsi/tct/'\n",
    "sub_paths = [\n",
    "            'NILM',\n",
    "            'POS'\n",
    "        ]\n",
    "wsi_dirs = []\n",
    "for sub_path in sub_paths:\n",
    "    wsi_dirs.extend([os.path.join(wsi_root, sub_path, wsi_name) for wsi_name in os.listdir(os.path.join(wsi_root, sub_path))])\n",
    "# data_roots = list(map(lambda x: os.path.join(wsi_root, x), sub_paths))\n",
    "# data_roots\n",
    "# wsi_dirs = [os.path.join(wsi_root, sub_dir) for sub_dir in os.listdir(data_roots) ]\n",
    "wsi_dirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import glob\n",
    "\n",
    "train_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                          transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                          transforms.ToTensor()])\n",
    "    \n",
    "\n",
    "train_set = Whole_Slide_Patchs_Ngc(\n",
    "            data_dir='/home1/wsi/ngc-2023-1333/',\n",
    "            train_label_path='/home/huangjialong/projects/BiomedCLIP-PUNCE/datatools/ngc_labels/ngc_train_label.csv',\n",
    "            transform=train_transform\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]] tensor([[0.2765, 0.1852, 0.2274, 0.1506, 0.1602],\n",
      "        [0.2159, 0.1409, 0.1849, 0.2888, 0.1695],\n",
      "        [0.1244, 0.1427, 0.2141, 0.2983, 0.2204],\n",
      "        [0.1451, 0.2369, 0.2650, 0.2379, 0.1151],\n",
      "        [0.1354, 0.1046, 0.2688, 0.2269, 0.2644],\n",
      "        [0.2930, 0.1570, 0.2331, 0.1355, 0.1814],\n",
      "        [0.2257, 0.3268, 0.1634, 0.1427, 0.1414],\n",
      "        [0.2123, 0.1062, 0.2431, 0.2417, 0.1966],\n",
      "        [0.2173, 0.2060, 0.2000, 0.2304, 0.1462],\n",
      "        [0.1517, 0.2533, 0.1651, 0.2723, 0.1577]], dtype=torch.float64)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Only one class present in y_true. ROC AUC score is not defined in that case.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_37846/3189169087.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mroc_auc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label_one_hot\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mroc_auc_macro\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dist-pu/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    570\u001b[0m             \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m             \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m         )\n\u001b[1;32m    574\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# multilabel-indicator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dist-pu/lib/python3.7/site-packages/sklearn/metrics/_base.py\u001b[0m in \u001b[0;36m_average_binary_score\u001b[0;34m(binary_metric, y_true, y_score, average, sample_weight)\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbinary_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/dist-pu/lib/python3.7/site-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_roc_auc_score\u001b[0;34m(y_true, y_score, sample_weight, max_fpr)\u001b[0m\n\u001b[1;32m    336\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    337\u001b[0m         raise ValueError(\n\u001b[0;32m--> 338\u001b[0;31m             \u001b[0;34m\"Only one class present in y_true. ROC AUC score \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    339\u001b[0m             \u001b[0;34m\"is not defined in that case.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         )\n",
      "\u001b[0;31mValueError\u001b[0m: Only one class present in y_true. ROC AUC score is not defined in that case."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "n_classes = 5\n",
    "y_label = np.random.randint(0,n_classes, (10))\n",
    "y_pred = np.random.rand(10, n_classes)\n",
    "y_pred = torch.softmax(torch.tensor(y_pred), dim=1)\n",
    "y_label_one_hot = np.eye(n_classes)[y_label]\n",
    "print(y_label_one_hot, y_pred)\n",
    "roc_auc = dict()\n",
    "\n",
    "for i in range(n_classes):\n",
    "    roc_auc[i] = roc_auc_score(y_label_one_hot[:, i], y_pred[:, i])\n",
    "roc_auc = list(roc_auc.values())\n",
    "roc_auc_macro = np.mean(roc_auc)\n",
    "roc_auc_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 224, 224])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set[10][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "565720\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "root_dir = '/home1/wsi/ngc-2023-224/'\n",
    "sub_dirs = [\n",
    "    'Unannotated_KSJ/Unannotated-KSJ-TCTNGC-NILM',\n",
    "    'Unannotated_KSJ/Unannotated-KSJ-TCTNGC-POS',\n",
    "    'Unannotated_XIMEA/Unannotated-XIMEA-TCTNGC-NILM',\n",
    "    'Unannotated_XIMEA/Unannotated-XIMEA-TCTNGC-POS'\n",
    "]\n",
    "sum_wsi = 0\n",
    "for sub_dir in sub_dirs:\n",
    "    sub_dir_path = os.path.join(root_dir, sub_dir)\n",
    "    sum_wsi += len(os.listdir(sub_dir_path))\n",
    "sum_wsi\n",
    "sum_images = 0\n",
    "\n",
    "def count_fun(sub_dir):\n",
    "    sum_images = 0\n",
    "    input_dir_tmp = os.path.join(root_dir, sub_dir)\n",
    "    for root, dirs, files in os.walk(input_dir_tmp):\n",
    "        for filename in files:\n",
    "            if filename.endswith('.jpg') or filename.endswith('.png') or filename.endswith('.jpeg'):\n",
    "                sum_images += 1\n",
    "    return sum_images \n",
    "for sub_dir in sub_dirs:\n",
    "    sum_images += count_fun(sub_dir)\n",
    "print(sum_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch import tensor\n",
    "from torchmetrics.classification import BinarySpecificity\n",
    "target = tensor([0, 1, 0, 1, 0, 1])\n",
    "preds = tensor([0, 0, 1, 1, 0, 1])\n",
    "metric = BinarySpecificity()\n",
    "metric(preds, target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adapter': OrderedDict([('hide_layer.weight',\n",
       "               tensor([[ 0.0109, -0.0350,  0.0311,  ...,  0.0307,  0.0095,  0.0083],\n",
       "                       [-0.0034,  0.0327,  0.0025,  ..., -0.0300,  0.0202,  0.0268],\n",
       "                       [ 0.0229,  0.0451,  0.0338,  ...,  0.0130, -0.0130,  0.0236],\n",
       "                       ...,\n",
       "                       [-0.0213,  0.0386,  0.0194,  ..., -0.0484, -0.0293, -0.0139],\n",
       "                       [ 0.0197,  0.0509,  0.0287,  ..., -0.0375,  0.0119,  0.0043],\n",
       "                       [ 0.0115,  0.0238,  0.0194,  ...,  0.0040, -0.0067, -0.0480]],\n",
       "                      device='cuda:0')),\n",
       "              ('hide_layer.bias',\n",
       "               tensor([-0.2269,  0.2048,  0.1236,  0.0651,  0.0013,  0.0025,  0.1936,  0.0200,\n",
       "                        0.2058,  0.2394,  0.2005,  0.4795,  0.3440, -0.0141,  0.6812,  0.0355,\n",
       "                        0.5717, -0.5975,  0.0265, -0.0436, -0.1840, -0.1434,  0.1415, -0.0168,\n",
       "                       -0.2090,  0.0154,  0.0908,  0.0705, -0.1890,  0.5126, -0.1928,  0.2626,\n",
       "                        0.0113,  0.3986,  0.2094, -0.0591, -0.2312, -0.3872, -0.0144,  0.2650,\n",
       "                        0.0693, -0.1298, -0.0531,  0.0235,  0.1087, -0.2287,  0.1161,  0.1306,\n",
       "                        0.1457, -0.3340,  0.1522, -0.0369, -0.2120, -0.4814,  0.1612,  0.2128,\n",
       "                        0.0832,  0.1036,  0.2788, -0.0563, -0.4531, -0.2633,  0.0558,  0.2704,\n",
       "                       -0.3633,  0.0507, -0.3508, -0.3760, -0.0176, -0.1021, -0.3568, -0.1752,\n",
       "                        0.1245,  0.4145, -0.1757,  0.2691,  0.1051,  0.2463, -0.0182,  0.2083,\n",
       "                       -0.1582, -0.0884,  0.1760, -0.4594, -0.2763, -0.3737, -0.0862,  0.4208,\n",
       "                       -0.4323, -0.0222,  0.2747,  0.3981, -0.2772, -0.0369, -0.2640,  0.6869,\n",
       "                       -0.3667,  0.0197,  0.3617, -0.2209,  0.5264, -0.2027, -0.0075, -0.1217,\n",
       "                        0.1318,  0.2203,  0.0984, -0.1157,  0.2255, -0.1033,  0.2651, -0.0802,\n",
       "                        0.0296,  0.0707, -0.5421,  0.1179, -0.2282, -0.1173,  0.1497, -0.0624,\n",
       "                        0.1941, -0.1322, -0.1754,  0.0166,  0.1966,  0.3354,  0.0746, -0.0333,\n",
       "                        0.4619, -0.1859, -0.3292, -0.3565, -0.2024, -0.1192,  0.3430,  0.3034,\n",
       "                        0.0639, -0.3540, -0.0054,  0.3323,  0.0845,  0.3982, -0.1563,  0.0612,\n",
       "                        0.3903,  0.9396,  0.5902,  0.5811,  0.0223,  0.0028, -0.3297, -0.3580,\n",
       "                        0.1655, -0.2856,  0.4666, -0.1440,  0.0088, -0.2315, -0.1788,  0.2399,\n",
       "                       -0.2923,  0.0402,  0.1058,  0.3623, -0.0758,  0.4662,  0.0860,  0.8003,\n",
       "                       -0.2788,  0.3541, -0.0210,  0.0374, -0.3666,  0.2507, -0.3797,  0.0043,\n",
       "                       -0.2281, -0.8224, -0.1736,  0.2285,  0.2384, -0.4163, -0.0742, -0.1056,\n",
       "                       -0.0657, -0.0952,  0.2854, -0.1497,  0.2760,  0.2234, -0.1087, -0.2329,\n",
       "                        0.4587, -0.4567,  0.1523, -0.6213,  0.0477, -0.6065, -0.0673,  0.2349,\n",
       "                        0.0032,  0.1735,  0.3396, -0.0803,  0.3485, -0.0051,  0.4782, -0.0375,\n",
       "                       -0.5675,  0.0589, -0.1845, -0.3379,  0.1217, -0.0546,  0.5778,  0.1087,\n",
       "                       -0.0691,  0.5391,  0.3023,  0.2132, -0.0567,  0.7811, -0.4872,  0.6100,\n",
       "                       -0.1444,  0.4493, -0.1104,  0.0063, -0.3918, -0.1295,  0.0748, -0.0829,\n",
       "                       -0.2680, -0.0254,  0.2536,  0.2818,  0.2583,  0.0946, -0.5029, -0.1781,\n",
       "                        0.4593, -0.1316, -0.2107,  0.0117,  0.2376,  0.5711, -0.0815, -0.3324,\n",
       "                        0.4939,  0.3245,  0.0472,  0.0903,  0.1290,  0.5142,  0.1938,  0.1522,\n",
       "                        0.3270,  0.2809,  0.1220, -0.2182, -0.0668,  0.1894, -0.0716, -0.4396,\n",
       "                        0.1663, -0.1671,  0.0144,  0.0385,  0.0150, -0.1736, -0.1175, -0.5836,\n",
       "                       -0.2708, -0.3119,  0.1161, -0.1064, -0.1811, -0.2274, -0.0108, -0.2891,\n",
       "                        0.2244,  0.0542,  0.2477, -0.6498, -0.2817, -0.0585,  0.0395,  0.1392,\n",
       "                        0.4983, -0.1630, -0.2354, -0.0081,  0.0274, -0.1583,  0.0020,  0.4802,\n",
       "                        0.0230,  0.2770, -0.1400, -0.0157,  0.5189, -0.1199,  0.0190,  0.1366,\n",
       "                        0.1621,  0.2588, -0.3376, -0.4225,  0.0843,  0.1093,  0.5585, -0.3215,\n",
       "                        0.3545,  0.0761, -0.1998, -0.2854, -0.2995,  0.0615, -0.1016,  0.2463,\n",
       "                       -0.3563,  0.0596, -0.1932,  0.0418,  0.1075, -0.0057, -0.5165, -0.1357,\n",
       "                       -0.1910,  0.0992, -0.2330,  0.1906, -0.3124, -0.1056,  0.0060, -0.4374,\n",
       "                       -0.1837,  0.3391,  0.6745, -0.1972,  0.1070, -0.0888,  0.1992, -0.3762,\n",
       "                       -0.2623,  0.5184, -0.0256,  0.1372,  0.1878,  0.0744,  0.0663, -0.0699,\n",
       "                       -0.0826, -0.2583,  0.4387,  0.3041,  0.1807, -0.4288,  0.0693, -0.2645,\n",
       "                       -0.2894,  0.1126,  0.0961,  0.1002,  0.0756,  0.3180,  0.1088,  0.0215,\n",
       "                        0.5383, -0.5326,  0.2845, -0.2799, -0.4761,  0.4583, -0.0900, -0.1140,\n",
       "                       -0.3022, -0.0885, -0.0407, -0.2089, -0.0289, -0.1899,  0.0514, -0.3177,\n",
       "                       -0.4575, -0.0521,  0.1387,  0.3800, -0.0326, -0.0864,  0.0156,  0.1973,\n",
       "                       -0.7044,  0.0412, -0.1542,  0.2891, -0.1770, -0.2625, -0.0884, -0.0536,\n",
       "                       -0.3185,  0.1105, -0.2542,  0.3613,  0.0294, -0.2507, -0.2512,  0.2473,\n",
       "                        0.1659,  0.0827,  0.2904, -0.0322, -0.3003, -0.4083,  0.3434, -0.0357,\n",
       "                       -0.1626, -0.0378,  0.1634,  0.3323, -0.1051, -0.7092, -0.2208,  0.1961,\n",
       "                       -0.1371,  0.2236, -0.2635,  0.1897, -0.0382, -0.1176, -0.2170, -0.4185,\n",
       "                        0.1733, -0.0455,  0.0434,  0.0769, -0.1712,  0.2825, -0.2794, -0.0397,\n",
       "                        0.2314, -0.0999, -0.1710, -0.1840,  0.4951,  0.1137, -0.0351,  0.5067,\n",
       "                       -0.3249,  0.0232,  0.4402, -0.4521,  0.1085,  0.2530,  0.1988, -0.2003,\n",
       "                       -0.4291, -0.6581, -0.9080, -0.0604, -0.2161,  0.0160, -0.1562,  0.2735,\n",
       "                       -0.1837,  0.5959, -0.0527, -0.4692,  0.0795,  0.3432,  0.0339,  0.1346,\n",
       "                        0.0715, -0.1385, -0.0902,  0.0775,  0.1433, -0.0036,  0.1951,  0.0725,\n",
       "                       -0.3238,  0.1095, -0.1654, -0.0014,  0.2745,  0.2242, -0.0986,  0.2521,\n",
       "                       -0.1787,  0.1251, -0.3883, -0.1318,  0.3003,  0.1465,  0.1173, -0.3092,\n",
       "                       -0.1188, -0.4468, -0.3603,  0.0592,  0.0835,  0.2086,  0.2901,  0.0843,\n",
       "                        0.1136,  0.1666,  0.1529, -0.2756,  0.0332,  0.5293,  0.1529, -0.0862],\n",
       "                      device='cuda:0'))]),\n",
       " 'lr_sche': {'base_lrs': [0.6],\n",
       "  'last_epoch': 720,\n",
       "  '_step_count': 721,\n",
       "  'verbose': False,\n",
       "  '_get_lr_called_within_step': False,\n",
       "  '_last_lr': [0.3577875948049462],\n",
       "  'lr_lambdas': [None]},\n",
       " 'optimizer': {'state': {351: {'momentum_buffer': tensor([[-9.6155e-09, -4.9006e-07,  1.8814e-07,  ...,  3.2616e-07,\n",
       "              1.7614e-07,  8.7010e-08],\n",
       "            [-2.9472e-07,  3.4179e-07, -2.3733e-07,  ..., -4.2360e-07,\n",
       "              3.2304e-07,  3.7904e-07],\n",
       "            [ 4.3299e-07,  9.6216e-07,  7.1367e-07,  ...,  2.2082e-07,\n",
       "             -2.5709e-07,  4.3126e-07],\n",
       "            ...,\n",
       "            [-9.6058e-08,  4.6412e-07,  2.4750e-07,  ..., -3.6569e-07,\n",
       "             -3.1287e-07, -1.2151e-07],\n",
       "            [ 2.5308e-07,  7.5232e-07,  3.2036e-07,  ..., -2.9803e-07,\n",
       "              6.3135e-08,  7.5661e-08],\n",
       "            [ 1.1903e-07,  3.9151e-08,  2.9201e-07,  ...,  7.3205e-08,\n",
       "             -2.9050e-08, -4.8761e-07]], device='cuda:0')},\n",
       "   352: {'momentum_buffer': tensor([-7.6008e-07,  5.9048e-06,  5.4530e-07, -2.4583e-06,  1.6694e-06,\n",
       "            -6.4717e-07,  8.5348e-06, -5.0561e-06,  5.9507e-07,  2.2916e-06,\n",
       "             1.9506e-06,  4.6825e-06,  1.1100e-06, -3.9229e-06,  1.0176e-05,\n",
       "             9.8119e-07,  4.3748e-06, -8.4628e-06,  1.8967e-06, -2.6914e-06,\n",
       "            -3.1895e-06,  2.2926e-06,  5.3072e-06,  1.6075e-06, -1.9448e-06,\n",
       "            -8.0508e-08, -1.4245e-07, -9.2364e-07, -3.4997e-07,  6.0493e-06,\n",
       "            -2.4002e-06,  8.0998e-06, -4.8284e-07,  3.7855e-06,  3.6845e-06,\n",
       "             1.3616e-06, -1.6459e-06, -6.8433e-06, -6.9066e-07,  5.9602e-07,\n",
       "            -4.5503e-06,  3.5312e-06, -7.1978e-07,  1.8086e-06, -3.3674e-06,\n",
       "            -5.2062e-06,  2.3971e-06,  1.0893e-06, -2.1207e-06,  2.6373e-06,\n",
       "             6.6015e-06,  1.8940e-06, -6.9278e-06, -3.4608e-06,  4.7955e-06,\n",
       "             4.4937e-07, -2.9908e-06, -8.4022e-07,  4.8860e-06, -3.0405e-06,\n",
       "            -5.9551e-06,  7.9072e-07,  3.1547e-06,  3.9513e-06, -6.6117e-06,\n",
       "            -1.5609e-06, -3.6434e-06, -6.9248e-06,  2.8475e-06,  4.4561e-07,\n",
       "            -1.4068e-06,  1.3815e-06, -1.9796e-06,  2.9835e-06, -6.9674e-06,\n",
       "             6.0633e-06,  2.9264e-06,  2.6556e-06, -1.0190e-06,  3.0707e-06,\n",
       "            -6.3505e-06, -4.2636e-06,  2.3937e-07, -1.3421e-06, -2.3514e-06,\n",
       "            -3.4034e-06,  3.7929e-06,  3.4684e-06, -5.7002e-06, -2.7330e-06,\n",
       "             2.9402e-06,  3.0663e-06, -3.4841e-06,  6.7887e-07, -3.5868e-06,\n",
       "             8.5973e-06, -2.7025e-06,  2.2203e-06,  3.5336e-06,  9.2189e-07,\n",
       "             9.1695e-06,  1.9150e-07,  2.2168e-06,  1.5881e-06,  2.1761e-06,\n",
       "             1.6084e-06,  2.4624e-06,  1.6839e-06,  1.4202e-06, -8.1408e-07,\n",
       "             4.6973e-06, -1.9213e-06, -3.5128e-08, -6.4682e-07, -5.3371e-06,\n",
       "            -1.0090e-06,  1.4102e-07, -6.3531e-06,  1.7898e-06,  4.4881e-06,\n",
       "             3.5418e-06, -1.3405e-06, -3.5922e-06,  4.5245e-06,  5.7384e-07,\n",
       "             4.7120e-06,  1.4462e-06, -3.2853e-06,  5.1975e-06, -3.6343e-06,\n",
       "            -4.7691e-06, -3.3722e-06, -3.5433e-06, -2.5440e-07,  2.4818e-06,\n",
       "             3.4769e-06, -1.9233e-06, -3.3880e-06,  1.1895e-06,  4.3176e-06,\n",
       "             2.2100e-06,  3.5951e-06,  1.9883e-06, -2.2948e-07,  2.8880e-06,\n",
       "             1.4970e-05,  6.8282e-06,  9.1724e-06,  1.0916e-06, -4.1615e-06,\n",
       "            -6.7305e-06, -2.1152e-06,  5.9995e-07, -5.7517e-06,  7.5708e-06,\n",
       "             1.4914e-08, -2.1415e-07,  1.0840e-07, -7.6903e-07,  6.7795e-06,\n",
       "            -3.1556e-06, -3.1928e-07,  5.0433e-07,  4.4296e-06, -5.7160e-06,\n",
       "             3.1871e-06,  1.5453e-06,  7.8120e-06,  4.7727e-07,  5.1652e-06,\n",
       "             3.4633e-06,  2.9999e-06, -1.6317e-06, -1.6575e-06, -2.6933e-07,\n",
       "             9.3962e-07, -6.5393e-06, -9.3635e-06, -2.0556e-08,  5.0062e-06,\n",
       "             4.1020e-06, -7.1038e-06, -3.1984e-06, -3.0634e-06, -3.6426e-06,\n",
       "             1.3395e-06, -2.9781e-08, -4.7358e-08,  3.7664e-06,  6.4053e-07,\n",
       "            -2.5546e-06, -2.0324e-06,  4.8552e-06, -4.7506e-06,  2.1353e-06,\n",
       "            -8.6043e-06,  2.5424e-06, -5.7797e-06,  2.7140e-06,  7.0291e-06,\n",
       "             1.8500e-06, -1.2584e-06,  7.5110e-06,  2.1589e-06,  7.0872e-07,\n",
       "             2.6555e-06,  4.2371e-06,  2.0595e-06, -6.3425e-06,  2.3240e-06,\n",
       "             6.0419e-07, -3.5323e-06,  4.7454e-06,  2.0728e-06,  6.1493e-06,\n",
       "            -2.7682e-06,  2.9348e-07,  8.9880e-06,  7.3193e-06,  4.5633e-06,\n",
       "             4.6197e-06,  1.1701e-05, -6.2452e-06,  1.0312e-05,  2.6428e-06,\n",
       "             1.9517e-06,  6.4264e-07,  4.3357e-06, -6.0062e-06, -1.7539e-06,\n",
       "             1.2734e-06, -4.6734e-06, -5.0530e-06,  1.9002e-06,  7.9796e-07,\n",
       "             6.2478e-06,  7.2592e-06,  2.3641e-06, -3.2862e-06, -2.1832e-06,\n",
       "             8.8903e-06,  3.5509e-06, -3.3993e-06,  7.3519e-07,  1.6286e-06,\n",
       "             6.0808e-06, -4.6233e-06, -5.0541e-06,  3.7770e-06,  6.5285e-06,\n",
       "            -1.4377e-06,  3.6904e-06,  5.6386e-07,  2.7840e-06,  2.5336e-06,\n",
       "            -2.2153e-06,  3.4871e-06,  1.4737e-06,  4.5675e-06,  3.4417e-07,\n",
       "            -3.2799e-06,  1.9502e-06, -3.6492e-06, -3.7302e-06,  2.1621e-08,\n",
       "            -4.6698e-06, -1.3314e-06,  1.4567e-06, -9.1943e-07, -6.3985e-06,\n",
       "            -2.1769e-06, -5.3112e-06, -7.3496e-06, -4.7379e-06,  2.6338e-06,\n",
       "            -3.3253e-06,  3.6400e-07, -1.1381e-06,  1.6778e-06, -5.2520e-06,\n",
       "            -1.7061e-07, -1.4496e-06,  3.6420e-06, -6.0478e-06,  3.4797e-08,\n",
       "            -2.8460e-06, -3.9675e-07,  1.8639e-06,  6.5438e-06, -6.0831e-07,\n",
       "            -5.1760e-06, -2.1598e-06,  9.1578e-07, -7.6533e-06, -3.1469e-06,\n",
       "             3.4540e-06, -3.8514e-06,  5.4553e-06,  1.5422e-06,  2.1407e-06,\n",
       "             8.0088e-06, -2.4148e-06, -2.5428e-06, -1.1682e-06,  3.0035e-06,\n",
       "             7.3402e-06, -4.3298e-06, -9.3881e-07,  2.6595e-07, -2.1520e-06,\n",
       "             4.0104e-06, -3.7041e-06,  4.1620e-06,  2.1043e-06, -1.9007e-07,\n",
       "             6.2629e-07,  4.0723e-08, -8.8370e-07, -4.6335e-06,  3.4988e-06,\n",
       "            -3.0914e-06,  4.9139e-06, -3.1736e-06,  1.6094e-07,  4.1495e-06,\n",
       "             2.0015e-06, -7.1088e-06, -1.0669e-07, -5.3516e-06,  7.2457e-07,\n",
       "            -2.8017e-06,  1.1062e-06, -4.6876e-06, -3.8326e-06, -4.2160e-07,\n",
       "            -3.1107e-06, -1.1157e-06,  9.6945e-07,  5.9225e-06, -4.7119e-06,\n",
       "             1.6687e-07,  2.0418e-06,  2.1288e-06, -6.1535e-06, -2.3606e-06,\n",
       "             8.4275e-06, -3.4604e-06,  2.8272e-06,  5.8944e-06, -1.8135e-07,\n",
       "            -3.4150e-07, -8.2768e-07, -1.1742e-06, -1.9140e-06,  1.5724e-06,\n",
       "             2.0343e-06,  2.1039e-06, -1.7232e-06,  2.9145e-06, -2.5550e-06,\n",
       "            -9.1941e-08,  2.3694e-06, -3.0501e-06, -1.8833e-06,  2.8928e-06,\n",
       "             3.6550e-06, -2.8533e-06,  2.7766e-06,  4.3468e-06, -6.2844e-06,\n",
       "            -1.8384e-06, -4.7717e-06, -2.2528e-06,  6.7317e-06, -8.8959e-08,\n",
       "            -3.0363e-06, -4.7702e-06, -6.6862e-06, -2.2332e-06,  4.7792e-07,\n",
       "            -8.1532e-07, -1.7376e-06, -1.6413e-06, -3.1116e-07, -5.7762e-06,\n",
       "            -1.0782e-06, -3.5583e-07,  7.3294e-06, -4.7583e-06,  1.0531e-06,\n",
       "             1.2096e-06,  1.4508e-07, -8.6479e-06, -9.9205e-07,  6.8804e-07,\n",
       "             6.6739e-06, -5.5356e-06, -5.3755e-06, -3.1895e-06, -4.0532e-06,\n",
       "            -1.0290e-06, -2.0770e-06, -5.3049e-07,  5.8632e-06,  2.6322e-06,\n",
       "            -1.2827e-06, -2.2446e-08,  3.3299e-06,  1.2559e-06, -1.0012e-06,\n",
       "             4.6082e-06,  1.9657e-06, -6.0642e-07, -5.0561e-06,  2.7241e-06,\n",
       "            -3.4427e-07,  2.2425e-06, -3.7431e-06, -1.0227e-06,  3.4046e-06,\n",
       "            -1.5569e-06, -4.9014e-06, -5.0192e-06, -3.1845e-06, -2.4987e-06,\n",
       "             8.0366e-06, -5.3666e-08,  5.4806e-06, -3.9022e-06, -3.8503e-06,\n",
       "            -6.5902e-06, -7.3327e-06,  2.0505e-07, -3.7454e-06,  2.3489e-06,\n",
       "             2.1565e-06, -5.4152e-06,  4.1769e-06, -9.8960e-07,  3.4052e-06,\n",
       "            -1.2887e-06,  7.6108e-07,  4.5118e-07, -6.0467e-06,  6.1286e-06,\n",
       "            -1.5893e-06,  3.1255e-06,  4.6877e-06, -7.3313e-06, -1.4661e-06,\n",
       "             3.0313e-06, -6.4045e-06,  2.8474e-06,  5.3901e-06,  3.9750e-06,\n",
       "             1.5468e-06, -5.4750e-06, -5.2270e-06, -1.0931e-05, -7.7998e-07,\n",
       "            -1.2434e-07, -2.0821e-06,  1.9258e-06,  4.9469e-06, -3.9585e-06,\n",
       "             7.7629e-06, -2.8580e-06, -4.2921e-06, -2.3915e-06,  6.0847e-08,\n",
       "             1.8817e-06, -4.8872e-06, -1.3248e-06, -1.4681e-07,  6.2234e-07,\n",
       "            -6.2560e-07,  2.4328e-06, -2.9552e-06, -9.1811e-07,  1.1423e-06,\n",
       "            -6.9639e-06, -1.5875e-07, -3.5608e-06, -3.9946e-06,  3.9782e-06,\n",
       "            -1.3460e-06, -3.7180e-06, -4.4715e-07, -1.9630e-06,  1.3265e-06,\n",
       "            -3.3734e-06,  4.4849e-07,  5.2785e-06, -2.4974e-06, -3.2397e-07,\n",
       "            -2.6129e-06,  1.0865e-06, -4.0219e-06, -5.3101e-06, -2.0626e-06,\n",
       "            -2.2097e-06,  3.7169e-06,  2.5463e-06,  1.4776e-06,  3.3902e-06,\n",
       "             1.3903e-07,  3.4740e-07, -1.3172e-06, -2.4098e-06,  4.4218e-06,\n",
       "             7.5733e-07, -1.0018e-06], device='cuda:0')},\n",
       "   353: {'momentum_buffer': tensor([[ 1.8682e-07, -2.4838e-07, -6.1031e-08,  ...,  3.7119e-07,\n",
       "              1.0426e-07, -3.9150e-07],\n",
       "            [ 8.0019e-08,  2.0378e-08, -4.0528e-07,  ...,  1.0908e-07,\n",
       "              9.6613e-08, -1.9922e-07],\n",
       "            [-5.7717e-09,  2.6733e-07, -3.0715e-08,  ..., -9.3168e-08,\n",
       "              1.5994e-07,  1.4856e-07],\n",
       "            ...,\n",
       "            [ 7.4868e-08, -2.5185e-07,  4.5576e-07,  ..., -3.7247e-07,\n",
       "              1.1822e-07, -1.8940e-07],\n",
       "            [-2.9589e-07,  3.7910e-07, -6.7590e-09,  ..., -1.6961e-08,\n",
       "              1.0763e-07,  1.0182e-07],\n",
       "            [-4.8978e-08,  2.4676e-07, -6.5788e-08,  ...,  2.8424e-07,\n",
       "              3.9850e-08, -3.6813e-07]], device='cuda:0')},\n",
       "   354: {'momentum_buffer': tensor([-3.0978e-07, -3.3691e-07,  1.1533e-06,  ..., -1.6448e-06,\n",
       "            -1.4250e-07, -1.6622e-07], device='cuda:0')},\n",
       "   355: {'momentum_buffer': tensor([[-3.3370e-08, -1.5027e-07, -1.1363e-07,  ..., -1.6524e-07,\n",
       "             -2.0677e-07,  6.0969e-08],\n",
       "            [ 2.7100e-08,  1.4794e-07, -1.7601e-07,  ...,  2.6722e-07,\n",
       "              1.7144e-07, -2.1951e-07],\n",
       "            [-2.9313e-08,  2.1718e-07,  1.2616e-07,  ..., -2.2863e-07,\n",
       "              8.9807e-08, -1.1935e-08],\n",
       "            ...,\n",
       "            [-5.2214e-08, -1.6676e-07, -6.4208e-08,  ..., -2.8322e-07,\n",
       "             -7.0713e-08, -8.3351e-08],\n",
       "            [ 2.0163e-07, -1.2029e-07,  8.1068e-08,  ..., -4.2234e-08,\n",
       "             -5.8201e-08, -1.8612e-07],\n",
       "            [-1.3937e-07, -1.5947e-07, -1.3008e-07,  ...,  8.4420e-08,\n",
       "             -8.6712e-08, -8.9216e-08]], device='cuda:0')},\n",
       "   356: {'momentum_buffer': tensor([-1.0787e-06,  5.2928e-06, -7.4958e-07,  5.9312e-06, -1.5526e-05,\n",
       "            -5.2728e-06,  3.8678e-06,  2.6160e-06,  6.2619e-06, -7.8762e-06,\n",
       "            -6.4304e-06, -5.9696e-06, -1.8634e-05, -1.2813e-06,  1.3966e-05,\n",
       "            -4.8672e-06,  1.3159e-06,  9.9486e-06,  6.2850e-06, -9.8916e-07,\n",
       "             1.1588e-05, -4.3230e-06, -1.3755e-06,  6.6957e-06,  8.6027e-06,\n",
       "            -5.4715e-07,  4.8098e-06, -1.0594e-05, -5.2943e-06,  4.5831e-06,\n",
       "             7.9629e-06, -2.7648e-06,  1.1292e-06, -3.3132e-06,  1.0069e-05,\n",
       "            -4.6048e-06,  1.7684e-05, -5.5786e-06,  1.4202e-06, -5.4161e-06,\n",
       "            -4.7960e-06,  2.1695e-05,  1.6349e-06,  3.4062e-06,  2.6740e-06,\n",
       "             1.0078e-06, -6.7934e-06, -1.2109e-05,  1.0194e-05,  6.2992e-07,\n",
       "            -1.5497e-05,  1.1247e-06, -3.8619e-06,  6.3873e-06, -9.3508e-06,\n",
       "            -2.2900e-05,  3.0900e-06, -2.9870e-06,  1.3700e-05,  4.2026e-06,\n",
       "             4.4436e-06,  5.7986e-06,  4.2972e-07,  1.5062e-05,  2.2856e-06,\n",
       "             8.1559e-06, -8.8612e-07, -4.7615e-07,  1.1602e-05,  2.1115e-06,\n",
       "            -4.5820e-06,  5.7036e-06, -5.1210e-06,  8.0492e-06, -4.2385e-06,\n",
       "             5.9207e-06,  1.8879e-06, -9.0157e-06,  3.2061e-06, -1.0095e-05,\n",
       "             1.8855e-06,  2.3978e-07, -1.0326e-05,  8.2816e-07,  1.2008e-05,\n",
       "             1.2306e-05, -1.0976e-05, -4.1993e-07, -3.1410e-06, -4.1804e-06,\n",
       "            -1.6988e-06, -3.8913e-07,  3.3124e-06, -3.6225e-06, -4.8255e-06,\n",
       "             2.7020e-06, -1.0241e-05,  6.5678e-07, -2.1395e-06, -4.4097e-06,\n",
       "             7.8967e-06, -4.4764e-06, -1.2016e-07, -1.4518e-05, -1.5312e-05,\n",
       "             4.9223e-07, -5.7083e-06,  9.4631e-07,  5.0419e-06, -8.5377e-06,\n",
       "             7.3743e-06,  1.6935e-05,  2.9475e-06,  1.6657e-05, -8.6107e-07,\n",
       "            -6.0739e-06,  9.0163e-06,  3.2233e-06, -1.4294e-05,  2.0278e-06,\n",
       "             8.7888e-07, -4.4224e-06, -7.0647e-06, -5.6324e-07, -6.8184e-06,\n",
       "             2.9149e-06,  5.1755e-06,  3.2559e-06, -6.7870e-08,  3.7718e-06,\n",
       "             5.0778e-06, -2.9319e-06, -8.4772e-06,  9.0846e-06,  1.7934e-06,\n",
       "            -1.4598e-06,  1.3822e-06,  7.8343e-06,  3.3752e-07, -9.2279e-06,\n",
       "            -1.8554e-05,  5.4738e-06,  1.8859e-05,  1.3500e-06, -7.6393e-06,\n",
       "             1.6934e-06, -1.2209e-06,  2.3661e-06,  1.1980e-06,  1.0477e-05,\n",
       "            -2.7079e-06, -2.4521e-06, -8.9437e-06, -2.8485e-06,  1.8071e-06,\n",
       "            -1.4329e-05, -3.4364e-06, -8.0408e-06, -8.1218e-06, -9.9431e-06,\n",
       "             2.5025e-06, -5.7271e-07, -1.0895e-05, -8.2655e-06, -2.6788e-06,\n",
       "             6.6394e-06,  3.6817e-06, -3.5009e-06,  3.7094e-06, -1.3004e-06,\n",
       "            -6.9370e-06, -3.1459e-06, -9.4067e-06,  6.1614e-06, -5.3091e-06,\n",
       "             4.7028e-06,  8.2699e-06,  7.7594e-06, -3.6323e-06, -1.9660e-06,\n",
       "             4.7628e-06,  1.1323e-05, -6.0056e-06, -1.8994e-05, -1.4889e-05,\n",
       "             8.9961e-06,  9.8393e-06,  6.9020e-06, -2.5642e-06,  8.7922e-06,\n",
       "             2.0542e-06,  3.5980e-06,  5.0155e-06,  1.1775e-06,  1.1124e-05,\n",
       "             6.4977e-06,  4.7355e-06, -8.9062e-06, -5.4684e-06, -1.4531e-06,\n",
       "             2.3988e-06,  1.4490e-05,  5.8319e-06, -2.9420e-06, -1.0844e-05,\n",
       "            -5.7212e-06,  1.1078e-05, -5.2275e-06, -8.6422e-06,  9.1078e-06,\n",
       "             4.2311e-06, -3.3225e-07, -1.3879e-06, -3.3806e-06, -4.4124e-06,\n",
       "             1.2762e-05,  2.1009e-06,  4.5813e-06, -3.6798e-06,  8.2804e-06,\n",
       "             1.2216e-05, -1.1645e-06,  7.9311e-06, -9.8307e-06,  3.9869e-06,\n",
       "            -7.2992e-06, -4.4291e-06, -3.6974e-06, -2.7092e-06,  1.7342e-06,\n",
       "            -3.9747e-06, -8.0517e-06, -4.5569e-06,  4.1082e-07, -5.8622e-06,\n",
       "             2.0560e-05,  3.6480e-06, -1.2702e-05,  5.4339e-06, -7.9128e-06,\n",
       "            -1.2308e-06,  8.0075e-07, -1.4202e-07,  7.6291e-07,  6.9461e-06,\n",
       "            -3.3357e-06,  1.4233e-06, -5.1500e-06, -1.6773e-06,  3.4228e-06,\n",
       "             3.1603e-06,  9.8451e-06,  8.8220e-06,  2.7818e-06, -1.4235e-05,\n",
       "            -2.2666e-05,  1.1585e-06, -1.7807e-06, -1.4905e-06,  7.6472e-06,\n",
       "            -7.1535e-06,  6.5113e-06,  3.7936e-06, -2.3040e-06, -4.0355e-06,\n",
       "             7.1557e-06,  1.4224e-05, -7.5020e-06, -2.4980e-06, -1.6735e-06,\n",
       "             4.2296e-06,  4.3480e-06,  1.6344e-05,  1.5448e-06,  5.4865e-06,\n",
       "             1.0184e-06, -7.0643e-06,  3.2230e-06, -1.4136e-06, -5.0929e-06,\n",
       "            -5.8075e-06,  6.4117e-06,  7.1238e-06,  3.1840e-06, -2.9807e-06,\n",
       "             1.4733e-05,  5.7235e-06,  5.4695e-06, -1.4433e-06,  1.6711e-05,\n",
       "             6.1628e-06, -8.3212e-06, -8.0003e-07,  3.0228e-06,  2.2227e-06,\n",
       "            -8.7905e-06, -7.1488e-06, -3.5683e-06,  4.0359e-06,  4.1693e-06,\n",
       "             4.1442e-06,  3.4662e-06,  3.8421e-06,  1.0115e-06,  1.0821e-07,\n",
       "             1.5604e-06,  2.0007e-06,  6.7798e-06, -1.3567e-05,  9.5207e-06,\n",
       "            -1.7085e-05,  4.3418e-06,  6.3985e-06, -3.7475e-06, -6.8600e-06,\n",
       "             1.0944e-05,  8.8468e-07, -2.6537e-06, -4.1379e-06, -1.7064e-05,\n",
       "            -3.9934e-06, -3.7698e-06, -9.0733e-06, -2.2672e-06,  5.4232e-07,\n",
       "             3.5313e-06,  4.9700e-06,  1.1063e-05,  1.3542e-06, -9.9595e-06,\n",
       "             2.0778e-06,  8.4930e-06,  3.6456e-07,  5.4646e-06,  7.4509e-06,\n",
       "            -1.6434e-06, -1.0091e-05, -8.7795e-06,  5.3057e-06, -6.1342e-07,\n",
       "            -1.1756e-06,  5.2484e-07, -7.1081e-06, -4.2018e-06,  7.6957e-06,\n",
       "            -3.3529e-07,  3.6174e-06, -5.0265e-07, -5.6485e-06, -8.2686e-06,\n",
       "            -3.6755e-06, -3.9584e-06,  1.1722e-05, -1.0179e-06,  9.0109e-06,\n",
       "            -4.0699e-06, -8.1199e-06, -4.1629e-06, -1.4737e-05, -1.8503e-05,\n",
       "             1.0233e-05, -4.4656e-06,  2.7867e-05,  2.0859e-05, -3.0082e-06,\n",
       "             3.9790e-06, -1.2906e-05, -3.9665e-06,  1.0277e-05,  9.0393e-06,\n",
       "            -4.7281e-06, -1.0850e-05, -1.3427e-05,  3.0368e-06,  7.5913e-06,\n",
       "             4.8051e-06, -3.6199e-06, -2.8859e-06, -4.0704e-06,  5.5464e-06,\n",
       "             1.4220e-07, -3.1007e-06,  3.4392e-06,  3.0169e-06, -3.4854e-06,\n",
       "             1.3799e-06,  7.9487e-06, -7.1429e-06,  2.3579e-06,  1.3294e-05,\n",
       "            -8.8370e-07,  4.2712e-06,  1.0232e-06, -3.6499e-06,  1.2813e-05,\n",
       "             4.0988e-06, -1.1060e-05,  1.3025e-05, -1.9920e-07, -1.0763e-05,\n",
       "             1.8205e-06, -2.0607e-07, -1.4731e-05, -5.7061e-06, -7.8014e-06,\n",
       "            -3.7690e-07, -1.0903e-05,  3.8853e-06,  1.0850e-05,  4.9666e-06,\n",
       "             1.2800e-05, -8.1124e-06, -4.4181e-07,  2.1231e-06,  7.2964e-06,\n",
       "            -2.2014e-05,  1.6133e-05, -1.5132e-06, -1.0946e-05, -6.2026e-06,\n",
       "            -5.2783e-06, -2.6983e-06,  4.8361e-06,  5.1940e-06, -5.5868e-06,\n",
       "            -1.2174e-05,  1.4202e-06, -7.4152e-06,  5.3522e-06,  3.5013e-06,\n",
       "             2.0464e-06, -1.8424e-07,  1.8192e-06, -3.2873e-07,  3.9842e-06,\n",
       "             5.1870e-06, -6.5482e-06, -5.9920e-06, -1.4668e-06, -7.4568e-06,\n",
       "            -8.7148e-06,  1.1281e-05,  1.4896e-06, -2.7914e-07, -8.4009e-06,\n",
       "            -4.4897e-06,  4.8395e-06,  4.3775e-06, -1.8849e-06, -3.9381e-06,\n",
       "            -7.6185e-06,  4.3167e-06,  5.5087e-06, -1.3023e-05, -1.4001e-05,\n",
       "            -4.0553e-06,  4.8849e-06,  7.1600e-06, -2.3994e-06, -1.7329e-06,\n",
       "             7.7480e-06,  1.3245e-05,  4.3970e-06,  5.2047e-06,  2.0687e-06,\n",
       "            -3.7157e-06, -1.4113e-06,  7.1085e-06, -6.0202e-06,  7.8884e-06,\n",
       "            -7.1582e-06,  1.4337e-06,  9.2350e-06,  7.5637e-06, -1.4116e-05,\n",
       "            -4.9150e-06, -6.6590e-06,  1.0753e-05,  2.0287e-05, -8.1850e-06,\n",
       "             8.2844e-06,  1.2616e-05,  8.1923e-06, -4.9361e-07, -8.9829e-06,\n",
       "            -3.3409e-08, -7.3661e-06, -1.5790e-06,  5.2180e-06,  1.6992e-05,\n",
       "             7.3814e-06,  2.8484e-06, -1.1774e-05, -4.4020e-06, -4.9768e-06,\n",
       "            -3.6578e-06, -9.1368e-08, -4.0784e-06,  3.7569e-06, -3.2920e-06,\n",
       "            -8.3372e-06,  4.4597e-06,  8.1395e-06,  1.4309e-05, -1.4801e-05,\n",
       "             3.9550e-06, -4.4037e-06,  9.2773e-06, -5.2197e-06, -7.1451e-06,\n",
       "             3.2893e-06,  8.8344e-06], device='cuda:0')}},\n",
       "  'param_groups': [{'lr': 0.3577875948049462,\n",
       "    'momentum': 0.9,\n",
       "    'dampening': 0,\n",
       "    'weight_decay': 1e-06,\n",
       "    'nesterov': True,\n",
       "    'maximize': False,\n",
       "    'foreach': None,\n",
       "    'initial_lr': 0.6,\n",
       "    'params': [0,\n",
       "     1,\n",
       "     2,\n",
       "     3,\n",
       "     4,\n",
       "     5,\n",
       "     6,\n",
       "     7,\n",
       "     8,\n",
       "     9,\n",
       "     10,\n",
       "     11,\n",
       "     12,\n",
       "     13,\n",
       "     14,\n",
       "     15,\n",
       "     16,\n",
       "     17,\n",
       "     18,\n",
       "     19,\n",
       "     20,\n",
       "     21,\n",
       "     22,\n",
       "     23,\n",
       "     24,\n",
       "     25,\n",
       "     26,\n",
       "     27,\n",
       "     28,\n",
       "     29,\n",
       "     30,\n",
       "     31,\n",
       "     32,\n",
       "     33,\n",
       "     34,\n",
       "     35,\n",
       "     36,\n",
       "     37,\n",
       "     38,\n",
       "     39,\n",
       "     40,\n",
       "     41,\n",
       "     42,\n",
       "     43,\n",
       "     44,\n",
       "     45,\n",
       "     46,\n",
       "     47,\n",
       "     48,\n",
       "     49,\n",
       "     50,\n",
       "     51,\n",
       "     52,\n",
       "     53,\n",
       "     54,\n",
       "     55,\n",
       "     56,\n",
       "     57,\n",
       "     58,\n",
       "     59,\n",
       "     60,\n",
       "     61,\n",
       "     62,\n",
       "     63,\n",
       "     64,\n",
       "     65,\n",
       "     66,\n",
       "     67,\n",
       "     68,\n",
       "     69,\n",
       "     70,\n",
       "     71,\n",
       "     72,\n",
       "     73,\n",
       "     74,\n",
       "     75,\n",
       "     76,\n",
       "     77,\n",
       "     78,\n",
       "     79,\n",
       "     80,\n",
       "     81,\n",
       "     82,\n",
       "     83,\n",
       "     84,\n",
       "     85,\n",
       "     86,\n",
       "     87,\n",
       "     88,\n",
       "     89,\n",
       "     90,\n",
       "     91,\n",
       "     92,\n",
       "     93,\n",
       "     94,\n",
       "     95,\n",
       "     96,\n",
       "     97,\n",
       "     98,\n",
       "     99,\n",
       "     100,\n",
       "     101,\n",
       "     102,\n",
       "     103,\n",
       "     104,\n",
       "     105,\n",
       "     106,\n",
       "     107,\n",
       "     108,\n",
       "     109,\n",
       "     110,\n",
       "     111,\n",
       "     112,\n",
       "     113,\n",
       "     114,\n",
       "     115,\n",
       "     116,\n",
       "     117,\n",
       "     118,\n",
       "     119,\n",
       "     120,\n",
       "     121,\n",
       "     122,\n",
       "     123,\n",
       "     124,\n",
       "     125,\n",
       "     126,\n",
       "     127,\n",
       "     128,\n",
       "     129,\n",
       "     130,\n",
       "     131,\n",
       "     132,\n",
       "     133,\n",
       "     134,\n",
       "     135,\n",
       "     136,\n",
       "     137,\n",
       "     138,\n",
       "     139,\n",
       "     140,\n",
       "     141,\n",
       "     142,\n",
       "     143,\n",
       "     144,\n",
       "     145,\n",
       "     146,\n",
       "     147,\n",
       "     148,\n",
       "     149,\n",
       "     150,\n",
       "     151,\n",
       "     152,\n",
       "     153,\n",
       "     154,\n",
       "     155,\n",
       "     156,\n",
       "     157,\n",
       "     158,\n",
       "     159,\n",
       "     160,\n",
       "     161,\n",
       "     162,\n",
       "     163,\n",
       "     164,\n",
       "     165,\n",
       "     166,\n",
       "     167,\n",
       "     168,\n",
       "     169,\n",
       "     170,\n",
       "     171,\n",
       "     172,\n",
       "     173,\n",
       "     174,\n",
       "     175,\n",
       "     176,\n",
       "     177,\n",
       "     178,\n",
       "     179,\n",
       "     180,\n",
       "     181,\n",
       "     182,\n",
       "     183,\n",
       "     184,\n",
       "     185,\n",
       "     186,\n",
       "     187,\n",
       "     188,\n",
       "     189,\n",
       "     190,\n",
       "     191,\n",
       "     192,\n",
       "     193,\n",
       "     194,\n",
       "     195,\n",
       "     196,\n",
       "     197,\n",
       "     198,\n",
       "     199,\n",
       "     200,\n",
       "     201,\n",
       "     202,\n",
       "     203,\n",
       "     204,\n",
       "     205,\n",
       "     206,\n",
       "     207,\n",
       "     208,\n",
       "     209,\n",
       "     210,\n",
       "     211,\n",
       "     212,\n",
       "     213,\n",
       "     214,\n",
       "     215,\n",
       "     216,\n",
       "     217,\n",
       "     218,\n",
       "     219,\n",
       "     220,\n",
       "     221,\n",
       "     222,\n",
       "     223,\n",
       "     224,\n",
       "     225,\n",
       "     226,\n",
       "     227,\n",
       "     228,\n",
       "     229,\n",
       "     230,\n",
       "     231,\n",
       "     232,\n",
       "     233,\n",
       "     234,\n",
       "     235,\n",
       "     236,\n",
       "     237,\n",
       "     238,\n",
       "     239,\n",
       "     240,\n",
       "     241,\n",
       "     242,\n",
       "     243,\n",
       "     244,\n",
       "     245,\n",
       "     246,\n",
       "     247,\n",
       "     248,\n",
       "     249,\n",
       "     250,\n",
       "     251,\n",
       "     252,\n",
       "     253,\n",
       "     254,\n",
       "     255,\n",
       "     256,\n",
       "     257,\n",
       "     258,\n",
       "     259,\n",
       "     260,\n",
       "     261,\n",
       "     262,\n",
       "     263,\n",
       "     264,\n",
       "     265,\n",
       "     266,\n",
       "     267,\n",
       "     268,\n",
       "     269,\n",
       "     270,\n",
       "     271,\n",
       "     272,\n",
       "     273,\n",
       "     274,\n",
       "     275,\n",
       "     276,\n",
       "     277,\n",
       "     278,\n",
       "     279,\n",
       "     280,\n",
       "     281,\n",
       "     282,\n",
       "     283,\n",
       "     284,\n",
       "     285,\n",
       "     286,\n",
       "     287,\n",
       "     288,\n",
       "     289,\n",
       "     290,\n",
       "     291,\n",
       "     292,\n",
       "     293,\n",
       "     294,\n",
       "     295,\n",
       "     296,\n",
       "     297,\n",
       "     298,\n",
       "     299,\n",
       "     300,\n",
       "     301,\n",
       "     302,\n",
       "     303,\n",
       "     304,\n",
       "     305,\n",
       "     306,\n",
       "     307,\n",
       "     308,\n",
       "     309,\n",
       "     310,\n",
       "     311,\n",
       "     312,\n",
       "     313,\n",
       "     314,\n",
       "     315,\n",
       "     316,\n",
       "     317,\n",
       "     318,\n",
       "     319,\n",
       "     320,\n",
       "     321,\n",
       "     322,\n",
       "     323,\n",
       "     324,\n",
       "     325,\n",
       "     326,\n",
       "     327,\n",
       "     328,\n",
       "     329,\n",
       "     330,\n",
       "     331,\n",
       "     332,\n",
       "     333,\n",
       "     334,\n",
       "     335,\n",
       "     336,\n",
       "     337,\n",
       "     338,\n",
       "     339,\n",
       "     340,\n",
       "     341,\n",
       "     342,\n",
       "     343,\n",
       "     344,\n",
       "     345,\n",
       "     346,\n",
       "     347,\n",
       "     348,\n",
       "     349,\n",
       "     350,\n",
       "     351,\n",
       "     352,\n",
       "     353,\n",
       "     354,\n",
       "     355,\n",
       "     356]}]},\n",
       " 'epoch': 10,\n",
       " 'wandb_id': 'wbajq4k6'}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "path = '/home/huangjialong/projects/BiomedCLIP-PUNCE/simclr/output-model/new-simclr-puc/biomed_simclr_infonce_filterGC_224_4*256/biomed_simclr_infonce_filterGC_224_4*256_epoch10.pt'\n",
    "tensor = torch.load(path)\n",
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "model.cuda()\n",
    "img_path = '/home1/wsi/gc-224/NILM/202000767/1_10.jpg'\n",
    "input = preprocess_val(Image.open(img_path)).unsqueeze(0).to('cuda')\n",
    "img_feature, _, scalar = model(input)\n",
    "img_feature.shape\n",
    "\n",
    "img_feature1 = model.encode_image(input)\n",
    "img_feature1.shape\n",
    "\n",
    "img_feature2 = model.visual.trunk(input)\n",
    "\n",
    "img_feature2 /= img_feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0404,  1.7260, -0.8140],\n",
      "        [ 1.3722,  0.5060, -0.4823],\n",
      "        [-0.7853,  0.6681, -0.4439],\n",
      "        [ 0.1888,  0.5986,  0.6458],\n",
      "        [ 0.6306, -1.4668, -0.6798]], requires_grad=True) tensor([0, 2, 2, 2, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.8474, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "def fix_seed(seed):\n",
    "    torch.manual_seed(seed) # 为CPU设置随机种子\n",
    "    torch.cuda.manual_seed(seed) # 为当前GPU设置随机种子\n",
    "    torch.cuda.manual_seed_all(seed)  # if you are using multi-GPU，为所有GPU设置随机种子\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "fix_seed(2024)\n",
    "# Example of target with class indices\n",
    "input = torch.randn(5, 3, requires_grad=True)\n",
    "target = torch.randint(3, (5,), dtype=torch.int64)\n",
    "print(input, target)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.8474)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "input = torch.tensor([[0,  1, -0.8140],\n",
    "        [ 1.3722,  0.5060, -0.4823],\n",
    "        [-0.7853,  0.6681, -0.4439],\n",
    "        [ 0.1888,  0.5986,  0.6458],\n",
    "        [ 0.6306, -1.4668, -0.6798]], dtype=torch.float32)\n",
    "target = torch.tensor([0, 2, 2, 2, 1])\n",
    "target = F.one_hot(target, num_classes=3).type(torch.float32)\n",
    "loss = F.cross_entropy(input, target)\n",
    "loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.) tensor(nan)\n"
     ]
    }
   ],
   "source": [
    "n = -torch.inf\n",
    "input = torch.tensor([[1., n, n],])\n",
    "target1 = torch.tensor([0])\n",
    "target2 = torch.tensor([[2., 0., 0.],])\n",
    "loss1 = F.cross_entropy(input, target1)\n",
    "loss2 = F.cross_entropy(input, target2)\n",
    "print(loss1, loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trunk.cls_token\n",
      "trunk.pos_embed\n",
      "trunk.patch_embed.proj.weight\n",
      "trunk.patch_embed.proj.bias\n",
      "trunk.blocks.0.norm1.weight\n",
      "trunk.blocks.0.norm1.bias\n",
      "trunk.blocks.0.attn.qkv.weight\n",
      "trunk.blocks.0.attn.qkv.bias\n",
      "trunk.blocks.0.attn.proj.weight\n",
      "trunk.blocks.0.attn.proj.bias\n",
      "trunk.blocks.0.norm2.weight\n",
      "trunk.blocks.0.norm2.bias\n",
      "trunk.blocks.0.mlp.fc1.weight\n",
      "trunk.blocks.0.mlp.fc1.bias\n",
      "trunk.blocks.0.mlp.fc2.weight\n",
      "trunk.blocks.0.mlp.fc2.bias\n",
      "trunk.blocks.1.norm1.weight\n",
      "trunk.blocks.1.norm1.bias\n",
      "trunk.blocks.1.attn.qkv.weight\n",
      "trunk.blocks.1.attn.qkv.bias\n",
      "trunk.blocks.1.attn.proj.weight\n",
      "trunk.blocks.1.attn.proj.bias\n",
      "trunk.blocks.1.norm2.weight\n",
      "trunk.blocks.1.norm2.bias\n",
      "trunk.blocks.1.mlp.fc1.weight\n",
      "trunk.blocks.1.mlp.fc1.bias\n",
      "trunk.blocks.1.mlp.fc2.weight\n",
      "trunk.blocks.1.mlp.fc2.bias\n",
      "trunk.blocks.2.norm1.weight\n",
      "trunk.blocks.2.norm1.bias\n",
      "trunk.blocks.2.attn.qkv.weight\n",
      "trunk.blocks.2.attn.qkv.bias\n",
      "trunk.blocks.2.attn.proj.weight\n",
      "trunk.blocks.2.attn.proj.bias\n",
      "trunk.blocks.2.norm2.weight\n",
      "trunk.blocks.2.norm2.bias\n",
      "trunk.blocks.2.mlp.fc1.weight\n",
      "trunk.blocks.2.mlp.fc1.bias\n",
      "trunk.blocks.2.mlp.fc2.weight\n",
      "trunk.blocks.2.mlp.fc2.bias\n",
      "trunk.blocks.3.norm1.weight\n",
      "trunk.blocks.3.norm1.bias\n",
      "trunk.blocks.3.attn.qkv.weight\n",
      "trunk.blocks.3.attn.qkv.bias\n",
      "trunk.blocks.3.attn.proj.weight\n",
      "trunk.blocks.3.attn.proj.bias\n",
      "trunk.blocks.3.norm2.weight\n",
      "trunk.blocks.3.norm2.bias\n",
      "trunk.blocks.3.mlp.fc1.weight\n",
      "trunk.blocks.3.mlp.fc1.bias\n",
      "trunk.blocks.3.mlp.fc2.weight\n",
      "trunk.blocks.3.mlp.fc2.bias\n",
      "trunk.blocks.4.norm1.weight\n",
      "trunk.blocks.4.norm1.bias\n",
      "trunk.blocks.4.attn.qkv.weight\n",
      "trunk.blocks.4.attn.qkv.bias\n",
      "trunk.blocks.4.attn.proj.weight\n",
      "trunk.blocks.4.attn.proj.bias\n",
      "trunk.blocks.4.norm2.weight\n",
      "trunk.blocks.4.norm2.bias\n",
      "trunk.blocks.4.mlp.fc1.weight\n",
      "trunk.blocks.4.mlp.fc1.bias\n",
      "trunk.blocks.4.mlp.fc2.weight\n",
      "trunk.blocks.4.mlp.fc2.bias\n",
      "trunk.blocks.5.norm1.weight\n",
      "trunk.blocks.5.norm1.bias\n",
      "trunk.blocks.5.attn.qkv.weight\n",
      "trunk.blocks.5.attn.qkv.bias\n",
      "trunk.blocks.5.attn.proj.weight\n",
      "trunk.blocks.5.attn.proj.bias\n",
      "trunk.blocks.5.norm2.weight\n",
      "trunk.blocks.5.norm2.bias\n",
      "trunk.blocks.5.mlp.fc1.weight\n",
      "trunk.blocks.5.mlp.fc1.bias\n",
      "trunk.blocks.5.mlp.fc2.weight\n",
      "trunk.blocks.5.mlp.fc2.bias\n",
      "trunk.blocks.6.norm1.weight\n",
      "trunk.blocks.6.norm1.bias\n",
      "trunk.blocks.6.attn.qkv.weight\n",
      "trunk.blocks.6.attn.qkv.bias\n",
      "trunk.blocks.6.attn.proj.weight\n",
      "trunk.blocks.6.attn.proj.bias\n",
      "trunk.blocks.6.norm2.weight\n",
      "trunk.blocks.6.norm2.bias\n",
      "trunk.blocks.6.mlp.fc1.weight\n",
      "trunk.blocks.6.mlp.fc1.bias\n",
      "trunk.blocks.6.mlp.fc2.weight\n",
      "trunk.blocks.6.mlp.fc2.bias\n",
      "trunk.blocks.7.norm1.weight\n",
      "trunk.blocks.7.norm1.bias\n",
      "trunk.blocks.7.attn.qkv.weight\n",
      "trunk.blocks.7.attn.qkv.bias\n",
      "trunk.blocks.7.attn.proj.weight\n",
      "trunk.blocks.7.attn.proj.bias\n",
      "trunk.blocks.7.norm2.weight\n",
      "trunk.blocks.7.norm2.bias\n",
      "trunk.blocks.7.mlp.fc1.weight\n",
      "trunk.blocks.7.mlp.fc1.bias\n",
      "trunk.blocks.7.mlp.fc2.weight\n",
      "trunk.blocks.7.mlp.fc2.bias\n",
      "trunk.blocks.8.norm1.weight\n",
      "trunk.blocks.8.norm1.bias\n",
      "trunk.blocks.8.attn.qkv.weight\n",
      "trunk.blocks.8.attn.qkv.bias\n",
      "trunk.blocks.8.attn.proj.weight\n",
      "trunk.blocks.8.attn.proj.bias\n",
      "trunk.blocks.8.norm2.weight\n",
      "trunk.blocks.8.norm2.bias\n",
      "trunk.blocks.8.mlp.fc1.weight\n",
      "trunk.blocks.8.mlp.fc1.bias\n",
      "trunk.blocks.8.mlp.fc2.weight\n",
      "trunk.blocks.8.mlp.fc2.bias\n",
      "trunk.blocks.9.norm1.weight\n",
      "trunk.blocks.9.norm1.bias\n",
      "trunk.blocks.9.attn.qkv.weight\n",
      "trunk.blocks.9.attn.qkv.bias\n",
      "trunk.blocks.9.attn.proj.weight\n",
      "trunk.blocks.9.attn.proj.bias\n",
      "trunk.blocks.9.norm2.weight\n",
      "trunk.blocks.9.norm2.bias\n",
      "trunk.blocks.9.mlp.fc1.weight\n",
      "trunk.blocks.9.mlp.fc1.bias\n",
      "trunk.blocks.9.mlp.fc2.weight\n",
      "trunk.blocks.9.mlp.fc2.bias\n",
      "trunk.blocks.10.norm1.weight\n",
      "trunk.blocks.10.norm1.bias\n",
      "trunk.blocks.10.attn.qkv.weight\n",
      "trunk.blocks.10.attn.qkv.bias\n",
      "trunk.blocks.10.attn.proj.weight\n",
      "trunk.blocks.10.attn.proj.bias\n",
      "trunk.blocks.10.norm2.weight\n",
      "trunk.blocks.10.norm2.bias\n",
      "trunk.blocks.10.mlp.fc1.weight\n",
      "trunk.blocks.10.mlp.fc1.bias\n",
      "trunk.blocks.10.mlp.fc2.weight\n",
      "trunk.blocks.10.mlp.fc2.bias\n",
      "trunk.blocks.11.norm1.weight\n",
      "trunk.blocks.11.norm1.bias\n",
      "trunk.blocks.11.attn.qkv.weight\n",
      "trunk.blocks.11.attn.qkv.bias\n",
      "trunk.blocks.11.attn.proj.weight\n",
      "trunk.blocks.11.attn.proj.bias\n",
      "trunk.blocks.11.norm2.weight\n",
      "trunk.blocks.11.norm2.bias\n",
      "trunk.blocks.11.mlp.fc1.weight\n",
      "trunk.blocks.11.mlp.fc1.bias\n",
      "trunk.blocks.11.mlp.fc2.weight\n",
      "trunk.blocks.11.mlp.fc2.bias\n",
      "trunk.norm.weight\n",
      "trunk.norm.bias\n",
      "head.proj.weight\n"
     ]
    }
   ],
   "source": [
    "for k, v in model.visual.named_parameters():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'norm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[65], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m linear1 \u001b[39m=\u001b[39m LinearAdapter(\u001b[39m10\u001b[39m)\n\u001b[1;32m     17\u001b[0m linear2 \u001b[39m=\u001b[39m LinearAdapter(\u001b[39m10\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m nor \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mnormalize(\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m module \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mSequential(linear1, linear2, nor)\n\u001b[1;32m     20\u001b[0m module\n",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/torch/nn/functional.py:4620\u001b[0m, in \u001b[0;36mnormalize\u001b[0;34m(input, p, dim, eps, out)\u001b[0m\n\u001b[1;32m   4618\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(normalize, (\u001b[39minput\u001b[39m, out), \u001b[39minput\u001b[39m, p\u001b[39m=\u001b[39mp, dim\u001b[39m=\u001b[39mdim, eps\u001b[39m=\u001b[39meps, out\u001b[39m=\u001b[39mout)\n\u001b[1;32m   4619\u001b[0m \u001b[39mif\u001b[39;00m out \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 4620\u001b[0m     denom \u001b[39m=\u001b[39m \u001b[39minput\u001b[39;49m\u001b[39m.\u001b[39;49mnorm(p, dim, keepdim\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\u001b[39m.\u001b[39mclamp_min(eps)\u001b[39m.\u001b[39mexpand_as(\u001b[39minput\u001b[39m)\n\u001b[1;32m   4621\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m \u001b[39m/\u001b[39m denom\n\u001b[1;32m   4622\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'norm'"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class LinearAdapter(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LinearAdapter, self).__init__()\n",
    "        self.hide_layer = nn.Linear(input_dim, input_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "        x = self.hide_layer(x)\n",
    "        return x\n",
    "\n",
    "linear1 = LinearAdapter(10)\n",
    "linear2 = LinearAdapter(10)\n",
    "nor = F.normalize(10)\n",
    "module = nn.Sequential(linear1, linear2, nor)\n",
    "module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangjialong/miniconda3/envs/biomed/lib/python3.8/site-packages/torch/nn/init.py:405: UserWarning: Initializing zero-element tensors is a no-op\n",
      "  warnings.warn(\"Initializing zero-element tensors is a no-op\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([], size=(1, 0), grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "x = torch.ones(1, 10)\n",
    "linear = nn.Linear(10, 0)\n",
    "y = linear(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        ...,\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "        [1., 1., 1.,  ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "fea_dir1 = '/home/huangjialong/projects/BiomedCLIP-PUNCE/extract-features/result-final-gc-features/biomed-test/pt'\n",
    "fea_dir2 = '/home/huangjialong/projects/BiomedCLIP-PUNCE/extract-features/result-final-gc-features/biomed-test2/pt'\n",
    "fea_dir3 = '/home/huangjialong/projects/BiomedCLIP-PUNCE/extract-features/result-final-gc-features/biomed2/pt'\n",
    "pt_file = 'xCY20005897-NILM.pt'\n",
    "\n",
    "pt_path1 = os.path.join(fea_dir1, pt_file)\n",
    "pt_path2 = os.path.join(fea_dir2, pt_file)\n",
    "pt_path3 = os.path.join(fea_dir3, pt_file)\n",
    "fea1 = torch.load(pt_path1)\n",
    "fea2 = torch.load(pt_path2)\n",
    "fea3 = torch.load(pt_path3)\n",
    "fea2 /= fea3\n",
    "fea2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-2.0756e+00,  4.8968e-01, -1.1921e+00,  7.8138e-01,  5.2103e-01,\n",
       "          -1.8302e+00, -1.1896e-01,  3.3987e-01,  2.6367e-01,  5.0438e-01],\n",
       "         [ 9.6812e-01,  9.8213e-01,  7.0351e-01,  1.1103e+00, -6.4374e-01,\n",
       "           9.4631e-01, -3.7023e+00,  6.7075e-01,  2.3759e-01,  7.2683e-01],\n",
       "         [ 2.0717e+00,  8.7473e-01,  1.4393e+00,  1.4921e+00,  5.6588e+00,\n",
       "           7.5281e-01,  9.3706e-01,  2.1748e+00,  1.4782e+00,  5.8152e-01],\n",
       "         [ 8.9782e-01,  4.5270e-01,  5.1339e-01,  9.2950e-01,  9.0871e-01,\n",
       "           6.8978e-01,  5.1612e-01,  7.1402e-01,  2.0777e+01,  9.7726e-01],\n",
       "         [ 2.0132e+00,  1.1093e+01,  7.7555e-01,  1.2542e-01,  7.6793e-01,\n",
       "           8.1515e-01, -4.7929e-01,  1.8532e+00,  3.7247e-01,  1.3500e+01]],\n",
       "\n",
       "        [[ 1.2070e+00,  7.4351e-01,  5.7571e-01,  1.0943e+00,  1.7656e+00,\n",
       "           6.5129e-01,  7.1894e-01,  1.7322e+00,  8.1733e-01,  7.1680e-01],\n",
       "         [-1.3851e+00,  1.9621e+00,  1.7829e+00,  1.0089e+00,  1.2072e+00,\n",
       "           1.8607e+00,  1.2389e+00,  1.4929e+00,  1.3664e+00,  1.7160e+00],\n",
       "         [ 3.0433e-01,  7.4731e-01,  1.7653e+00,  1.3714e+00,  8.0670e-01,\n",
       "           1.3209e+00,  1.8617e+00,  2.0305e+00,  1.5808e-01, -1.6662e-01],\n",
       "         [ 3.0889e-01,  6.2692e-01, -1.6174e+00,  7.3387e-01,  7.7707e-01,\n",
       "           1.7628e+00,  3.0598e+00, -3.3587e-02,  4.1725e+00,  6.3401e-01],\n",
       "         [ 8.2707e-01,  3.5733e+00,  1.3698e+00,  1.1331e+00,  4.4513e+00,\n",
       "           2.7241e+02,  9.5967e-01,  1.0472e+00,  1.4918e+00,  1.9110e+00]],\n",
       "\n",
       "        [[ 7.3149e-01, -3.9980e-01,  7.2002e-01,  1.3487e+00,  7.3067e-01,\n",
       "           2.0825e+00,  7.4290e-01,  1.3416e+00,  3.6305e-01,  1.2968e+00],\n",
       "         [ 8.8495e-01,  1.3557e+00, -2.3072e+01,  1.2799e+00,  9.8148e-01,\n",
       "          -6.8646e-01,  8.2216e-01,  9.6780e-01,  1.2623e+00,  1.1348e+00],\n",
       "         [ 1.1571e+00,  9.5001e-01,  1.4424e+00, -1.6803e-02,  9.5302e-01,\n",
       "           5.8723e-01,  1.0013e+00,  1.3394e+00,  8.6781e-01,  1.2468e+00],\n",
       "         [ 6.0629e-01,  1.8275e+00,  1.4292e+00,  1.4810e+00,  1.6037e+00,\n",
       "           6.3904e-01,  1.6377e+00,  1.7564e+00,  1.3741e+00,  1.8994e+00],\n",
       "         [ 1.6290e+00,  1.1002e+00,  1.3879e+00,  1.4395e+00,  9.3854e-01,\n",
       "           1.2160e+00,  1.1167e+00,  8.0951e-01,  7.1699e-01,  1.4761e+00]],\n",
       "\n",
       "        [[ 1.0513e+00,  2.7266e+00,  1.2722e+00,  8.8011e-01,  1.1793e+00,\n",
       "           8.6022e-01,  4.4865e-01,  8.3884e-01,  1.0043e+00,  9.0537e-01],\n",
       "         [ 1.5819e+00,  1.3782e+00,  3.9010e+00,  1.5767e+00, -2.6602e-01,\n",
       "           3.3831e+00,  4.0982e+00,  7.0432e-01,  3.7386e+00,  8.1805e+00],\n",
       "         [ 1.0480e+00,  6.5861e-01,  1.1273e+00,  5.7747e-01,  2.0973e-01,\n",
       "           1.1026e+00,  7.8188e-01,  6.9846e-01,  5.3155e+00,  6.9958e-01],\n",
       "         [ 1.2944e+00,  1.2724e+00,  1.4084e+00,  1.5193e+00,  2.0424e+00,\n",
       "           1.5156e+00,  1.5333e+00, -4.9903e-01,  1.2589e+00,  1.3499e+00],\n",
       "         [-3.7000e+01,  2.4873e+00,  9.9741e-01,  4.1906e+00, -8.6480e-02,\n",
       "          -3.9205e-01,  2.0177e+00,  1.0209e+00,  7.9193e-01,  7.7006e-01]],\n",
       "\n",
       "        [[ 1.0751e+00, -2.4585e-01,  6.7300e-02,  7.3891e-01,  2.1863e-01,\n",
       "           3.8139e-01,  8.3405e-01,  2.0702e+00,  1.1020e+00,  1.5364e+00],\n",
       "         [ 6.2775e-01, -8.6566e-01,  4.0387e+00, -9.3119e-01,  9.0940e-02,\n",
       "           6.7181e-01,  9.1091e-02,  5.8365e-01,  9.7077e-01,  1.9207e+00],\n",
       "         [ 1.6781e+00,  1.6415e+00,  9.1583e-01,  1.0941e+00,  2.3223e+00,\n",
       "           2.8307e+00,  6.8286e-01,  2.6097e+00,  1.1563e+00,  4.0947e+00],\n",
       "         [ 3.1012e+00,  9.4309e-01,  1.0076e+00,  9.7545e-01,  9.5464e-01,\n",
       "           8.5739e-01,  9.8153e-01,  9.4879e-01,  9.6960e-01,  9.9274e-01],\n",
       "         [ 6.6344e-01,  5.6681e-01,  1.2913e+00,  1.1747e+00,  1.1296e+00,\n",
       "           9.8215e-01, -6.2222e-01,  7.5490e-01,  6.2889e-01,  7.0103e-01]],\n",
       "\n",
       "        [[ 6.7230e-01,  7.8749e-01,  4.4214e-01,  7.7429e-01, -2.9173e+00,\n",
       "           1.6151e+00,  1.3746e+00,  6.8556e-01,  2.3969e+00,  2.8384e-01],\n",
       "         [ 3.0108e+00,  2.0963e-01,  8.1829e-01,  9.1599e-01,  1.5450e+00,\n",
       "           2.6732e+00,  1.2415e+01,  3.6709e-01,  9.0441e-01,  4.7070e+00],\n",
       "         [ 8.8060e-01,  8.8028e-01,  8.8051e-01,  8.8016e-01,  8.8013e-01,\n",
       "           8.8040e-01,  8.8035e-01,  8.8067e-01,  8.8015e-01,  8.8067e-01],\n",
       "         [ 8.1082e-01,  1.3167e+00,  5.7381e-01,  1.3156e+00,  2.4205e-01,\n",
       "           1.1415e+00,  7.6556e-01,  6.2346e-01,  1.4137e+00,  7.0241e-01],\n",
       "         [ 1.4064e+00,  8.9430e-01,  7.8584e-01,  7.7049e-01,  8.9823e-01,\n",
       "           7.5679e-01,  1.0460e+00,  3.0857e-01, -4.0551e-02,  9.8248e-01]],\n",
       "\n",
       "        [[ 1.0337e+00,  5.1002e+00,  1.1643e+00,  7.0300e-01,  1.2607e+00,\n",
       "           8.2362e-01,  1.5394e+00,  7.7977e-01,  5.6901e+00,  2.0558e+00],\n",
       "         [ 5.7505e-01,  6.0900e-01,  6.8390e-01,  2.0542e+00,  1.5216e+00,\n",
       "           5.5716e-01,  3.5280e-01, -8.2700e-02,  2.3165e-02,  5.8145e+00],\n",
       "         [ 1.4288e+00,  3.2106e+00, -3.9281e-01,  5.7737e-01,  5.3115e-01,\n",
       "          -1.2570e-01,  1.2583e-01,  4.4353e-01,  1.5131e+00,  5.9796e-01],\n",
       "         [-9.5279e-01,  7.0510e-01,  9.4173e-01,  7.3774e-01,  1.5186e+00,\n",
       "           6.7594e-01,  9.1893e-01,  7.2451e-01,  5.6698e-01,  9.2071e-01],\n",
       "         [ 1.4961e+00,  8.8949e-01,  6.9539e-01,  9.9864e-01,  1.4437e+00,\n",
       "           9.3398e-01,  6.2424e-01,  1.2946e+00,  7.4088e-01,  7.6011e-01]],\n",
       "\n",
       "        [[ 8.9806e-01,  8.5105e-01,  8.6043e-01,  8.4288e-01,  9.9045e-01,\n",
       "           8.5082e-01,  9.1574e-01,  4.1839e-01,  9.2433e-01,  8.1632e-01],\n",
       "         [ 1.2675e+00,  1.2000e+00,  7.9152e-01,  5.7393e-01,  5.0759e-01,\n",
       "           1.1757e+00,  9.6363e-01,  3.2098e-01,  9.8752e-01,  1.5821e+00],\n",
       "         [ 8.2840e-01, -1.2046e+00, -9.4462e-01, -1.5374e+00,  1.2345e+00,\n",
       "           2.0689e+00,  2.0768e+00,  1.0184e+00,  1.3052e+02,  1.1056e+00],\n",
       "         [ 2.6807e+00,  8.1704e-01, -5.5828e-01,  1.4801e+00,  6.0229e-01,\n",
       "           6.5473e-01,  2.5808e+01,  1.5045e-01,  8.5761e-01, -7.6999e+00],\n",
       "         [ 8.5241e-01,  8.4013e-01,  8.0331e-01,  9.2963e-01,  7.8623e-01,\n",
       "           8.5213e-01,  7.7391e-01,  8.3849e-01,  8.0024e-01,  8.5881e-01]],\n",
       "\n",
       "        [[ 9.8324e-01,  1.0812e+00,  7.8233e-01,  6.4428e-01,  1.1351e+00,\n",
       "           6.6362e-01,  7.3742e-01,  9.8256e-01,  3.2733e-01,  1.3131e+00],\n",
       "         [ 1.0052e+00,  1.4325e+00,  7.9661e-01,  7.0352e-01,  8.4859e-01,\n",
       "           8.4170e-01,  1.0861e+00,  8.8533e-01,  9.7200e-01,  8.7590e-01],\n",
       "         [ 2.2732e+00,  8.1941e-01,  1.0329e+00,  3.6116e+00, -2.5366e-01,\n",
       "           1.3664e+00,  8.4658e-01,  1.8688e+00, -2.3099e-01,  9.1434e-01],\n",
       "         [ 1.9153e+00,  2.0496e+00, -7.2780e-01,  1.1159e+00, -6.5200e-02,\n",
       "           1.8313e+00,  9.3360e-01,  3.8202e+00,  9.7398e-01,  1.1026e+00],\n",
       "         [ 9.3242e-01,  1.0046e+00,  7.8768e-01,  8.4603e-01,  9.4730e-01,\n",
       "           1.0268e+00,  1.2868e+00,  5.4355e-01,  1.0816e+00,  6.6420e-01]],\n",
       "\n",
       "        [[ 8.7898e-01,  8.6138e-01,  8.8215e-01,  8.3495e-01,  1.0656e+00,\n",
       "           8.5835e-01,  7.8705e-01,  1.1754e+00,  9.3332e-01,  8.9207e-01],\n",
       "         [-4.7969e-02, -6.0334e-01,  3.8483e+00,  8.2099e-01,  6.5836e-01,\n",
       "           8.9778e-01,  5.1330e-01, -7.5601e-01,  1.6018e+00,  2.7956e+00],\n",
       "         [ 6.4137e+00,  1.7246e+00,  2.0787e+00,  1.7575e+00,  6.1420e+00,\n",
       "           2.5158e+00,  1.7703e+00,  1.3284e+00,  2.7675e+00,  1.7536e+00],\n",
       "         [ 1.1572e+00,  1.1690e+00, -5.8691e-01,  5.2975e+00,  3.1684e+00,\n",
       "           3.2709e+00,  2.2399e+00, -2.5330e+00,  1.3168e+01,  3.7095e-01],\n",
       "         [ 5.3892e+00,  1.4610e+00,  1.9503e+00,  1.7560e+00,  1.3405e+00,\n",
       "           1.3430e+00,  1.4556e+00,  1.3354e+00,  1.5123e+00,  1.4544e+00]],\n",
       "\n",
       "        [[ 7.3416e-01,  1.0708e+00,  8.7925e-01,  1.6292e-01,  2.4926e-01,\n",
       "           5.7409e-01,  6.6464e-01,  9.0455e-01,  7.4850e-01,  1.0196e-01],\n",
       "         [ 1.0572e+00,  8.2012e+01,  9.4785e-01,  1.2272e+00,  9.6071e-01,\n",
       "           1.1699e+00,  8.5956e-01,  1.2434e+00,  1.3089e+00,  1.1856e+00],\n",
       "         [ 5.1743e+00,  2.0201e-01,  7.2326e-01,  5.6065e+00,  9.5481e-01,\n",
       "          -1.3008e-01,  9.7536e-01, -2.4330e+00,  4.6143e+00,  1.8521e-02],\n",
       "         [ 1.3812e+00, -6.1913e-01,  7.0502e-02,  3.1578e+00,  6.5330e-01,\n",
       "           8.2746e-01,  2.0875e+00, -1.8871e-01, -6.1477e-02,  8.9197e-01],\n",
       "         [-4.3464e-01, -1.5053e-01,  1.2713e+00,  6.4286e-01,  1.0206e+00,\n",
       "           6.9105e+00,  1.3279e+00,  3.9273e-01,  3.1722e+00,  7.3213e-01]],\n",
       "\n",
       "        [[ 7.4701e-02,  9.3666e-01,  6.0908e-01,  1.7052e+00,  5.4179e-01,\n",
       "           4.1261e-01,  1.0463e+00,  7.4974e+00,  2.4016e+00,  3.4323e-01],\n",
       "         [ 9.1182e-01, -1.1613e+01, -2.8464e+00,  6.1333e-02,  2.5403e-01,\n",
       "          -2.7475e-01, -2.0674e+00,  6.3117e-01,  1.2985e+00,  6.0253e-01],\n",
       "         [ 1.1136e+00,  9.7127e-01,  3.6803e-01,  6.2626e-01,  1.7423e+00,\n",
       "           3.3664e+00,  8.0087e-01,  8.5215e-01,  2.9563e+00,  1.7486e+00],\n",
       "         [ 1.0516e+00,  1.0257e+00,  1.0062e+00,  9.1502e-01,  1.0244e+00,\n",
       "           1.0016e+00,  1.1127e+00,  1.0084e+00,  1.0212e+00,  9.9548e-01],\n",
       "         [ 9.2945e-01,  7.5556e-01,  2.1436e+00,  8.1572e-01,  1.1545e+00,\n",
       "           1.1961e-01,  1.5510e+00,  1.3092e+00,  9.2720e-01,  1.3767e+00]],\n",
       "\n",
       "        [[ 1.6001e+00,  1.1273e+00,  1.0026e+00,  9.6217e-01,  9.5995e-01,\n",
       "           1.5112e+00,  9.4435e-01,  1.2429e+00,  3.3969e-01,  1.2495e+00],\n",
       "         [ 1.1797e+00,  6.3190e-01,  2.6950e-01,  1.0825e+00,  1.0419e+00,\n",
       "           7.9540e-01,  6.2458e-01,  6.9147e-01,  7.0049e-01,  7.9745e-01],\n",
       "         [ 2.0871e+00,  1.7529e+00,  8.5897e-01,  5.3960e-01,  1.0712e+01,\n",
       "           4.4662e-01,  1.9051e-01,  9.0802e-02,  7.8320e-01,  5.0943e-01],\n",
       "         [ 3.1635e+00,  4.6984e-01,  1.3706e-01,  3.2580e+00,  9.2698e-01,\n",
       "           5.0442e-01,  9.3423e-01,  2.4179e+00,  3.6583e+00,  2.1063e+00],\n",
       "         [ 1.2330e+00,  1.2698e+00,  1.3173e+00,  1.2502e+00,  1.2547e+00,\n",
       "           1.2401e+00,  1.2395e+00,  1.2460e+00,  1.2566e+00,  1.2604e+00]],\n",
       "\n",
       "        [[ 1.8770e+00,  6.1321e-01,  9.7591e-01,  3.6340e-02,  1.9166e-01,\n",
       "           6.8426e-01,  1.2986e+00,  5.5516e-01,  3.2029e-01,  1.8586e+00],\n",
       "         [ 9.1249e-01,  2.8653e+00,  9.9373e-01,  2.5900e+00,  3.1578e+00,\n",
       "           3.9013e-02,  1.5175e+00,  1.6558e+00,  1.0168e+00,  1.0333e+00],\n",
       "         [ 3.2779e-01, -1.3987e+00,  9.1357e-02,  9.4798e-01,  2.6998e+00,\n",
       "           2.5555e+00,  8.9761e-01, -1.1217e+00,  2.1879e-01,  1.1164e-01],\n",
       "         [ 2.5544e+00,  1.9510e+00,  1.0255e+00,  1.2233e+00,  1.2526e+00,\n",
       "           1.7696e+00,  1.1273e+00,  1.6738e+00,  2.2942e+00,  2.8261e+00],\n",
       "         [ 8.8558e-01,  9.0169e-01,  7.7100e-01,  7.0731e-01,  7.0869e-01,\n",
       "           6.8091e-01,  6.6657e-01,  6.7149e-01,  6.1483e-01,  6.5087e-01]],\n",
       "\n",
       "        [[ 1.0696e+00,  1.0007e+00,  1.1984e+00,  1.2143e+00,  1.0873e+00,\n",
       "           9.2237e-01,  8.2356e-01,  8.6355e-01,  1.1777e+00,  1.1820e+00],\n",
       "         [-1.2737e+00,  8.1306e-01,  1.2999e+00,  1.3294e+00,  3.1122e+00,\n",
       "           2.0571e+00,  1.0283e+00, -3.2838e-02, -1.2881e+00,  9.9260e+00],\n",
       "         [ 1.0790e+00,  1.3416e+00,  1.9069e+00,  1.2531e+00, -3.1675e+00,\n",
       "           1.2331e+00,  1.6182e+00,  1.6920e+00,  1.9589e+00,  2.8060e+00],\n",
       "         [ 1.4265e+00,  9.4736e-01,  1.1760e+00,  1.6695e+00,  1.1931e+00,\n",
       "           1.4893e+00,  7.7276e-01,  1.5397e+00,  1.0712e+00, -5.7863e-01],\n",
       "         [ 8.4275e-01,  2.0350e+01, -1.3513e+01,  7.3880e-01, -4.3401e-01,\n",
       "          -5.6840e+00,  6.9933e-01,  7.6540e-01,  1.3225e+00,  2.1152e+00]],\n",
       "\n",
       "        [[ 2.6703e+00,  6.8820e-01,  6.1430e-01,  5.2711e+00, -2.2149e+00,\n",
       "           4.1871e+00,  2.6177e+00,  1.6007e+00,  1.5586e+00,  6.2619e-01],\n",
       "         [ 1.3638e+00,  1.0218e+00,  2.0818e-01,  8.0068e-01,  9.8656e-01,\n",
       "           7.5307e-01,  7.0669e-01,  7.9313e-01,  1.1452e+00,  1.3298e+00],\n",
       "         [-1.6835e+00,  9.7934e-01,  8.7709e-01, -8.2661e-01,  1.0518e+01,\n",
       "          -3.9166e-02,  1.9648e+00,  2.0092e+00,  9.3286e-01,  7.6381e-01],\n",
       "         [ 9.3669e-01,  9.9884e-01,  3.8780e+00,  2.0474e+00,  6.9173e-01,\n",
       "           8.5373e-01,  1.3335e+00,  7.5187e-01,  2.5005e+00,  2.9371e-01],\n",
       "         [ 8.9338e-01,  9.8787e-01,  1.0210e+00,  1.2740e+00,  9.0385e-01,\n",
       "           9.0940e-01,  2.0516e+00, -3.3305e-01,  1.0891e+00,  8.8712e-01]],\n",
       "\n",
       "        [[ 2.4085e+00,  1.8428e+00,  8.7271e-01,  1.0736e+00,  9.5846e-01,\n",
       "           5.6248e-01,  2.9656e-01,  9.6665e-01,  8.0164e-01, -1.8032e+01],\n",
       "         [ 3.8904e-01,  1.1397e+00,  9.3040e-01,  7.5962e-01,  1.0086e+00,\n",
       "           7.5136e-01, -1.5510e-01,  1.3127e+00,  7.2525e-01,  6.4009e-01],\n",
       "         [ 1.2228e+00,  5.6936e-01,  6.5611e-01,  5.5910e-01,  6.8682e-01,\n",
       "           1.1003e+00,  1.0919e+00,  8.1421e-01,  2.3513e+01,  7.5460e-01],\n",
       "         [ 5.9371e-01,  1.6524e-01,  1.4189e+00,  6.4180e-01,  7.1155e-01,\n",
       "           3.0907e+00,  3.9267e-01, -1.0121e+00,  6.0542e-01, -4.7880e+00],\n",
       "         [ 9.2855e-01,  1.2763e+00,  3.3730e-01, -1.2441e-01,  6.5862e-01,\n",
       "           3.5060e+00,  7.5468e-01,  1.6508e+00,  1.9541e+00,  7.9324e-01]],\n",
       "\n",
       "        [[ 5.6017e-01,  9.4095e-01,  1.5757e+00,  1.2836e+00,  1.8694e+00,\n",
       "           9.9297e-01,  1.1367e+00,  9.3033e-01,  1.2957e+00,  1.3023e+00],\n",
       "         [ 1.2499e+00,  1.3830e+00,  8.8163e-01,  4.4968e-01,  9.4325e-01,\n",
       "           6.1453e-01,  1.1904e+00,  1.0838e+00,  8.9762e-01,  1.2589e+00],\n",
       "         [ 2.6774e+00,  9.6700e+00,  4.6003e-01,  1.9160e+00,  2.1080e+00,\n",
       "           5.9181e-02, -2.4894e-01,  1.8785e+00,  2.8692e+00,  1.6182e+00],\n",
       "         [ 3.2421e-01,  6.3281e-01,  2.7450e-01,  6.2811e-01,  1.8124e-01,\n",
       "           2.7432e-01,  1.6752e+00,  1.3257e+00,  1.3825e+00,  2.1703e-01],\n",
       "         [ 1.4495e+00, -4.1489e+00,  1.6032e+00,  1.3914e+00,  4.0251e+00,\n",
       "           1.4127e+00,  1.3852e+00,  1.7428e+00,  2.7506e+00,  1.7820e+00]],\n",
       "\n",
       "        [[ 1.0229e+00,  1.6520e+00,  4.4606e-01,  1.1303e+00,  9.1895e-01,\n",
       "           8.7020e-01,  1.0597e+00,  9.8443e-01,  9.2380e-01,  4.7553e-01],\n",
       "         [ 9.9519e-01,  5.9200e-01,  9.9675e-01,  1.0201e+00,  6.1832e-01,\n",
       "           7.0315e-01,  4.1771e-01,  3.9828e-01,  7.3608e-01, -4.3680e+00],\n",
       "         [ 1.4115e+00,  1.3311e+00,  6.1208e-01,  1.3822e+00, -1.1255e+00,\n",
       "           5.5566e-01,  1.6476e+00,  1.0163e+00,  9.6156e-01,  9.4378e-01],\n",
       "         [ 4.7974e-01,  1.7400e+00,  9.6730e+00,  3.9870e-01,  6.9821e-01,\n",
       "           6.3349e+00,  3.0398e-01,  7.3924e-01,  2.0129e+00,  3.7674e-01],\n",
       "         [ 5.5108e-01,  5.3356e-01,  9.8306e-01,  4.1879e-01,  9.2545e-02,\n",
       "           8.6156e-01,  4.9276e-01,  3.8437e-02,  4.3751e-01,  4.2549e-01]],\n",
       "\n",
       "        [[ 1.9235e+00,  1.3126e+00,  7.3300e-01,  7.9056e-01,  7.8872e-01,\n",
       "           7.0984e-01,  2.5030e+00,  1.2866e+00,  6.4108e-01,  1.7774e+00],\n",
       "         [ 1.7312e+00,  1.1851e+00,  9.4556e-01,  1.7032e+00,  9.8116e-01,\n",
       "           1.0570e+00,  1.0914e+00,  1.8880e+00,  2.0183e+00,  1.0639e+00],\n",
       "         [ 1.1024e-01,  7.3279e-01, -5.5883e-01,  7.7526e-01,  1.5026e-01,\n",
       "           1.2881e+00,  1.1942e+00,  6.8664e-01,  7.4788e-01,  5.6955e-01],\n",
       "         [ 7.5680e-01, -4.4902e+01,  4.1971e-01,  1.2976e+01,  6.4754e+00,\n",
       "          -2.4710e+00, -1.6802e-01, -4.0880e+00, -5.6519e+00,  7.1767e-01],\n",
       "         [ 6.7273e-01, -2.6295e+00, -5.5220e-01, -6.7437e+00, -2.6203e+00,\n",
       "          -7.5456e-01, -2.8689e+00,  8.3804e-01,  5.5191e-01, -1.1630e+00]]],\n",
       "       grad_fn=<DivBackward0>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "# NLP Example\n",
    "# NLP Example\n",
    "# NLP Example\n",
    "batch, sentence_length, embedding_dim = 20, 5, 10\n",
    "embedding = torch.randn(batch, sentence_length, embedding_dim)\n",
    "layer_norm = nn.LayerNorm(embedding_dim)\n",
    "# Activate module\n",
    "out = layer_norm(embedding)\n",
    "out /= embedding\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/huangjialong/miniconda3/envs/biomed/lib/python3.8/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/huangjialong/miniconda3/envs/biomed/lib/python3.8/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from torchvision import models\n",
    "\n",
    "pretrained = True\n",
    "model_baseline = models.resnet50(pretrained=pretrained)\n",
    "print(model_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open_clip\n",
    "from torch import nn\n",
    "class BiomedclipBackbone(nn.Module):\n",
    "    def __init__(self, without_head: bool = False):\n",
    "        super(BiomedclipBackbone, self).__init__()\n",
    "        \n",
    "        model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "        if without_head:\n",
    "            model = model.visual.trunk\n",
    "        else:\n",
    "            model = model.visual\n",
    "        self.model = model\n",
    "        self.preprocess_val = preprocess_val\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.model(x)\n",
    "        features /= features.norm(p=2, dim=-1, keepdim=True)\n",
    "        return features\n",
    "\n",
    "model = BiomedclipBackbone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Compose(\n",
      "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
      "    CenterCrop(size=(224, 224))\n",
      "    <function _convert_to_rgb at 0x7f941ee09f70>\n",
      "    ToTensor()\n",
      "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Compose(\n",
       "    Resize(size=(224, 224), interpolation=bicubic, max_size=None, antialias=None)\n",
       "    CenterCrop(size=(224, 224))\n",
       "    ToTensor()\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "preprocess_val = model.preprocess_val\n",
    "print(preprocess_val)\n",
    "\n",
    "transfrom = transforms.Compose([\n",
    "    transforms.Resize((224, 224), interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "    transforms.CenterCrop((224,224)),\n",
    "    transforms.ToTensor()])\n",
    "transfrom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIPProcessor:\n",
      "- image_processor: CLIPImageProcessor {\n",
      "  \"_valid_processor_keys\": [\n",
      "    \"images\",\n",
      "    \"do_resize\",\n",
      "    \"size\",\n",
      "    \"resample\",\n",
      "    \"do_center_crop\",\n",
      "    \"crop_size\",\n",
      "    \"do_rescale\",\n",
      "    \"rescale_factor\",\n",
      "    \"do_normalize\",\n",
      "    \"image_mean\",\n",
      "    \"image_std\",\n",
      "    \"do_convert_rgb\",\n",
      "    \"return_tensors\",\n",
      "    \"data_format\",\n",
      "    \"input_data_format\"\n",
      "  ],\n",
      "  \"crop_size\": {\n",
      "    \"height\": 224,\n",
      "    \"width\": 224\n",
      "  },\n",
      "  \"do_center_crop\": true,\n",
      "  \"do_convert_rgb\": true,\n",
      "  \"do_normalize\": true,\n",
      "  \"do_rescale\": true,\n",
      "  \"do_resize\": true,\n",
      "  \"image_mean\": [\n",
      "    0.48145466,\n",
      "    0.4578275,\n",
      "    0.40821073\n",
      "  ],\n",
      "  \"image_processor_type\": \"CLIPImageProcessor\",\n",
      "  \"image_std\": [\n",
      "    0.26862954,\n",
      "    0.26130258,\n",
      "    0.27577711\n",
      "  ],\n",
      "  \"resample\": 3,\n",
      "  \"rescale_factor\": 0.00392156862745098,\n",
      "  \"size\": {\n",
      "    \"shortest_edge\": 224\n",
      "  }\n",
      "}\n",
      "\n",
      "- tokenizer: CLIPTokenizerFast(name_or_path='vinid/plip', vocab_size=49408, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|startoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'pad_token': '<|endoftext|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
      "\t49406: AddedToken(\"<|startoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
      "\t49407: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
      "}\n",
      "\n",
      "{\n",
      "  \"processor_class\": \"CLIPProcessor\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CLIPProcessor' object has no attribute 'transforms'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mprint\u001b[39m(preprocess_val)\n\u001b[1;32m      4\u001b[0m preprocess_list \u001b[39m=\u001b[39m []\n\u001b[0;32m----> 5\u001b[0m \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m preprocess_val\u001b[39m.\u001b[39;49mtransforms:\n\u001b[1;32m      6\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(t, transforms\u001b[39m.\u001b[39mNormalize):\n\u001b[1;32m      7\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CLIPProcessor' object has no attribute 'transforms'"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "preprocess_val = model.preprocess_val\n",
    "print(preprocess_val)\n",
    "preprocess_list = []\n",
    "for t in preprocess_val.transforms:\n",
    "    if isinstance(t, transforms.Normalize):\n",
    "        continue\n",
    "    preprocess_list.append(t)\n",
    "preprocess = transforms.Compose(preprocess_list)\n",
    "preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import CLIPProcessor\n",
    "import torch\n",
    "preprocess_val = CLIPProcessor.from_pretrained(\"vinid/plip\")\n",
    "data = torch.rand(3,224,224)\n",
    "tmp = preprocess_val(images=data, return_tensors=\"pt\")\n",
    "tmp['pixel_values']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "import open_clip\n",
    "\n",
    "model, _, preprocess = open_clip.create_model_and_transforms('ViT-B-16', pretrained='laion2b_s34b_b88k')\n",
    "model.eval()  # model in train mode by default, impacts some models with BatchNorm or stochastic depth active\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-16')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs: tensor([[0.8239, 0.1305, 0.0457]])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = preprocess(Image.open(\"3_31.jpg\")).unsqueeze(0)\n",
    "text = tokenizer([\"a diagram\", \"a dog\", \"a cat\"])\n",
    "\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    image_features = model.encode_image(image)\n",
    "    text_features = model.encode_text(text)\n",
    "    image_features /= image_features.norm(dim=-1, keepdim=True)\n",
    "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "    text_probs = (100.0 * image_features @ text_features.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs:\", text_probs)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unused or unrecognized kwargs: padding.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "\n",
    "model = CLIPModel.from_pretrained(\"vinid/plip\")\n",
    "processor = CLIPProcessor.from_pretrained(\"vinid/plip\")\n",
    "\n",
    "image = Image.open(\"3_31.jpg\")\n",
    "\n",
    "inputs = processor(text=[\"a photo of label 1\", \"a photo of label 2\"],\n",
    "                    images=image, return_tensors=\"pt\", padding=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "GatedRepoError",
     "evalue": "401 Client Error. (Request ID: Root=1-66a0b5c8-66547f145532fb2608aa9af8;2194cac4-4391-4caa-9273-0c71ba705963)\n\nCannot access gated repo for url https://hf-mirror.com/prov-gigapath/prov-gigapath/resolve/main/model.safetensors.\nAccess to model prov-gigapath/prov-gigapath is restricted. You must be authenticated to access it.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     response\u001b[39m.\u001b[39;49mraise_for_status()\n\u001b[1;32m    305\u001b[0m \u001b[39mexcept\u001b[39;00m HTTPError \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[39mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[39mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "\u001b[0;31mHTTPError\u001b[0m: 401 Client Error: Unauthorized for url: https://hf-mirror.com/prov-gigapath/prov-gigapath/resolve/main/model.safetensors",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mGatedRepoError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorchvision\u001b[39;00m \u001b[39mimport\u001b[39;00m transforms\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m tile_encoder \u001b[39m=\u001b[39m timm\u001b[39m.\u001b[39;49mcreate_model(\u001b[39m\"\u001b[39;49m\u001b[39mhf_hub:prov-gigapath/prov-gigapath\u001b[39;49m\u001b[39m\"\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m      8\u001b[0m transform \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose(\n\u001b[1;32m      9\u001b[0m     [\n\u001b[1;32m     10\u001b[0m         transforms\u001b[39m.\u001b[39mResize(\u001b[39m256\u001b[39m, interpolation\u001b[39m=\u001b[39mtransforms\u001b[39m.\u001b[39mInterpolationMode\u001b[39m.\u001b[39mBICUBIC),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     ]\n\u001b[1;32m     15\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/_factory.py:117\u001b[0m, in \u001b[0;36mcreate_model\u001b[0;34m(model_name, pretrained, pretrained_cfg, pretrained_cfg_overlay, checkpoint_path, scriptable, exportable, no_jit, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m create_fn \u001b[39m=\u001b[39m model_entrypoint(model_name)\n\u001b[1;32m    116\u001b[0m \u001b[39mwith\u001b[39;00m set_layer_config(scriptable\u001b[39m=\u001b[39mscriptable, exportable\u001b[39m=\u001b[39mexportable, no_jit\u001b[39m=\u001b[39mno_jit):\n\u001b[0;32m--> 117\u001b[0m     model \u001b[39m=\u001b[39m create_fn(\n\u001b[1;32m    118\u001b[0m         pretrained\u001b[39m=\u001b[39;49mpretrained,\n\u001b[1;32m    119\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    120\u001b[0m         pretrained_cfg_overlay\u001b[39m=\u001b[39;49mpretrained_cfg_overlay,\n\u001b[1;32m    121\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    122\u001b[0m     )\n\u001b[1;32m    124\u001b[0m \u001b[39mif\u001b[39;00m checkpoint_path:\n\u001b[1;32m    125\u001b[0m     load_checkpoint(model, checkpoint_path)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/vision_transformer.py:2479\u001b[0m, in \u001b[0;36mvit_giant_patch14_dinov2\u001b[0;34m(pretrained, **kwargs)\u001b[0m\n\u001b[1;32m   2471\u001b[0m \u001b[39m# The hidden_features of SwiGLU is calculated by:\u001b[39;00m\n\u001b[1;32m   2472\u001b[0m \u001b[39m# hidden_features = (int(hidden_features * 2 / 3) + 7) // 8 * 8\u001b[39;00m\n\u001b[1;32m   2473\u001b[0m \u001b[39m# When embed_dim=1536, hidden_features=4096\u001b[39;00m\n\u001b[1;32m   2474\u001b[0m \u001b[39m# With SwiGLUPacked, we need to set hidden_features = 2 * 4096 = 8192\u001b[39;00m\n\u001b[1;32m   2475\u001b[0m model_args \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m   2476\u001b[0m     patch_size\u001b[39m=\u001b[39m\u001b[39m14\u001b[39m, embed_dim\u001b[39m=\u001b[39m\u001b[39m1536\u001b[39m, depth\u001b[39m=\u001b[39m\u001b[39m40\u001b[39m, num_heads\u001b[39m=\u001b[39m\u001b[39m24\u001b[39m, init_values\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m,\n\u001b[1;32m   2477\u001b[0m     mlp_ratio\u001b[39m=\u001b[39m\u001b[39m2.66667\u001b[39m \u001b[39m*\u001b[39m \u001b[39m2\u001b[39m, mlp_layer\u001b[39m=\u001b[39mSwiGLUPacked, img_size\u001b[39m=\u001b[39m\u001b[39m518\u001b[39m, act_layer\u001b[39m=\u001b[39mnn\u001b[39m.\u001b[39mSiLU\n\u001b[1;32m   2478\u001b[0m )\n\u001b[0;32m-> 2479\u001b[0m model \u001b[39m=\u001b[39m _create_vision_transformer(\n\u001b[1;32m   2480\u001b[0m     \u001b[39m'\u001b[39;49m\u001b[39mvit_giant_patch14_dinov2\u001b[39;49m\u001b[39m'\u001b[39;49m, pretrained\u001b[39m=\u001b[39;49mpretrained, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mdict\u001b[39;49m(model_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs))\n\u001b[1;32m   2481\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/vision_transformer.py:1781\u001b[0m, in \u001b[0;36m_create_vision_transformer\u001b[0;34m(variant, pretrained, **kwargs)\u001b[0m\n\u001b[1;32m   1778\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39msiglip\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m variant \u001b[39mand\u001b[39;00m kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mglobal_pool\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mmap\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m   1779\u001b[0m     strict \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m-> 1781\u001b[0m \u001b[39mreturn\u001b[39;00m build_model_with_cfg(\n\u001b[1;32m   1782\u001b[0m     VisionTransformer,\n\u001b[1;32m   1783\u001b[0m     variant,\n\u001b[1;32m   1784\u001b[0m     pretrained,\n\u001b[1;32m   1785\u001b[0m     pretrained_filter_fn\u001b[39m=\u001b[39;49m_filter_fn,\n\u001b[1;32m   1786\u001b[0m     pretrained_strict\u001b[39m=\u001b[39;49mstrict,\n\u001b[1;32m   1787\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m   1788\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/_builder.py:410\u001b[0m, in \u001b[0;36mbuild_model_with_cfg\u001b[0;34m(model_cls, variant, pretrained, pretrained_cfg, pretrained_cfg_overlay, model_cfg, feature_cfg, pretrained_strict, pretrained_filter_fn, kwargs_filter, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m num_classes_pretrained \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mif\u001b[39;00m features \u001b[39melse\u001b[39;00m \u001b[39mgetattr\u001b[39m(model, \u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, kwargs\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mnum_classes\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m1000\u001b[39m))\n\u001b[1;32m    409\u001b[0m \u001b[39mif\u001b[39;00m pretrained:\n\u001b[0;32m--> 410\u001b[0m     load_pretrained(\n\u001b[1;32m    411\u001b[0m         model,\n\u001b[1;32m    412\u001b[0m         pretrained_cfg\u001b[39m=\u001b[39;49mpretrained_cfg,\n\u001b[1;32m    413\u001b[0m         num_classes\u001b[39m=\u001b[39;49mnum_classes_pretrained,\n\u001b[1;32m    414\u001b[0m         in_chans\u001b[39m=\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mget(\u001b[39m'\u001b[39;49m\u001b[39min_chans\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m3\u001b[39;49m),\n\u001b[1;32m    415\u001b[0m         filter_fn\u001b[39m=\u001b[39;49mpretrained_filter_fn,\n\u001b[1;32m    416\u001b[0m         strict\u001b[39m=\u001b[39;49mpretrained_strict,\n\u001b[1;32m    417\u001b[0m     )\n\u001b[1;32m    419\u001b[0m \u001b[39m# Wrap the model in a feature extraction module if enabled\u001b[39;00m\n\u001b[1;32m    420\u001b[0m \u001b[39mif\u001b[39;00m features:\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/_builder.py:190\u001b[0m, in \u001b[0;36mload_pretrained\u001b[0;34m(model, pretrained_cfg, num_classes, in_chans, filter_fn, strict)\u001b[0m\n\u001b[1;32m    188\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict_from_hf(\u001b[39m*\u001b[39mpretrained_loc)\n\u001b[1;32m    189\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m         state_dict \u001b[39m=\u001b[39m load_state_dict_from_hf(pretrained_loc)\n\u001b[1;32m    191\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    192\u001b[0m     model_name \u001b[39m=\u001b[39m pretrained_cfg\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39marchitecture\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mthis model\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/timm/models/_hub.py:179\u001b[0m, in \u001b[0;36mload_state_dict_from_hf\u001b[0;34m(model_id, filename)\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[39mfor\u001b[39;00m safe_filename \u001b[39min\u001b[39;00m _get_safe_alternatives(filename):\n\u001b[1;32m    178\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 179\u001b[0m         cached_safe_file \u001b[39m=\u001b[39m hf_hub_download(repo_id\u001b[39m=\u001b[39;49mhf_model_id, filename\u001b[39m=\u001b[39;49msafe_filename, revision\u001b[39m=\u001b[39;49mhf_revision)\n\u001b[1;32m    180\u001b[0m         _logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    181\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[\u001b[39m\u001b[39m{\u001b[39;00mmodel_id\u001b[39m}\u001b[39;00m\u001b[39m] Safe alternative available for \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mfilename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    182\u001b[0m             \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(as \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00msafe_filename\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m). Loading weights using safetensors.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    183\u001b[0m         \u001b[39mreturn\u001b[39;00m safetensors\u001b[39m.\u001b[39mtorch\u001b[39m.\u001b[39mload_file(cached_safe_file, device\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/file_download.py:1403\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1397\u001b[0m     \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1398\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mCannot find the requested files in the disk cache and outgoing traffic has been disabled. To enable\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1399\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m hf.co look-ups and downloads online, set \u001b[39m\u001b[39m'\u001b[39m\u001b[39mlocal_files_only\u001b[39m\u001b[39m'\u001b[39m\u001b[39m to False.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1400\u001b[0m     )\n\u001b[1;32m   1401\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, RepositoryNotFoundError) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(head_call_error, GatedRepoError):\n\u001b[1;32m   1402\u001b[0m     \u001b[39m# Repo not found or gated => let's raise the actual error\u001b[39;00m\n\u001b[0;32m-> 1403\u001b[0m     \u001b[39mraise\u001b[39;00m head_call_error\n\u001b[1;32m   1404\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1405\u001b[0m     \u001b[39m# Otherwise: most likely a connection issue or Hub downtime => let's warn the user\u001b[39;00m\n\u001b[1;32m   1406\u001b[0m     \u001b[39mraise\u001b[39;00m LocalEntryNotFoundError(\n\u001b[1;32m   1407\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mAn error happened while trying to locate the file on the Hub and we cannot find the requested files\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1408\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m in the local cache. Please check your connection and try again or make sure your Internet connection\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1409\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m is on.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1410\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mhead_call_error\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/file_download.py:1261\u001b[0m, in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, local_dir_use_symlinks, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, token, local_files_only, legacy_cache_layout, endpoint)\u001b[0m\n\u001b[1;32m   1259\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1260\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1261\u001b[0m         metadata \u001b[39m=\u001b[39m get_hf_file_metadata(\n\u001b[1;32m   1262\u001b[0m             url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1263\u001b[0m             token\u001b[39m=\u001b[39;49mtoken,\n\u001b[1;32m   1264\u001b[0m             proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1265\u001b[0m             timeout\u001b[39m=\u001b[39;49metag_timeout,\n\u001b[1;32m   1266\u001b[0m             library_name\u001b[39m=\u001b[39;49mlibrary_name,\n\u001b[1;32m   1267\u001b[0m             library_version\u001b[39m=\u001b[39;49mlibrary_version,\n\u001b[1;32m   1268\u001b[0m             user_agent\u001b[39m=\u001b[39;49muser_agent,\n\u001b[1;32m   1269\u001b[0m         )\n\u001b[1;32m   1270\u001b[0m     \u001b[39mexcept\u001b[39;00m EntryNotFoundError \u001b[39mas\u001b[39;00m http_error:\n\u001b[1;32m   1271\u001b[0m         \u001b[39m# Cache the non-existence of the file and raise\u001b[39;00m\n\u001b[1;32m   1272\u001b[0m         commit_hash \u001b[39m=\u001b[39m http_error\u001b[39m.\u001b[39mresponse\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(HUGGINGFACE_HEADER_X_REPO_COMMIT)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/utils/_validators.py:118\u001b[0m, in \u001b[0;36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[39mif\u001b[39;00m check_use_auth_token:\n\u001b[1;32m    116\u001b[0m     kwargs \u001b[39m=\u001b[39m smoothly_deprecate_use_auth_token(fn_name\u001b[39m=\u001b[39mfn\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, has_token\u001b[39m=\u001b[39mhas_token, kwargs\u001b[39m=\u001b[39mkwargs)\n\u001b[0;32m--> 118\u001b[0m \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/file_download.py:1667\u001b[0m, in \u001b[0;36mget_hf_file_metadata\u001b[0;34m(url, token, proxies, timeout, library_name, library_version, user_agent)\u001b[0m\n\u001b[1;32m   1664\u001b[0m headers[\u001b[39m\"\u001b[39m\u001b[39mAccept-Encoding\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39midentity\u001b[39m\u001b[39m\"\u001b[39m  \u001b[39m# prevent any compression => we want to know the real size of the file\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \u001b[39m# Retrieve metadata\u001b[39;00m\n\u001b[0;32m-> 1667\u001b[0m r \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m   1668\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mHEAD\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1669\u001b[0m     url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m   1670\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[1;32m   1671\u001b[0m     allow_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m   1672\u001b[0m     follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1673\u001b[0m     proxies\u001b[39m=\u001b[39;49mproxies,\n\u001b[1;32m   1674\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[1;32m   1675\u001b[0m )\n\u001b[1;32m   1676\u001b[0m hf_raise_for_status(r)\n\u001b[1;32m   1678\u001b[0m \u001b[39m# Return\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/file_download.py:385\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[39m# Recursively follow relative redirects\u001b[39;00m\n\u001b[1;32m    384\u001b[0m \u001b[39mif\u001b[39;00m follow_relative_redirects:\n\u001b[0;32m--> 385\u001b[0m     response \u001b[39m=\u001b[39m _request_wrapper(\n\u001b[1;32m    386\u001b[0m         method\u001b[39m=\u001b[39;49mmethod,\n\u001b[1;32m    387\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[1;32m    388\u001b[0m         follow_relative_redirects\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m    389\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mparams,\n\u001b[1;32m    390\u001b[0m     )\n\u001b[1;32m    392\u001b[0m     \u001b[39m# If redirection, we redirect only relative paths.\u001b[39;00m\n\u001b[1;32m    393\u001b[0m     \u001b[39m# This is useful in case of a renamed repository.\u001b[39;00m\n\u001b[1;32m    394\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m300\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m response\u001b[39m.\u001b[39mstatus_code \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m399\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/file_download.py:409\u001b[0m, in \u001b[0;36m_request_wrapper\u001b[0;34m(method, url, follow_relative_redirects, **params)\u001b[0m\n\u001b[1;32m    407\u001b[0m \u001b[39m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[1;32m    408\u001b[0m response \u001b[39m=\u001b[39m get_session()\u001b[39m.\u001b[39mrequest(method\u001b[39m=\u001b[39mmethod, url\u001b[39m=\u001b[39murl, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams)\n\u001b[0;32m--> 409\u001b[0m hf_raise_for_status(response)\n\u001b[1;32m    410\u001b[0m \u001b[39mreturn\u001b[39;00m response\n",
      "File \u001b[0;32m~/anaconda3/envs/biomed/lib/python3.8/site-packages/huggingface_hub/utils/_errors.py:321\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[39melif\u001b[39;00m error_code \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mGatedRepo\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    318\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    319\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mCannot access gated repo for url \u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39murl\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    320\u001b[0m     )\n\u001b[0;32m--> 321\u001b[0m     \u001b[39mraise\u001b[39;00m GatedRepoError(message, response) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[1;32m    323\u001b[0m \u001b[39melif\u001b[39;00m error_message \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAccess to this resource is disabled.\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    324\u001b[0m     message \u001b[39m=\u001b[39m (\n\u001b[1;32m    325\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mresponse\u001b[39m.\u001b[39mstatus_code\u001b[39m}\u001b[39;00m\u001b[39m Client Error.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    326\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    329\u001b[0m         \u001b[39m+\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mAccess to this resource is disabled.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    330\u001b[0m     )\n",
      "\u001b[0;31mGatedRepoError\u001b[0m: 401 Client Error. (Request ID: Root=1-66a0b5c8-66547f145532fb2608aa9af8;2194cac4-4391-4caa-9273-0c71ba705963)\n\nCannot access gated repo for url https://hf-mirror.com/prov-gigapath/prov-gigapath/resolve/main/model.safetensors.\nAccess to model prov-gigapath/prov-gigapath is restricted. You must be authenticated to access it."
     ]
    }
   ],
   "source": [
    "import timm\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "\n",
    "tile_encoder = timm.create_model(\"hf_hub:prov-gigapath/prov-gigapath\", pretrained=True)\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(256, interpolation=transforms.InterpolationMode.BICUBIC),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 9])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "tensor1 = torch.randn(3, 4)\n",
    "tensor2 = torch.randn(3, 5)\n",
    "tensor_cat = torch.cat((tensor1, tensor2), dim=-1)\n",
    "tensor_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实际\\预测\t|\tNILM\t|\tASC-US\t|\tASC-H\t|\t总计\n",
      "--------------------------------------------------------------------------------\n",
      "NILM\t\t|\t2\t|\t1\t|\t0\t|\t3\n",
      "--------------------------------------------------------------------------------\n",
      "ASC-US\t\t|\t0\t|\t1\t|\t2\t|\t3\n",
      "--------------------------------------------------------------------------------\n",
      "ASC-H\t\t|\t1\t|\t2\t|\t0\t|\t3\n",
      "--------------------------------------------------------------------------------\n",
      "总计\t\t|\t3\t|\t4\t|\t2\t|\t9\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 重新定义混淆矩阵和类别数量\n",
    "cm_manual = [\n",
    "    [2, 1, 0],  # 实际类别 0\n",
    "    [0, 1, 2],  # 实际类别 1\n",
    "    [1, 2, 0]   # 实际类别 2\n",
    "]\n",
    "num_classes = len(cm_manual)  # 类别数量\n",
    "\n",
    "# 重新计算行和列的总计\n",
    "row_totals = [sum(row) for row in cm_manual]\n",
    "col_totals = [sum(col) for col in zip(*cm_manual)]\n",
    "total = sum(row_totals)\n",
    "class_labels = ['NILM', 'ASC-US', 'ASC-H']\n",
    "\n",
    "# 重新格式化混淆矩阵，确保第一行包含类别名称\n",
    "formatted_cm_with_labels = \"实际\\预测\\t|\\t\" + \"\\t|\\t\".join(map(str, class_labels)) + \"\\t|\\t总计\\n\"\n",
    "formatted_cm_with_labels += \"-\" * ((len(class_labels)+2) * 16) + \"\\n\"\n",
    "for i, label in enumerate(class_labels):\n",
    "    formatted_cm_with_labels += label + \"\\t\\t|\\t\"\n",
    "    for j in range(num_classes):\n",
    "        formatted_cm_with_labels += str(cm_manual[i][j]) + \"\\t|\\t\"\n",
    "    formatted_cm_with_labels += str(row_totals[i]) + \"\\n\"\n",
    "    formatted_cm_with_labels += \"-\" * ((len(class_labels)+2) * 16) + \"\\n\"\n",
    "formatted_cm_with_labels += \"总计\\t\\t|\\t\" + \"\\t|\\t\".join(map(str, col_totals)) + \"\\t|\\t\" + str(total) + \"\\n\"\n",
    "\n",
    "print(formatted_cm_with_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第一个小于75的元素的位置是: (tensor(0), tensor(0))\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def find_first_less_than(tensor, target):\n",
    "    # 找到所有小于目标值的元素的位置\n",
    "    less_than_target = torch.where(tensor < target)\n",
    "    \n",
    "    # 如果没有找到，返回-1\n",
    "    if len(less_than_target[0]) == 0:\n",
    "        return -1\n",
    "    \n",
    "    # 返回第一个小于目标值的元素的位置\n",
    "    return (less_than_target[0][0], less_than_target[1][0])\n",
    "\n",
    "# 示例张量\n",
    "tensor = torch.tensor([[10, 20, 30, 40],\n",
    "                       [50, 60, 70, 80],\n",
    "                       [90, 100, 110, 120]])\n",
    "\n",
    "# 目标值\n",
    "target_value = 75\n",
    "\n",
    "# 调用函数\n",
    "position = find_first_less_than(tensor, target_value)\n",
    "\n",
    "print(f\"第一个小于{target_value}的元素的位置是: {position}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomed-clip",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
