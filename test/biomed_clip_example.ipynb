{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "t8BYG2CFF6wD"
      },
      "source": [
        "### Install libraries\n",
        "<font color='red'>**Make sure to restart the Colab runtime after installation**</font>\n",
        "\n",
        "Colab Menu -> Runtime -> Restart runtime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
            "Collecting open_clip_torch\n",
            "  Using cached https://pypi.tuna.tsinghua.edu.cn/packages/7c/7f/952fdffa17b15d0c7c51a730860fcf4f4982528ecc753b190dcd46cc944b/open_clip_torch-2.23.0-py3-none-any.whl (1.5 MB)\n",
            "Requirement already satisfied: transformers in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (4.30.2)\n",
            "Requirement already satisfied: matplotlib in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (3.5.3)\n",
            "Requirement already satisfied: torchvision in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (0.10.0)\n",
            "Requirement already satisfied: ftfy in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (6.1.1)\n",
            "Requirement already satisfied: tqdm in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (4.65.2)\n",
            "Requirement already satisfied: timm in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (0.9.12)\n",
            "Requirement already satisfied: sentencepiece in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (0.1.99)\n",
            "Requirement already satisfied: protobuf in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (3.20.3)\n",
            "Requirement already satisfied: huggingface-hub in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (0.16.4)\n",
            "Requirement already satisfied: regex in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (2023.10.3)\n",
            "Requirement already satisfied: torch>=1.9.0 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from open_clip_torch) (1.9.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (0.4.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: requests in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (2.28.2)\n",
            "Requirement already satisfied: filelock in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (3.12.2)\n",
            "Requirement already satisfied: importlib-metadata in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (6.7.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (9.5.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (4.38.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from matplotlib) (0.11.0)\n",
            "Requirement already satisfied: fsspec in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (2023.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from huggingface-hub->open_clip_torch) (4.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from ftfy->open_clip_torch) (0.2.6)\n",
            "Requirement already satisfied: zipp>=0.5 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from importlib-metadata->transformers) (3.15.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/huangjialong/miniconda3/envs/dist-pu/lib/python3.7/site-packages (from requests->transformers) (3.2.0)\n",
            "Installing collected packages: open_clip_torch\n",
            "Successfully installed open_clip_torch-2.23.0\n"
          ]
        }
      ],
      "source": [
        "!pip install open_clip_torch transformers matplotlib"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kaOyeKkjqnri"
      },
      "source": [
        "## Load BiomedCLIP model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V8Yv9g_8EQ1W",
        "outputId": "3ec24c9b-4c4f-4c17-8d76-6cfd74bb8bdf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "import open_clip\n",
        "\n",
        "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
        "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Compose(\n",
            "    Resize(size=224, interpolation=bicubic, max_size=None, antialias=None)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    <function _convert_to_rgb at 0x7f65343ebdd0>\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.48145466, 0.4578275, 0.40821073], std=[0.26862954, 0.26130258, 0.27577711])\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(preprocess_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torchvision.transforms.transforms.Compose"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(preprocess_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CustomTextCLIP(\n",
            "  (visual): TimmModel(\n",
            "    (trunk): VisionTransformer(\n",
            "      (patch_embed): PatchEmbed(\n",
            "        (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
            "        (norm): Identity()\n",
            "      )\n",
            "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
            "      (patch_drop): Identity()\n",
            "      (norm_pre): Identity()\n",
            "      (blocks): Sequential(\n",
            "        (0): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (1): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (2): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (3): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (4): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (5): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (6): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (7): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (8): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (9): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (10): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "        (11): Block(\n",
            "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (attn): Attention(\n",
            "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
            "            (q_norm): Identity()\n",
            "            (k_norm): Identity()\n",
            "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
            "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls1): Identity()\n",
            "          (drop_path1): Identity()\n",
            "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "          (mlp): Mlp(\n",
            "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
            "            (act): GELU(approximate='none')\n",
            "            (drop1): Dropout(p=0.0, inplace=False)\n",
            "            (norm): Identity()\n",
            "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
            "            (drop2): Dropout(p=0.0, inplace=False)\n",
            "          )\n",
            "          (ls2): Identity()\n",
            "          (drop_path2): Identity()\n",
            "        )\n",
            "      )\n",
            "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
            "      (fc_norm): Identity()\n",
            "      (head_drop): Dropout(p=0.0, inplace=False)\n",
            "      (head): Identity()\n",
            "    )\n",
            "    (head): Sequential(\n",
            "      (drop): Dropout(p=0.0, inplace=False)\n",
            "      (proj): Linear(in_features=768, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            "  (text): HFTextEncoder(\n",
            "    (transformer): BertModel(\n",
            "      (embeddings): BertEmbeddings(\n",
            "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "        (position_embeddings): Embedding(512, 768)\n",
            "        (token_type_embeddings): Embedding(2, 768)\n",
            "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "      (encoder): BertEncoder(\n",
            "        (layer): ModuleList(\n",
            "          (0): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (1): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (2): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (3): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (4): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (5): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (6): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (7): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (8): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (9): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (10): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "          (11): BertLayer(\n",
            "            (attention): BertAttention(\n",
            "              (self): BertSelfAttention(\n",
            "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "              (output): BertSelfOutput(\n",
            "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "                (dropout): Dropout(p=0.1, inplace=False)\n",
            "              )\n",
            "            )\n",
            "            (intermediate): BertIntermediate(\n",
            "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "              (intermediate_act_fn): GELUActivation()\n",
            "            )\n",
            "            (output): BertOutput(\n",
            "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "              (dropout): Dropout(p=0.1, inplace=False)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "    (pooler): ClsLastHiddenStatePooler()\n",
            "    (proj): Sequential(\n",
            "      (0): Linear(in_features=768, out_features=640, bias=False)\n",
            "      (1): GELU(approximate='none')\n",
            "      (2): Linear(in_features=640, out_features=512, bias=False)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "print(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import open_clip\n",
        "\n",
        "dataset_path = 'test-imgs'\n",
        "template = 'this is a photo of '\n",
        "labels = [\n",
        "    'adenocarcinoma histopathology',\n",
        "    'brain MRI',\n",
        "    'covid line chart',\n",
        "    'squamous cell carcinoma histopathology',\n",
        "    'immunohistochemistry histopathology',\n",
        "    'bone X-ray',\n",
        "    'chest X-ray',\n",
        "    'pie chart',\n",
        "    'hematoxylin and eosin histopathology'\n",
        "]\n",
        "\n",
        "test_imgs = glob.glob(dataset_path + '/*')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "context_length = 256\n",
        "\n",
        "images = torch.stack([preprocess_val(Image.open(img)) for img in test_imgs]).to(device)\n",
        "texts = tokenizer([template + l for l in labels], context_length=context_length).to(device)\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # image_features @ text_features.t()执行了图像特征和文本特征之间的点积操作，生成了一个分数矩阵。然后，通过乘以logit_scale对分数矩阵进行缩放。这个缩放过程可以增加或减小点积的值，从而影响最终的logits结果。\n",
        "    \n",
        "    image_features, text_features, logit_scale = model(images, texts)\n",
        "    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
        "    sorted_indices = torch.argsort(logits, dim=-1, descending=True)\n",
        "\n",
        "    logits = logits.cpu().numpy()\n",
        "    sorted_indices = sorted_indices.cpu().numpy()\n",
        "\n",
        "top_k = -1\n",
        "\n",
        "# for i, img in enumerate(test_imgs):\n",
        "#     pred = labels[sorted_indices[i][0]]\n",
        "\n",
        "#     top_k = len(labels) if top_k == -1 else top_k\n",
        "#     print(img.split('/')[-1] + ':')\n",
        "#     for j in range(top_k):\n",
        "#         jth_index = sorted_indices[i][j]\n",
        "#         print(f'{labels[jth_index]}: {logits[i][jth_index]}')\n",
        "#     print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "image_features, text_features, logit_scale = model(images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 512])\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'shape'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_128747/538315753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "print(image_features.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([4, 9])"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 512])\n",
            "tensor(87.3208, device='cuda:0')\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)\n",
        "print(image_features.shape)\n",
        "print(logit_scale)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "bk0hm1R7qqU_"
      },
      "source": [
        "# Download sample images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "692f8c386f9743a1a12f7d6c7959ca67",
            "3e0f188e73294f6ea4d1e28640cfdc22",
            "b754e18c5c49499d92db4803cfa426b7",
            "6743cbc5ca2c47e7be565e0d6cd933c9",
            "02aa2c49f2a94a7eb48794ed783c93e8",
            "ad84c0ed082d4ab7abf2815fc1910efa",
            "87a18840cc2c45ac824e8fe3d83d5150",
            "0b3b4fc0e99a47d0a494aee20166337f",
            "2de24c12eebd4054a3e6163fb6951986",
            "1c9af9a39e594c689590d09ae71baeb3",
            "182cc15b918a45d081543a6b3f182a07"
          ]
        },
        "id": "qqafKW1kqgc4",
        "outputId": "34c29f78-32c5-4a6f-914e-30e8a07840a6"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_113859/870063421.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhuggingface_hub\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msnapshot_download\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"biomed-clip-share\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/_snapshot_download.py\u001b[0m in \u001b[0;36msnapshot_download\u001b[0;34m(repo_id, revision, repo_type, cache_dir, local_dir, local_dir_use_symlinks, library_name, library_version, user_agent, proxies, etag_timeout, resume_download, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class)\u001b[0m\n\u001b[1;32m    184\u001b[0m     \u001b[0;31m# if we have internet connection we retrieve the correct folder name from the huggingface api\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0mapi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mHfApi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlibrary_version\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlibrary_version\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_agent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muser_agent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m     \u001b[0mrepo_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mapi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepo_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepo_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrepo_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrevision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m     \u001b[0;32massert\u001b[0m \u001b[0mrepo_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msha\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Repo info returned from server must have a revision sha.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mrepo_info\u001b[0;34m(self, repo_id, revision, repo_type, timeout, files_metadata, token)\u001b[0m\n\u001b[1;32m   1871\u001b[0m             \u001b[0mtoken\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1872\u001b[0m             \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1873\u001b[0;31m             \u001b[0mfiles_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfiles_metadata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1874\u001b[0m         )\n\u001b[1;32m   1875\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    116\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msmoothly_deprecate_use_auth_token\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhas_token\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhas_token\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inner_fn\u001b[0m  \u001b[0;31m# type: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/hf_api.py\u001b[0m in \u001b[0;36mmodel_info\u001b[0;34m(self, repo_id, revision, timeout, securityStatus, files_metadata, token)\u001b[0m\n\u001b[1;32m   1675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfiles_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1676\u001b[0m             \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"blobs\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1677\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1678\u001b[0m         \u001b[0mhf_raise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1679\u001b[0m         \u001b[0md\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, url, **kwargs)\u001b[0m\n\u001b[1;32m    600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"allow_redirects\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 602\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    603\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    587\u001b[0m         }\n\u001b[1;32m    588\u001b[0m         \u001b[0msend_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0msend_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/requests/sessions.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;31m# Send the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0madapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0;31m# Total elapsed time of the request (approximately)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/huggingface_hub/utils/_http.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, *args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;34m\"\"\"Catch any RequestException to append request id to the error message for debugging.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_AMZN_TRACE_ID\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/requests/adapters.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    495\u001b[0m                 \u001b[0mretries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m                 \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m                 \u001b[0mchunked\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunked\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m             )\n\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[1;32m    800\u001b[0m                 \u001b[0mpreload_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpreload_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m                 \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m                 \u001b[0;34m**\u001b[0m\u001b[0mresponse_kw\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m             )\n\u001b[1;32m    804\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_make_request\u001b[0;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0;31m# Trigger any extra validation we need to do.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mSocketTimeout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBaseSSLError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_timeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/connectionpool.py\u001b[0m in \u001b[0;36m_validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1090\u001b[0m         \u001b[0;31m# Force connect early to allow us to validate the connection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1092\u001b[0;31m             \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1094\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mconn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verified\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36mconnect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    609\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m         \u001b[0msock\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0mssl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSLSocket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msock\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new_conn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m         \u001b[0mserver_hostname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m         \u001b[0mtls_in_tls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/connection.py\u001b[0m in \u001b[0;36m_new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m                 \u001b[0msource_address\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 207\u001b[0;31m                 \u001b[0msocket_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msocket_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    208\u001b[0m             )\n\u001b[1;32m    209\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaierror\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/anaconda3/envs/biomed-clip/lib/python3.7/site-packages/urllib3/util/connection.py\u001b[0m in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0msource_address\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m                 \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_address\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msa\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m             \u001b[0;31m# Break explicitly a reference cycle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from huggingface_hub import snapshot_download\n",
        "snapshot_download(\"microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224\", local_dir=\"biomed-clip-share\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4WOxBdKr0e_m",
        "outputId": "2a05beae-6f5f-4c3c-ef59-b23210b6e1b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LICENSE.md\t\t   example_data\t\t\ttokenizer.json\n",
            "README.md\t\t   open_clip_config.json\ttokenizer_config.json\n",
            "biomed-vlp-eval.svg\t   open_clip_pytorch_model.bin\tvocab.txt\n",
            "biomed_clip_example.ipynb  special_tokens_map.json\n"
          ]
        }
      ],
      "source": [
        "!ls biomed-clip-share"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_11A5zFuGfkG"
      },
      "source": [
        "### Example: Zero-shot classifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSJw7Qpm1w-f",
        "outputId": "c8e69acc-09a6-41ac-a719-e0c2016e41d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1_0.jpg:\n",
            "bone X-ray: 0.9508612155914307\n",
            "chest X-ray: 0.01612868346273899\n",
            "hematoxylin and eosin histopathology: 0.01566678285598755\n",
            "brain MRI: 0.010328284464776516\n",
            "immunohistochemistry histopathology: 0.0070085967890918255\n",
            "squamous cell carcinoma histopathology: 5.719150067307055e-06\n",
            "pie chart: 6.289538418968732e-07\n",
            "covid line chart: 1.251025025794661e-07\n",
            "adenocarcinoma histopathology: 3.94438295359123e-08\n",
            "\n",
            "\n",
            "1_1.jpg:\n",
            "bone X-ray: 0.44941678643226624\n",
            "chest X-ray: 0.3400369882583618\n",
            "brain MRI: 0.1125471368432045\n",
            "immunohistochemistry histopathology: 0.0572371743619442\n",
            "hematoxylin and eosin histopathology: 0.03944217413663864\n",
            "adenocarcinoma histopathology: 0.0009473594836890697\n",
            "squamous cell carcinoma histopathology: 0.0003590733977034688\n",
            "pie chart: 1.1667721992125735e-05\n",
            "covid line chart: 1.6377296105929418e-06\n",
            "\n",
            "\n",
            "1_2.jpg:\n",
            "bone X-ray: 0.8977609872817993\n",
            "brain MRI: 0.047738853842020035\n",
            "immunohistochemistry histopathology: 0.025508597493171692\n",
            "hematoxylin and eosin histopathology: 0.018282264471054077\n",
            "chest X-ray: 0.010700441896915436\n",
            "pie chart: 7.813167030690238e-06\n",
            "squamous cell carcinoma histopathology: 7.616545190103352e-07\n",
            "covid line chart: 2.788729318581318e-07\n",
            "adenocarcinoma histopathology: 4.478018400533301e-09\n",
            "\n",
            "\n",
            "1_3.jpg:\n",
            "bone X-ray: 0.8831093311309814\n",
            "brain MRI: 0.06809093803167343\n",
            "chest X-ray: 0.0370124951004982\n",
            "immunohistochemistry histopathology: 0.006547426339238882\n",
            "hematoxylin and eosin histopathology: 0.005201656371355057\n",
            "squamous cell carcinoma histopathology: 3.0592989787692204e-05\n",
            "pie chart: 5.423786660685437e-06\n",
            "adenocarcinoma histopathology: 1.3579732467405847e-06\n",
            "covid line chart: 8.214050239985227e-07\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "from collections import OrderedDict\n",
        "\n",
        "import torch\n",
        "from PIL import Image\n",
        "import open_clip\n",
        "\n",
        "dataset_path = 'test-imgs'\n",
        "template = 'this is a photo of '\n",
        "labels = [\n",
        "    'adenocarcinoma histopathology',\n",
        "    'brain MRI',\n",
        "    'covid line chart',\n",
        "    'squamous cell carcinoma histopathology',\n",
        "    'immunohistochemistry histopathology',\n",
        "    'bone X-ray',\n",
        "    'chest X-ray',\n",
        "    'pie chart',\n",
        "    'hematoxylin and eosin histopathology'\n",
        "]\n",
        "\n",
        "test_imgs = glob.glob(dataset_path + '/*')\n",
        "\n",
        "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "model.to(device)\n",
        "model.eval()\n",
        "\n",
        "context_length = 256\n",
        "\n",
        "images = torch.stack([preprocess_val(Image.open(img)) for img in test_imgs]).to(device)\n",
        "texts = tokenizer([template + l for l in labels], context_length=context_length).to(device)\n",
        "with torch.no_grad():\n",
        "    \n",
        "    # image_features @ text_features.t()执行了图像特征和文本特征之间的点积操作，生成了一个分数矩阵。然后，通过乘以logit_scale对分数矩阵进行缩放。这个缩放过程可以增加或减小点积的值，从而影响最终的logits结果。\n",
        "    \n",
        "    image_features, text_features, logit_scale = model(images, texts)\n",
        "    logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
        "    sorted_indices = torch.argsort(logits, dim=-1, descending=True)\n",
        "\n",
        "    logits = logits.cpu().numpy()\n",
        "    sorted_indices = sorted_indices.cpu().numpy()\n",
        "\n",
        "top_k = -1\n",
        "\n",
        "for i, img in enumerate(test_imgs):\n",
        "    pred = labels[sorted_indices[i][0]]\n",
        "\n",
        "    top_k = len(labels) if top_k == -1 else top_k\n",
        "    print(img.split('/')[-1] + ':')\n",
        "    for j in range(top_k):\n",
        "        jth_index = sorted_indices[i][j]\n",
        "        print(f'{labels[jth_index]}: {logits[i][jth_index]}')\n",
        "    print('\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 224, 224])\n",
            "torch.Size([4, 512])\n"
          ]
        }
      ],
      "source": [
        "print(images.shape)\n",
        "print(image_features.shape)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "kIZEaLJB5H6A"
      },
      "source": [
        "<h2>Expected outputs</h2>\n",
        "<details>\n",
        "<pre>\n",
        "adenocarcinoma_histopathology.jpg:\n",
        "adenocarcinoma histopathology: 0.7818863987922668\n",
        "hematoxylin and eosin histopathology: 0.15517690777778625\n",
        "immunohistochemistry histopathology: 0.06149514392018318\n",
        "squamous cell carcinoma histopathology: 0.0014182085869833827\n",
        "chest X-ray: 2.017213228100445e-05\n",
        "brain MRI: 1.2181524198240368e-06\n",
        "pie chart: 7.932688959044754e-07\n",
        "bone X-ray: 7.436410101036017e-07\n",
        "covid line chart: 4.482610052036762e-07\n",
        "\n",
        "\n",
        "covid_line_chart.png:\n",
        "covid line chart: 0.9493210315704346\n",
        "adenocarcinoma histopathology: 0.01898195780813694\n",
        "squamous cell carcinoma histopathology: 0.0175501499325037\n",
        "immunohistochemistry histopathology: 0.006791787222027779\n",
        "hematoxylin and eosin histopathology: 0.003417333820834756\n",
        "brain MRI: 0.002629919210448861\n",
        "chest X-ray: 0.0010041205678135157\n",
        "bone X-ray: 0.00024685842799954116\n",
        "pie chart: 5.6812208640621975e-05\n",
        "\n",
        "\n",
        "bone_X-ray.jpg:\n",
        "bone X-ray: 0.9037961959838867\n",
        "hematoxylin and eosin histopathology: 0.07279316335916519\n",
        "brain MRI: 0.013534954749047756\n",
        "chest X-ray: 0.00821212213486433\n",
        "immunohistochemistry histopathology: 0.001647887285798788\n",
        "squamous cell carcinoma histopathology: 1.418814281350933e-05\n",
        "covid line chart: 1.1351590956110158e-06\n",
        "adenocarcinoma histopathology: 2.3802124360372545e-07\n",
        "pie chart: 9.433303205241828e-08\n",
        "\n",
        "\n",
        "pie_chart.png:\n",
        "pie chart: 0.999992847442627\n",
        "covid line chart: 6.056906840967713e-06\n",
        "brain MRI: 6.212158041307703e-07\n",
        "bone X-ray: 1.870277799298492e-07\n",
        "chest X-ray: 1.4315827456812258e-07\n",
        "immunohistochemistry histopathology: 7.397970591682679e-08\n",
        "hematoxylin and eosin histopathology: 1.3329795045535775e-08\n",
        "adenocarcinoma histopathology: 7.695367898463701e-09\n",
        "squamous cell carcinoma histopathology: 4.512833662317917e-09\n",
        "\n",
        "\n",
        "H_and_E_histopathology.jpg:\n",
        "hematoxylin and eosin histopathology: 0.7953251600265503\n",
        "immunohistochemistry histopathology: 0.19779996573925018\n",
        "chest X-ray: 0.005973907187581062\n",
        "bone X-ray: 0.0008049230673350394\n",
        "adenocarcinoma histopathology: 9.133991261478513e-05\n",
        "squamous cell carcinoma histopathology: 3.6423973597266013e-06\n",
        "brain MRI: 6.688684948130685e-07\n",
        "pie chart: 4.278819574210502e-07\n",
        "covid line chart: 3.051619401617245e-08\n",
        "\n",
        "\n",
        "brain_MRI.jpg:\n",
        "brain MRI: 0.9565795660018921\n",
        "hematoxylin and eosin histopathology: 0.041418157517910004\n",
        "immunohistochemistry histopathology: 0.0019450499676167965\n",
        "pie chart: 2.7151252652402036e-05\n",
        "squamous cell carcinoma histopathology: 1.0223812751064543e-05\n",
        "bone X-ray: 8.662499567435589e-06\n",
        "chest X-ray: 7.96773747424595e-06\n",
        "adenocarcinoma histopathology: 2.7692055937222904e-06\n",
        "covid line chart: 3.420084908611898e-07\n",
        "\n",
        "\n",
        "chest_X-ray.jpg:\n",
        "chest X-ray: 0.9998347759246826\n",
        "hematoxylin and eosin histopathology: 0.0001205605294671841\n",
        "bone X-ray: 4.112880560569465e-05\n",
        "immunohistochemistry histopathology: 1.0486423889233265e-06\n",
        "adenocarcinoma histopathology: 9.66637117016944e-07\n",
        "covid line chart: 9.508977996119938e-07\n",
        "brain MRI: 3.232386518448038e-07\n",
        "squamous cell carcinoma histopathology: 2.53368597213921e-07\n",
        "pie chart: 3.6984038054299617e-09\n",
        "\n",
        "\n",
        "squamous_cell_carcinoma_histopathology.jpeg:\n",
        "squamous cell carcinoma histopathology: 0.9469489455223083\n",
        "adenocarcinoma histopathology: 0.05259034037590027\n",
        "hematoxylin and eosin histopathology: 0.0003988408425357193\n",
        "immunohistochemistry histopathology: 6.187965482240543e-05\n",
        "chest X-ray: 1.4099594380923008e-08\n",
        "pie chart: 3.522500624519864e-10\n",
        "bone X-ray: 2.9633814846441453e-10\n",
        "brain MRI: 1.2720452469139332e-10\n",
        "covid line chart: 1.8425603924565603e-12\n",
        "\n",
        "\n",
        "IHC_histopathology.jpg:\n",
        "immunohistochemistry histopathology: 0.9465934634208679\n",
        "hematoxylin and eosin histopathology: 0.03232448548078537\n",
        "brain MRI: 0.020657211542129517\n",
        "adenocarcinoma histopathology: 0.000304735847748816\n",
        "bone X-ray: 4.5735167077509686e-05\n",
        "squamous cell carcinoma histopathology: 3.150868360535242e-05\n",
        "covid line chart: 2.0559578842949122e-05\n",
        "chest X-ray: 1.2715442608168814e-05\n",
        "pie chart: 9.55282575887395e-06\n",
        "</pre>\n",
        "</details>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zE5vznWj2CCf",
        "outputId": "34d02bdd-3a87-4bf5-807b-42800a6d0170"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_images_with_metadata(images, metadata):\n",
        "    num_images = len(images)\n",
        "    fig, axes = plt.subplots(nrows=num_images, ncols=1, figsize=(5, 5 * num_images))\n",
        "\n",
        "    for i, (img_path, metadata) in enumerate(zip(images, metadata)):\n",
        "        img = Image.open(img_path)\n",
        "        ax = axes[i]\n",
        "        ax.imshow(img)\n",
        "        ax.axis('off')\n",
        "        ax.set_title(f\"{metadata['filename']}\\n{metadata['top_probs']}\", fontsize=14)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "metadata_list = []\n",
        "\n",
        "top_k = 3\n",
        "for i, img in enumerate(test_imgs):\n",
        "    pred = labels[sorted_indices[i][0]]\n",
        "    img_name = img.split('/')[-1]\n",
        "\n",
        "    top_probs = []\n",
        "    top_k = len(labels) if top_k == -1 else top_k\n",
        "    for j in range(top_k):\n",
        "        jth_index = sorted_indices[i][j]\n",
        "        top_probs.append(f\"{labels[jth_index]}: {logits[i][jth_index] * 100:.1f}\")\n",
        "\n",
        "    metadata = {'filename': img_name, 'top_probs': '\\n'.join(top_probs)}\n",
        "    metadata_list.append(metadata)\n",
        "\n",
        "plot_images_with_metadata(test_imgs, metadata_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9i86dr-947h9"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('biomed-clip')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "vscode": {
      "interpreter": {
        "hash": "7cb5855cefb5e02dc34c4de578bb315cb99c7d65be2e4fad60d8d2596700f443"
      }
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02aa2c49f2a94a7eb48794ed783c93e8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b3b4fc0e99a47d0a494aee20166337f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "182cc15b918a45d081543a6b3f182a07": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c9af9a39e594c689590d09ae71baeb3": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2de24c12eebd4054a3e6163fb6951986": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3e0f188e73294f6ea4d1e28640cfdc22": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad84c0ed082d4ab7abf2815fc1910efa",
            "placeholder": "​",
            "style": "IPY_MODEL_87a18840cc2c45ac824e8fe3d83d5150",
            "value": "Fetching 21 files: 100%"
          }
        },
        "6743cbc5ca2c47e7be565e0d6cd933c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c9af9a39e594c689590d09ae71baeb3",
            "placeholder": "​",
            "style": "IPY_MODEL_182cc15b918a45d081543a6b3f182a07",
            "value": " 21/21 [00:00&lt;00:00, 20.35it/s]"
          }
        },
        "692f8c386f9743a1a12f7d6c7959ca67": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e0f188e73294f6ea4d1e28640cfdc22",
              "IPY_MODEL_b754e18c5c49499d92db4803cfa426b7",
              "IPY_MODEL_6743cbc5ca2c47e7be565e0d6cd933c9"
            ],
            "layout": "IPY_MODEL_02aa2c49f2a94a7eb48794ed783c93e8"
          }
        },
        "87a18840cc2c45ac824e8fe3d83d5150": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad84c0ed082d4ab7abf2815fc1910efa": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b754e18c5c49499d92db4803cfa426b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b3b4fc0e99a47d0a494aee20166337f",
            "max": 21,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2de24c12eebd4054a3e6163fb6951986",
            "value": 21
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
