{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "output_path = 'output_jpg'\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "# 打开大图像\n",
    "with Image.open('2_17.jpg') as img:\n",
    "    # 计算水平方向和垂直方向上可以切割出多少个256x256的图像\n",
    "    width, height = img.size\n",
    "    num_patches_x = width // 256\n",
    "    num_patches_y = height // 256\n",
    "\n",
    "    # 遍历所有可能的图像块\n",
    "    for i in range(num_patches_x):\n",
    "        for j in range(num_patches_y):\n",
    "            # 计算当前图像块的位置\n",
    "            left = i * 256\n",
    "            upper = j * 256\n",
    "            right = left + 256\n",
    "            lower = upper + 256\n",
    "\n",
    "            # 切割图像块\n",
    "            crop_patchs = img.crop((left, upper, right, lower))\n",
    "\n",
    "            # 保存切割后的图像块\n",
    "            patch.save(os.path.join(output_path,f'patch_{i}_{j}.jpg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2816, 4096, 3)\n",
      "(3, 1280, 1280)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "img_path = '../test/2_17.jpg'\n",
    "input_width, input_height = 1280, 1280\n",
    "img = cv2.imread(img_path)\n",
    "print(img.shape)\n",
    "img=cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "img=cv2.resize(img, (input_width, input_height))\n",
    "image_data = np.array(img) / 255.0\n",
    "image_data = np.transpose(image_data, (2, 0, 1))\n",
    "print(image_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features_FM import Whole_Slide_Patchs\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "wsi_path = '/home/huangjialong/projects/BiomedCLIP-PUNCE/datatools/xCY20010730-HSIL'\n",
    "preprocess = None\n",
    "target_patch_size = (224,224)\n",
    "fine_grained = True\n",
    "fine_grained_pre_size = (1280,1280)\n",
    "fine_grained_size = (256,256)\n",
    "dataset = Whole_Slide_Patchs(wsi_path=wsi_path, target_patch_size=target_patch_size, preprocess=preprocess,\\\n",
    "    fine_grained=fine_grained, fine_grained_pre_size=fine_grained_pre_size, fine_grained_size=fine_grained_size)\n",
    "# dataset[0].shape\n",
    "loader = DataLoader(dataset, batch_size=16, num_workers=20)\n",
    "for data in loader:\n",
    "    print(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP Error using [[('CUDAExecutionProvider', {'device_id': 1}), ('CUDAExecutionProvider', {'device_id': 2})]]\n",
      "Falling back to ['CUDAExecutionProvider', 'CPUExecutionProvider'] and retrying.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "/onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:124 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:117 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; expr=cudaDeviceSynchronize(); \n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:347\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    348\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:370\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    369\u001b[0m \u001b[39m# validate providers and provider_options before other initialization\u001b[39;00m\n\u001b[0;32m--> 370\u001b[0m providers, provider_options \u001b[39m=\u001b[39m check_and_normalize_provider_args(\n\u001b[1;32m    371\u001b[0m     providers, provider_options, available_providers\n\u001b[1;32m    372\u001b[0m )\n\u001b[1;32m    373\u001b[0m \u001b[39mif\u001b[39;00m providers \u001b[39m==\u001b[39m [] \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(available_providers) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:97\u001b[0m, in \u001b[0;36mcheck_and_normalize_provider_args\u001b[0;34m(providers, provider_options, available_provider_names)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 97\u001b[0m             \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39mproviders\u001b[39m\u001b[39m'\u001b[39m\u001b[39m values must be either strings or (string, dict) tuples.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     99\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mlist\u001b[39m(provider_name_to_options\u001b[39m.\u001b[39mkeys()), \u001b[39mlist\u001b[39m(provider_name_to_options\u001b[39m.\u001b[39mvalues())\n",
      "\u001b[0;31mValueError\u001b[0m: 'providers' values must be either strings or (string, dict) tuples.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m model_path \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m/home/huangjialong/projects/tctcls-lp/det-ljx/best_x7_20240822.onnx\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m# 使用ONNX模型文件创建一个推理会话，并指定执行提供者\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m session \u001b[39m=\u001b[39m ort\u001b[39m.\u001b[39;49mInferenceSession(model_path, providers\u001b[39m=\u001b[39;49mproviders)\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m model_inputs \u001b[39m=\u001b[39m session\u001b[39m.\u001b[39mget_inputs()\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m# 获取输入的形状，用于后续使用\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39m# input_shape = model_inputs[0].shape\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39m# input_name = model_inputs[0].name\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m# img = np.random.randn(10, 3, 1280, 1280).astype(np.float32)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://ssh-remote%2B504_3080_1/home/huangjialong/projects/BiomedCLIP-PUNCE/PatchEncoder/test.ipynb#W4sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39m# outputs = session.run(None, {input_name: img})\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:352\u001b[0m, in \u001b[0;36mInferenceSession.__init__\u001b[0;34m(self, path_or_bytes, sess_options, providers, provider_options, **kwargs)\u001b[0m\n\u001b[1;32m    350\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mEP Error using \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(providers))\n\u001b[1;32m    351\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mFalling back to \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m and retrying.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fallback_providers))\n\u001b[0;32m--> 352\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_create_inference_session(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fallback_providers, \u001b[39mNone\u001b[39;49;00m)\n\u001b[1;32m    353\u001b[0m \u001b[39m# Fallback only once.\u001b[39;00m\n\u001b[1;32m    354\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable_fallback()\n",
      "File \u001b[0;32m~/miniconda3/envs/biomed/lib/python3.8/site-packages/onnxruntime/capi/onnxruntime_inference_collection.py:395\u001b[0m, in \u001b[0;36mInferenceSession._create_inference_session\u001b[0;34m(self, providers, provider_options, disabled_optimizers)\u001b[0m\n\u001b[1;32m    392\u001b[0m     disabled_optimizers \u001b[39m=\u001b[39m \u001b[39mset\u001b[39m(disabled_optimizers)\n\u001b[1;32m    394\u001b[0m \u001b[39m# initialize the C++ InferenceSession\u001b[39;00m\n\u001b[0;32m--> 395\u001b[0m sess\u001b[39m.\u001b[39;49minitialize_session(providers, provider_options, disabled_optimizers)\n\u001b[1;32m    397\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess \u001b[39m=\u001b[39m sess\n\u001b[1;32m    398\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess_options \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sess\u001b[39m.\u001b[39msession_options\n",
      "\u001b[0;31mRuntimeError\u001b[0m: /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:124 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] /onnxruntime_src/onnxruntime/core/providers/cuda/cuda_call.cc:117 std::conditional_t<THRW, void, onnxruntime::common::Status> onnxruntime::CudaCall(ERRTYPE, const char*, const char*, ERRTYPE, const char*) [with ERRTYPE = cudaError; bool THRW = true; std::conditional_t<THRW, void, onnxruntime::common::Status> = void] CUDA failure 2: out of memory ; GPU=0 ; hostname=ubuntu ; expr=cudaDeviceSynchronize(); \n\n"
     ]
    }
   ],
   "source": [
    "import onnxruntime as ort\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "device_id=(1,2)\n",
    "# 判断是使用GPU或CPU\n",
    "providers = [\n",
    "    [('CUDAExecutionProvider', {'device_id': id, }) for id in device_id]\n",
    "#     'CPUExecutionProvider',  # 也可以设置CPU作为备选\n",
    "]\n",
    "model_path = '/home/huangjialong/projects/tctcls-lp/det-ljx/best_x7_20240822.onnx'\n",
    "# 使用ONNX模型文件创建一个推理会话，并指定执行提供者\n",
    "session = ort.InferenceSession(model_path, providers=providers)\n",
    "model_inputs = session.get_inputs()\n",
    "\n",
    "# 获取输入的形状，用于后续使用\n",
    "# input_shape = model_inputs[0].shape\n",
    "# input_name = model_inputs[0].name\n",
    "\n",
    "# img = np.random.randn(10, 3, 1280, 1280).astype(np.float32)\n",
    "# outputs = session.run(None, {input_name: img})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('CUDAExecutionProvider', {'device_id': 1}),\n",
       "  ('CUDAExecutionProvider', {'device_id': 2})]]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_id=(1,2)\n",
    "\n",
    "providers = [\n",
    "    [('CUDAExecutionProvider', {'device_id': id, }) for id in device_id]\n",
    "#     'CPUExecutionProvider',  # 也可以设置CPU作为备选\n",
    "]\n",
    "providers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_features_rtdetr import Whole_Slide_Patchs\n",
    "from torch.utils.data import DataLoader\n",
    "wsi_path = '/home/huangjialong/projects/BiomedCLIP-PUNCE/datatools/xCY20010730-HSIL'\n",
    "target_patch_size = (1280,1280)\n",
    "dataset = Whole_Slide_Patchs(wsi_path=wsi_path, target_patch_size=target_patch_size)\n",
    "# dataset[0].shape\n",
    "loader = DataLoader(dataset, batch_size=5, num_workers=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 3, 1280, 1280)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "imgs = np.stack([dataset[120+i] for i in range(5)])\n",
    "print(imgs.shape)\n",
    "input_name = model_inputs[0].name\n",
    "outputs = session.run(None, {input_name: img})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> (2, 256)\n",
      "<class 'numpy.ndarray'> (4, 256)\n",
      "<class 'numpy.ndarray'> (5, 256)\n",
      "<class 'numpy.ndarray'> (3, 256)\n",
      "<class 'numpy.ndarray'> (3, 256)\n",
      "<class 'numpy.ndarray'> (3, 256)\n",
      "<class 'numpy.ndarray'> (4, 256)\n",
      "<class 'numpy.ndarray'> (2, 256)\n",
      "<class 'numpy.ndarray'> (3, 256)\n",
      "<class 'numpy.ndarray'> (3, 256)\n"
     ]
    }
   ],
   "source": [
    "from extract_features_rtdetr import postprocess_feats\n",
    "\n",
    "    \n",
    "confidence_thres=0.1\n",
    "output_process = postprocess_feats(confidence_thres, outputs)\n",
    "for output in output_process:\n",
    "    print(type(output), output.shape)\n",
    "# wsi_feat = []\n",
    "# for data in DataLoader:\n",
    "#     outputs = session.run(None, {input_name: data})\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "biomed",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
