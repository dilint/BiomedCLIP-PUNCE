{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'bert.pooler.dense.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'cls.predictions.decoder.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import open_clip\n",
    "\n",
    "model, preprocess_train, preprocess_val = open_clip.create_model_and_transforms('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')\n",
    "tokenizer = open_clip.get_tokenizer('hf-hub:microsoft/BiomedCLIP-PubMedBERT_256-vit_base_patch16_224')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "DATA_PATH = 'C:\\\\Users\\\\11030\\\\Desktop\\\\biomed-clip-puNCE\\\\output\\\\FNAC'\n",
    "DATA_PREFIXS = [\"B\", \"M\"]\n",
    "OUTPUT_PATH = '..\\\\output\\\\FNAC-features'\n",
    "TEMPLATE = 'this is a photo of '\n",
    "BATCH_SIZE = 256\n",
    "labels = [\n",
    "    'adenocarcinoma histopathology',    # 阴性标签\n",
    "    'squamous cell carcinoma histopathology',   # 阳性标签\n",
    "]\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "context_length = 256\n",
    "texts = tokenizer([TEMPLATE + l for l in labels], context_length=context_length).to(device)\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None, device=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.device = device\n",
    "        self.file_list = os.listdir(root)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_list)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = os.path.join(self.root, self.file_list[index])\n",
    "        img = Image.open(img_path)\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        if self.device is not None:\n",
    "            img = img.to(self.device)\n",
    "        label = 0  # 默认所有图像的类别为0\n",
    "        wsi_num = os.path.basename(img_path).split(\"_\")[0]\n",
    "        return img, label, wsi_num\n",
    " \n",
    " \n",
    "# 从input_path读入图片转化为pth保存到output_path\n",
    "# 通过n_m.jpg的n判断图片属于哪一张wsi\n",
    "def extractFeaturesFromOneDirectories(input_path, output_path):   \n",
    "    # 创建 CustomDataset 数据集\n",
    "    # dataset = CustomDataset(root='D:/dataset/FNAC-2019/B', transform=preprocess_val, device=device)\n",
    "    dataset = CustomDataset(root=input_path, transform=preprocess_val, device=device)\n",
    "    # 创建 DataLoader\n",
    "    dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    scores = {}\n",
    "    all_image_features = {}\n",
    "\n",
    "    with torch.no_grad():\n",
    "        # 提取特征\n",
    "        for images, _, wsi_nums in dataloader:\n",
    "            # image_features @ text_features.t()执行了图像特征和文本特征之间的点积操作，生成了一个分数矩阵。然后，通过乘以logit_scale对分数矩阵进行缩放。这个缩放过程可以增加或减小点积的值，从而影响最终的logits结果。\n",
    "            image_features, text_features, logit_scale = model(images, texts)\n",
    "            logits = (logit_scale * image_features @ text_features.t()).detach().softmax(dim=-1)\n",
    "            logits = logits.cpu().numpy()\n",
    "            for logit, image_feature, wsi_num in zip(logits, image_features, wsi_nums): \n",
    "                if wsi_num not in scores:\n",
    "                    scores[wsi_num] = []\n",
    "                if wsi_num not in all_image_features:\n",
    "                    all_image_features[wsi_num] = []\n",
    "                scores[wsi_num].append(logit[1])\n",
    "                all_image_features[wsi_num].append(image_feature)\n",
    "                \n",
    "    # 存储pth\n",
    "    for wsi_num in scores.keys():\n",
    "        tmp_image_features = all_image_features[wsi_num]\n",
    "        tmp_scores = scores[wsi_num]\n",
    "\n",
    "        # 使用 enumerate 函数获取 all_image_features 的索引和值，并构建排序键\n",
    "        sorted_data = sorted(enumerate(tmp_scores), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # 选择前 100 个 all_image_features 的索引\n",
    "        selected_indices = [data[0] for data in sorted_data[:100]]\n",
    "        # 保持原本顺序\n",
    "        selected_indices.sort()\n",
    "        # 根据索引提取对应的 all_image_features\n",
    "        selected_features = [tmp_image_features[idx] for idx in selected_indices]\n",
    "\n",
    "        # 保存 selected_features\n",
    "        torch.save(selected_features, os.path.join(output_path, wsi_num + '.pth'))             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "for data_prefix in DATA_PREFIXS:\n",
    "    input_path = os.path.join(DATA_PATH, data_prefix)\n",
    "    output_path = os.path.join(OUTPUT_PATH, data_prefix)\n",
    "    if not os.path.exists(output_path): \n",
    "        try:\n",
    "            os.makedirs(output_path)\n",
    "        except OSError:\n",
    "            print(f\"Failed to create folder '{output_path}'.\")\n",
    "\n",
    "    extractFeaturesFromOneDirectories(input_path, output_path)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('biomed-clip')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7cb5855cefb5e02dc34c4de578bb315cb99c7d65be2e4fad60d8d2596700f443"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
